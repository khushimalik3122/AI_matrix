{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3lwk4UU5gSa",
        "outputId": "93af95d3-24bf-49f1-d35c-0b5236f855ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23iQnn8b1Kow",
        "outputId": "dc31963c-ed66-42a1-e6ae-9f97868868ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# Accessing the secret key from Colab secrets\n",
        "hf_token = userdata.get(\"HF_API_KEY\")\n",
        "\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "else:\n",
        "    raise ValueError(\"Hugging Face token not found in Colab secrets 'Colab_HF_token'\")"
      ],
      "metadata": {
        "id": "k1q0nSXb057Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oOAb5mFbpTjj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOla_bDCnG5Y"
      },
      "source": [
        "**Load and Preprocess Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SjCvvAZb9HkY",
        "outputId": "00908850-aab0-49e3-f56e-42ca16778aba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unique_id                     time         x         y     red     nir  \\\n",
              "0  ID_01FHV4  2018-01-03 10:59:22.851 -296455.0  846395.0  0.2920  0.3686   \n",
              "1  ID_01FHV4  2018-01-03 10:59:22.851 -296455.0  846395.0  0.2920  0.3686   \n",
              "2  ID_01FHV4  2018-02-12 10:59:25.232 -296455.0  846395.0  0.3510  0.3426   \n",
              "3  ID_01FHV4  2018-02-12 10:59:25.232 -296455.0  846395.0  0.3510  0.3426   \n",
              "4  ID_01FHV4  2018-03-14 10:59:24.436 -296455.0  846395.0  0.5312  0.6296   \n",
              "\n",
              "   swir16  swir22    blue   green  rededge1  rededge2  rededge3   nir08  \n",
              "0  0.4173  0.3869  0.2488  0.2708    0.3211    0.3555    0.3752  0.3862  \n",
              "1  0.4173  0.3869  0.2488  0.2708    0.3211    0.3555    0.3752  0.3862  \n",
              "2  0.4817  0.4577  0.2538  0.2914    0.3684    0.3484    0.3588  0.3628  \n",
              "3  0.4817  0.4577  0.2538  0.2914    0.3684    0.3484    0.3588  0.3628  \n",
              "4  0.6643  0.5882  0.5244  0.5308    0.6016    0.6217    0.6401  0.6404  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bddb84e-96c0-4b05-9b47-f169d3f597df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>time</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>red</th>\n",
              "      <th>nir</th>\n",
              "      <th>swir16</th>\n",
              "      <th>swir22</th>\n",
              "      <th>blue</th>\n",
              "      <th>green</th>\n",
              "      <th>rededge1</th>\n",
              "      <th>rededge2</th>\n",
              "      <th>rededge3</th>\n",
              "      <th>nir08</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-01-03 10:59:22.851</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>0.3686</td>\n",
              "      <td>0.4173</td>\n",
              "      <td>0.3869</td>\n",
              "      <td>0.2488</td>\n",
              "      <td>0.2708</td>\n",
              "      <td>0.3211</td>\n",
              "      <td>0.3555</td>\n",
              "      <td>0.3752</td>\n",
              "      <td>0.3862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-01-03 10:59:22.851</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>0.3686</td>\n",
              "      <td>0.4173</td>\n",
              "      <td>0.3869</td>\n",
              "      <td>0.2488</td>\n",
              "      <td>0.2708</td>\n",
              "      <td>0.3211</td>\n",
              "      <td>0.3555</td>\n",
              "      <td>0.3752</td>\n",
              "      <td>0.3862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-02-12 10:59:25.232</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.3510</td>\n",
              "      <td>0.3426</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.4577</td>\n",
              "      <td>0.2538</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.3684</td>\n",
              "      <td>0.3484</td>\n",
              "      <td>0.3588</td>\n",
              "      <td>0.3628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-02-12 10:59:25.232</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.3510</td>\n",
              "      <td>0.3426</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.4577</td>\n",
              "      <td>0.2538</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.3684</td>\n",
              "      <td>0.3484</td>\n",
              "      <td>0.3588</td>\n",
              "      <td>0.3628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-03-14 10:59:24.436</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.5312</td>\n",
              "      <td>0.6296</td>\n",
              "      <td>0.6643</td>\n",
              "      <td>0.5882</td>\n",
              "      <td>0.5244</td>\n",
              "      <td>0.5308</td>\n",
              "      <td>0.6016</td>\n",
              "      <td>0.6217</td>\n",
              "      <td>0.6401</td>\n",
              "      <td>0.6404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bddb84e-96c0-4b05-9b47-f169d3f597df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0bddb84e-96c0-4b05-9b47-f169d3f597df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0bddb84e-96c0-4b05-9b47-f169d3f597df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-769a766a-b44d-4dcc-8cb2-4d0efcb92dd0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-769a766a-b44d-4dcc-8cb2-4d0efcb92dd0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-769a766a-b44d-4dcc-8cb2-4d0efcb92dd0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/test (6).csv')\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4PfQfdag5ah3",
        "outputId": "59c714c3-78cc-4e16-89ef-57efe7b39bac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   blue crop_type  green   nir  nir08   red  rededge1  rededge2  rededge3  \\\n",
              "0   559     cocoa    771  2404   2585   846      1240      2006      2326   \n",
              "1   537     cocoa    916  2448   2750  1096      1464      2124      2390   \n",
              "2   540     cocoa    877  2402   2498  1084      1415      1943      2184   \n",
              "3  1944     cocoa   2094  3076   3307  2260      2537      2809      3043   \n",
              "4  2062     cocoa   2092  2484   2599  2210      2293      2371      2529   \n",
              "\n",
              "   swir16  swir22        time   unique_id         x         y  \n",
              "0    2630    1684  2022-01-03  PIXEL_0001  0.957526  6.899852  \n",
              "1    2851    1823  2022-01-08  PIXEL_0001  0.957526  6.899852  \n",
              "2    3069    2100  2022-01-23  PIXEL_0001  0.957526  6.899852  \n",
              "3    3887    2979  2022-01-28  PIXEL_0001  0.957526  6.899852  \n",
              "4    2837    2275  2022-02-12  PIXEL_0001  0.957526  6.899852  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6a54099-937f-4f53-897d-453afe2ea8c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>blue</th>\n",
              "      <th>crop_type</th>\n",
              "      <th>green</th>\n",
              "      <th>nir</th>\n",
              "      <th>nir08</th>\n",
              "      <th>red</th>\n",
              "      <th>rededge1</th>\n",
              "      <th>rededge2</th>\n",
              "      <th>rededge3</th>\n",
              "      <th>swir16</th>\n",
              "      <th>swir22</th>\n",
              "      <th>time</th>\n",
              "      <th>unique_id</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>559</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>771</td>\n",
              "      <td>2404</td>\n",
              "      <td>2585</td>\n",
              "      <td>846</td>\n",
              "      <td>1240</td>\n",
              "      <td>2006</td>\n",
              "      <td>2326</td>\n",
              "      <td>2630</td>\n",
              "      <td>1684</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>537</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>916</td>\n",
              "      <td>2448</td>\n",
              "      <td>2750</td>\n",
              "      <td>1096</td>\n",
              "      <td>1464</td>\n",
              "      <td>2124</td>\n",
              "      <td>2390</td>\n",
              "      <td>2851</td>\n",
              "      <td>1823</td>\n",
              "      <td>2022-01-08</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>540</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>877</td>\n",
              "      <td>2402</td>\n",
              "      <td>2498</td>\n",
              "      <td>1084</td>\n",
              "      <td>1415</td>\n",
              "      <td>1943</td>\n",
              "      <td>2184</td>\n",
              "      <td>3069</td>\n",
              "      <td>2100</td>\n",
              "      <td>2022-01-23</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1944</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>2094</td>\n",
              "      <td>3076</td>\n",
              "      <td>3307</td>\n",
              "      <td>2260</td>\n",
              "      <td>2537</td>\n",
              "      <td>2809</td>\n",
              "      <td>3043</td>\n",
              "      <td>3887</td>\n",
              "      <td>2979</td>\n",
              "      <td>2022-01-28</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2062</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>2092</td>\n",
              "      <td>2484</td>\n",
              "      <td>2599</td>\n",
              "      <td>2210</td>\n",
              "      <td>2293</td>\n",
              "      <td>2371</td>\n",
              "      <td>2529</td>\n",
              "      <td>2837</td>\n",
              "      <td>2275</td>\n",
              "      <td>2022-02-12</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6a54099-937f-4f53-897d-453afe2ea8c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6a54099-937f-4f53-897d-453afe2ea8c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6a54099-937f-4f53-897d-453afe2ea8c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e991a4c6-eddb-4dd6-abb8-00cb788a1d7c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e991a4c6-eddb-4dd6-abb8-00cb788a1d7c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e991a4c6-eddb-4dd6-abb8-00cb788a1d7c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 18442,\n  \"fields\": [\n    {\n      \"column\": \"blue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 488,\n        \"min\": 179,\n        \"max\": 10728,\n        \"num_unique_values\": 1935,\n        \"samples\": [\n          2580,\n          2090,\n          2228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crop_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"cocoa\",\n          \"rubber\",\n          \"oil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"green\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 464,\n        \"min\": 387,\n        \"max\": 9160,\n        \"num_unique_values\": 1718,\n        \"samples\": [\n          1572,\n          2710,\n          2300\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nir\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 836,\n        \"min\": 916,\n        \"max\": 8296,\n        \"num_unique_values\": 3092,\n        \"samples\": [\n          3317,\n          3101,\n          2518\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nir08\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 884,\n        \"min\": 1112,\n        \"max\": 8410,\n        \"num_unique_values\": 3989,\n        \"samples\": [\n          5043,\n          3969,\n          6066\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"red\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 513,\n        \"min\": 361,\n        \"max\": 8480,\n        \"num_unique_values\": 1990,\n        \"samples\": [\n          954,\n          2834,\n          1812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rededge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 482,\n        \"min\": 739,\n        \"max\": 8705,\n        \"num_unique_values\": 2545,\n        \"samples\": [\n          2370,\n          1323,\n          905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rededge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 743,\n        \"min\": 859,\n        \"max\": 8287,\n        \"num_unique_values\": 3522,\n        \"samples\": [\n          4057,\n          4277,\n          5480\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rededge3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 871,\n        \"min\": 978,\n        \"max\": 8146,\n        \"num_unique_values\": 3940,\n        \"samples\": [\n          2772,\n          5559,\n          5090\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"swir16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 621,\n        \"min\": 1509,\n        \"max\": 8174,\n        \"num_unique_values\": 3042,\n        \"samples\": [\n          3322,\n          4682,\n          3640\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"swir22\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 697,\n        \"min\": 875,\n        \"max\": 6929,\n        \"num_unique_values\": 3182,\n        \"samples\": [\n          2590,\n          1442,\n          2034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 94,\n        \"samples\": [\n          \"2023-06-12\",\n          \"2022-12-09\",\n          \"2022-02-17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"PIXEL_0204\",\n          \"PIXEL_0267\",\n          \"PIXEL_0153\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12941993225545187,\n        \"min\": 0.737631256617266,\n        \"max\": 1.1896215931644405,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          0.8558330501088164,\n          0.8653348628582926,\n          0.853572500546085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1333326103363097,\n        \"min\": 6.780823163721891,\n        \"max\": 7.231648189646034,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          7.083970461978835,\n          6.985528934655409,\n          6.965861127156559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Sentinel2_CropSamples_Reorganized.csv')\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "BUdSGsQz9U__",
        "outputId": "690feb6e-1d9c-4597-ad1b-11a1d9dde0f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "crop_type\n",
              "cocoa     6359\n",
              "rubber    6283\n",
              "oil       5800\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>crop_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cocoa</th>\n",
              "      <td>6359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rubber</th>\n",
              "      <td>6283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oil</th>\n",
              "      <td>5800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_df['crop_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoConfig\n",
        "\n",
        "model_name = \"AminiTech/amini-28M-v1\"\n",
        "\n",
        "# Load model config and model (for PatchTST, not a language model!)\n",
        "config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(model_name, config=config, trust_remote_code=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207,
          "referenced_widgets": [
            "19c5799fdc7f40258f28f1568a967de4",
            "79099b1ded42423fb22479cd36217db6",
            "f41396ad91fd41e5848fbdbbc263b358",
            "18a0d4c6ef4a42bba8f996c090accc19",
            "942f9db83e2d48e3a3812f5c2c873a05",
            "5d14bd34c3484a188062a12c82a91ba8",
            "5518ec3258d14c75b5e663ee7c0bb0c5",
            "a88839dce48f4ff38353a64edc9be18c",
            "f14d99d894cc4a4c9abd2e77b0bd3fbe",
            "29c63246cbff45d28042aae86152eeba",
            "24e8273d1b8a4348a95fbf4d48f6c6e2",
            "afb9c4ef904548eaaaa8fe37c94588ed",
            "2337e161ffbc4334af4b948da716ea59",
            "5dcd8406094547f7b9cf788beba99dba",
            "d24dacc1c21e4418ade4fecf1aa21040",
            "ff8072efb457436696c3df1f40111063",
            "fa4df50ccb6249c7bd4b829139440b4d",
            "dfae76d3452049c5b70c762abb8d7f1c",
            "c81114c28e6e471485edf3857e1ec627",
            "decbf00bc3a84733a166c28443073881",
            "b7885ae2379044158dcec2d28a331fb1",
            "f23293cddadc4e80a8636a80d79fa68d"
          ]
        },
        "id": "I9eOWlKD1NnV",
        "outputId": "ec9abd0e-7540-4c4a-8ce1-35139b5bdeee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19c5799fdc7f40258f28f1568a967de4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/75.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afb9c4ef904548eaaaa8fe37c94588ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J16b8-QjEHNq",
        "outputId": "296efc16-7d3f-4a5b-aaf8-c5e2615d8e1e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchTSTModel(\n",
              "  (scaler): PatchTSTScaler(\n",
              "    (scaler): PatchTSTMeanScaler()\n",
              "  )\n",
              "  (patchifier): PatchTSTPatchify()\n",
              "  (masking): PatchTSTMasking()\n",
              "  (encoder): PatchTSTEncoder(\n",
              "    (embedder): PatchTSTEmbedding(\n",
              "      (input_embedding): Linear(in_features=12, out_features=512, bias=True)\n",
              "    )\n",
              "    (positional_encoder): PatchTSTPositionalEncoding(\n",
              "      (positional_dropout): Identity()\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x PatchTSTEncoderLayer(\n",
              "        (self_attn): PatchTSTAttention(\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (dropout_path1): Identity()\n",
              "        (norm_sublayer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout_path2): Identity()\n",
              "        (norm_sublayer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Identity()\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (dropout_path3): Identity()\n",
              "        (norm_sublayer3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_aggregator(cls_embeddings):\n",
        "    \"\"\"\n",
        "    Fully averages all CLS embeddings, no splitting.\n",
        "    Handles extra dimensions safely.\n",
        "\n",
        "    Args:\n",
        "        cls_embeddings: list or array of CLS tokens [n, 512] or [1, n, 512]\n",
        "    Returns:\n",
        "        final_embedding: mean [512]-dim vector\n",
        "    \"\"\"\n",
        "    cls_embeddings = np.array(cls_embeddings)\n",
        "\n",
        "    # Handle possible extra dimensions\n",
        "    if cls_embeddings.ndim == 3 and cls_embeddings.shape[1] == 1:\n",
        "        cls_embeddings = cls_embeddings.squeeze(1)\n",
        "    elif cls_embeddings.ndim == 1:\n",
        "        cls_embeddings = cls_embeddings.reshape(1, -1)  # shape: [1, 512]\n",
        "\n",
        "    return np.mean(cls_embeddings, axis=0)\n"
      ],
      "metadata": {
        "id": "BF82AtG13qEG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings_sliding_window(df, model, max_length=48, stride=24):\n",
        "    grouped = df.groupby('unique_id')\n",
        "    all_embeddings = {}\n",
        "\n",
        "    for unique_id, group in grouped:\n",
        "        group = group.sort_values('time')\n",
        "        features = group[['blue', 'green', 'nir', 'nir08', 'red', 'rededge1',\n",
        "                          'rededge2', 'rededge3', 'swir16', 'swir22']].values\n",
        "        sequence_length = len(features)\n",
        "        print(f\"[{unique_id}] Raw sequence length: {sequence_length}\")\n",
        "\n",
        "        # Normalize\n",
        "        features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-6)\n",
        "        cls_list = []\n",
        "\n",
        "        if sequence_length < max_length:\n",
        "            # Pad to 48\n",
        "            pad_len = max_length - sequence_length\n",
        "            padding = np.zeros((pad_len, features.shape[1]))\n",
        "            features_padded = np.vstack([features, padding])\n",
        "\n",
        "            tensor_input = torch.tensor(features_padded, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            print(f\"[{unique_id}] Padded input shape: {tensor_input.shape}\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                try:\n",
        "                    output = model(tensor_input)\n",
        "                    print(f\"[{unique_id}] Output type: {type(output)}\")\n",
        "                    print(f\"[{unique_id}] Output shape: {output.last_hidden_state.shape}\")\n",
        "\n",
        "                    # ✅ CLS patch (index 0), mean across bands\n",
        "                    cls_token = output.last_hidden_state[:, :, 0, :].mean(dim=1).squeeze(0).cpu().numpy()\n",
        "                    assert cls_token.shape == (512,)\n",
        "                    cls_list.append(cls_token)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"[{unique_id}] Error during padded input: {type(e).__name__} - {e}\")\n",
        "                    continue\n",
        "\n",
        "        else:\n",
        "            # Sliding windows\n",
        "            for i in range(0, sequence_length - max_length + 1, stride):\n",
        "                window = features[i : i + max_length]\n",
        "                tensor_input = torch.tensor(window, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "                print(f\"[{unique_id}] Window {i} input shape: {tensor_input.shape}\")\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    try:\n",
        "                        output = model(tensor_input)\n",
        "                        print(f\"[{unique_id}] Output type: {type(output)}\")\n",
        "                        print(f\"[{unique_id}] Output shape: {output.last_hidden_state.shape}\")\n",
        "\n",
        "                        # ✅ CLS patch token = patch index 0\n",
        "                        cls_token = output.last_hidden_state[:, :, 0, :].mean(dim=1).squeeze(0).cpu().numpy()\n",
        "                        assert cls_token.shape == (512,)\n",
        "                        cls_list.append(cls_token)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"[{unique_id}] Error at window {i}: {type(e).__name__} - {e}\")\n",
        "                        continue\n",
        "\n",
        "        if cls_list:\n",
        "            cls_array = np.array(cls_list)\n",
        "            print(f\"[{unique_id}] CLS token array shape: {cls_array.shape}\")  # e.g., (3, 512)\n",
        "            all_embeddings[unique_id] = cls_list\n",
        "        else:\n",
        "            print(f\"[{unique_id}] No CLS tokens generated\")\n",
        "\n",
        "    return all_embeddings\n"
      ],
      "metadata": {
        "id": "YEHroeWVEIgv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_embeddings = generate_embeddings_sliding_window(train_df, model, max_length=48, stride=24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYhZepvN3wgb",
        "outputId": "93a09697-9d23-4915-9729-47307d207194"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PIXEL_0001] Raw sequence length: 54\n",
            "[PIXEL_0001] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0001] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0001] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0001] CLS token array shape: (1, 512)\n",
            "[PIXEL_0002] Raw sequence length: 108\n",
            "[PIXEL_0002] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0002] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0002] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0002] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0002] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0002] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0002] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0002] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0002] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0002] CLS token array shape: (3, 512)\n",
            "[PIXEL_0003] Raw sequence length: 112\n",
            "[PIXEL_0003] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0003] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0003] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0003] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0003] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0003] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0003] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0003] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0003] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0003] CLS token array shape: (3, 512)\n",
            "[PIXEL_0004] Raw sequence length: 55\n",
            "[PIXEL_0004] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0004] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0004] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0004] CLS token array shape: (1, 512)\n",
            "[PIXEL_0005] Raw sequence length: 46\n",
            "[PIXEL_0005] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0005] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0005] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0005] CLS token array shape: (1, 512)\n",
            "[PIXEL_0006] Raw sequence length: 110\n",
            "[PIXEL_0006] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0006] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0006] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0006] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0006] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0006] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0006] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0006] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0006] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0006] CLS token array shape: (3, 512)\n",
            "[PIXEL_0007] Raw sequence length: 54\n",
            "[PIXEL_0007] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0007] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0007] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0007] CLS token array shape: (1, 512)\n",
            "[PIXEL_0008] Raw sequence length: 109\n",
            "[PIXEL_0008] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0008] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0008] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0008] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0008] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0008] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0008] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0008] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0008] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0008] CLS token array shape: (3, 512)\n",
            "[PIXEL_0009] Raw sequence length: 51\n",
            "[PIXEL_0009] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0009] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0009] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0009] CLS token array shape: (1, 512)\n",
            "[PIXEL_0010] Raw sequence length: 51\n",
            "[PIXEL_0010] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0010] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0010] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0010] CLS token array shape: (1, 512)\n",
            "[PIXEL_0011] Raw sequence length: 57\n",
            "[PIXEL_0011] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0011] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0011] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0011] CLS token array shape: (1, 512)\n",
            "[PIXEL_0012] Raw sequence length: 43\n",
            "[PIXEL_0012] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0012] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0012] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0012] CLS token array shape: (1, 512)\n",
            "[PIXEL_0013] Raw sequence length: 55\n",
            "[PIXEL_0013] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0013] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0013] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0013] CLS token array shape: (1, 512)\n",
            "[PIXEL_0014] Raw sequence length: 55\n",
            "[PIXEL_0014] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0014] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0014] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0014] CLS token array shape: (1, 512)\n",
            "[PIXEL_0015] Raw sequence length: 56\n",
            "[PIXEL_0015] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0015] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0015] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0015] CLS token array shape: (1, 512)\n",
            "[PIXEL_0016] Raw sequence length: 54\n",
            "[PIXEL_0016] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0016] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0016] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0016] CLS token array shape: (1, 512)\n",
            "[PIXEL_0017] Raw sequence length: 46\n",
            "[PIXEL_0017] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0017] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0017] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0017] CLS token array shape: (1, 512)\n",
            "[PIXEL_0018] Raw sequence length: 44\n",
            "[PIXEL_0018] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0018] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0018] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0018] CLS token array shape: (1, 512)\n",
            "[PIXEL_0019] Raw sequence length: 56\n",
            "[PIXEL_0019] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0019] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0019] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0019] CLS token array shape: (1, 512)\n",
            "[PIXEL_0020] Raw sequence length: 49\n",
            "[PIXEL_0020] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0020] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0020] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0020] CLS token array shape: (1, 512)\n",
            "[PIXEL_0021] Raw sequence length: 46\n",
            "[PIXEL_0021] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0021] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0021] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0021] CLS token array shape: (1, 512)\n",
            "[PIXEL_0022] Raw sequence length: 51\n",
            "[PIXEL_0022] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0022] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0022] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0022] CLS token array shape: (1, 512)\n",
            "[PIXEL_0023] Raw sequence length: 54\n",
            "[PIXEL_0023] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0023] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0023] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0023] CLS token array shape: (1, 512)\n",
            "[PIXEL_0024] Raw sequence length: 46\n",
            "[PIXEL_0024] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0024] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0024] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0024] CLS token array shape: (1, 512)\n",
            "[PIXEL_0025] Raw sequence length: 108\n",
            "[PIXEL_0025] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0025] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0025] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0025] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0025] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0025] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0025] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0025] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0025] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0025] CLS token array shape: (3, 512)\n",
            "[PIXEL_0026] Raw sequence length: 110\n",
            "[PIXEL_0026] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0026] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0026] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0026] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0026] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0026] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0026] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0026] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0026] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0026] CLS token array shape: (3, 512)\n",
            "[PIXEL_0027] Raw sequence length: 111\n",
            "[PIXEL_0027] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0027] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0027] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0027] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0027] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0027] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0027] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0027] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0027] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0027] CLS token array shape: (3, 512)\n",
            "[PIXEL_0028] Raw sequence length: 45\n",
            "[PIXEL_0028] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0028] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0028] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0028] CLS token array shape: (1, 512)\n",
            "[PIXEL_0029] Raw sequence length: 49\n",
            "[PIXEL_0029] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0029] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0029] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0029] CLS token array shape: (1, 512)\n",
            "[PIXEL_0030] Raw sequence length: 58\n",
            "[PIXEL_0030] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0030] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0030] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0030] CLS token array shape: (1, 512)\n",
            "[PIXEL_0031] Raw sequence length: 51\n",
            "[PIXEL_0031] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0031] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0031] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0031] CLS token array shape: (1, 512)\n",
            "[PIXEL_0032] Raw sequence length: 49\n",
            "[PIXEL_0032] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0032] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0032] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0032] CLS token array shape: (1, 512)\n",
            "[PIXEL_0033] Raw sequence length: 64\n",
            "[PIXEL_0033] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0033] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0033] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0033] CLS token array shape: (1, 512)\n",
            "[PIXEL_0034] Raw sequence length: 47\n",
            "[PIXEL_0034] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0034] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0034] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0034] CLS token array shape: (1, 512)\n",
            "[PIXEL_0035] Raw sequence length: 46\n",
            "[PIXEL_0035] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0035] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0035] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0035] CLS token array shape: (1, 512)\n",
            "[PIXEL_0036] Raw sequence length: 58\n",
            "[PIXEL_0036] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0036] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0036] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0036] CLS token array shape: (1, 512)\n",
            "[PIXEL_0037] Raw sequence length: 57\n",
            "[PIXEL_0037] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0037] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0037] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0037] CLS token array shape: (1, 512)\n",
            "[PIXEL_0038] Raw sequence length: 49\n",
            "[PIXEL_0038] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0038] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0038] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0038] CLS token array shape: (1, 512)\n",
            "[PIXEL_0039] Raw sequence length: 46\n",
            "[PIXEL_0039] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0039] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0039] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0039] CLS token array shape: (1, 512)\n",
            "[PIXEL_0040] Raw sequence length: 46\n",
            "[PIXEL_0040] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0040] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0040] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0040] CLS token array shape: (1, 512)\n",
            "[PIXEL_0041] Raw sequence length: 48\n",
            "[PIXEL_0041] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0041] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0041] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0041] CLS token array shape: (1, 512)\n",
            "[PIXEL_0042] Raw sequence length: 54\n",
            "[PIXEL_0042] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0042] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0042] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0042] CLS token array shape: (1, 512)\n",
            "[PIXEL_0043] Raw sequence length: 100\n",
            "[PIXEL_0043] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0043] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0043] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0043] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0043] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0043] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0043] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0043] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0043] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0043] CLS token array shape: (3, 512)\n",
            "[PIXEL_0044] Raw sequence length: 48\n",
            "[PIXEL_0044] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0044] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0044] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0044] CLS token array shape: (1, 512)\n",
            "[PIXEL_0045] Raw sequence length: 52\n",
            "[PIXEL_0045] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0045] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0045] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0045] CLS token array shape: (1, 512)\n",
            "[PIXEL_0046] Raw sequence length: 48\n",
            "[PIXEL_0046] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0046] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0046] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0046] CLS token array shape: (1, 512)\n",
            "[PIXEL_0047] Raw sequence length: 56\n",
            "[PIXEL_0047] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0047] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0047] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0047] CLS token array shape: (1, 512)\n",
            "[PIXEL_0048] Raw sequence length: 58\n",
            "[PIXEL_0048] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0048] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0048] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0048] CLS token array shape: (1, 512)\n",
            "[PIXEL_0049] Raw sequence length: 111\n",
            "[PIXEL_0049] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0049] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0049] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0049] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0049] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0049] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0049] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0049] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0049] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0049] CLS token array shape: (3, 512)\n",
            "[PIXEL_0050] Raw sequence length: 41\n",
            "[PIXEL_0050] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0050] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0050] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0050] CLS token array shape: (1, 512)\n",
            "[PIXEL_0051] Raw sequence length: 51\n",
            "[PIXEL_0051] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0051] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0051] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0051] CLS token array shape: (1, 512)\n",
            "[PIXEL_0052] Raw sequence length: 113\n",
            "[PIXEL_0052] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0052] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0052] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0052] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0052] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0052] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0052] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0052] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0052] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0052] CLS token array shape: (3, 512)\n",
            "[PIXEL_0053] Raw sequence length: 52\n",
            "[PIXEL_0053] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0053] CLS token array shape: (1, 512)\n",
            "[PIXEL_0054] Raw sequence length: 54\n",
            "[PIXEL_0054] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0054] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0054] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0054] CLS token array shape: (1, 512)\n",
            "[PIXEL_0055] Raw sequence length: 55\n",
            "[PIXEL_0055] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0055] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0055] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0055] CLS token array shape: (1, 512)\n",
            "[PIXEL_0056] Raw sequence length: 107\n",
            "[PIXEL_0056] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0056] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0056] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0056] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0056] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0056] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0056] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0056] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0056] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0056] CLS token array shape: (3, 512)\n",
            "[PIXEL_0057] Raw sequence length: 117\n",
            "[PIXEL_0057] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0057] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0057] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0057] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0057] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0057] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0057] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0057] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0057] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0057] CLS token array shape: (3, 512)\n",
            "[PIXEL_0058] Raw sequence length: 49\n",
            "[PIXEL_0058] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0058] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0058] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0058] CLS token array shape: (1, 512)\n",
            "[PIXEL_0059] Raw sequence length: 50\n",
            "[PIXEL_0059] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0059] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0059] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0059] CLS token array shape: (1, 512)\n",
            "[PIXEL_0060] Raw sequence length: 119\n",
            "[PIXEL_0060] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0060] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0060] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0060] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0060] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0060] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0060] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0060] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0060] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0060] CLS token array shape: (3, 512)\n",
            "[PIXEL_0061] Raw sequence length: 62\n",
            "[PIXEL_0061] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0061] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0061] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0061] CLS token array shape: (1, 512)\n",
            "[PIXEL_0062] Raw sequence length: 43\n",
            "[PIXEL_0062] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0062] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0062] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0062] CLS token array shape: (1, 512)\n",
            "[PIXEL_0063] Raw sequence length: 53\n",
            "[PIXEL_0063] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0063] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0063] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0063] CLS token array shape: (1, 512)\n",
            "[PIXEL_0064] Raw sequence length: 53\n",
            "[PIXEL_0064] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0064] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0064] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0064] CLS token array shape: (1, 512)\n",
            "[PIXEL_0065] Raw sequence length: 49\n",
            "[PIXEL_0065] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0065] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0065] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0065] CLS token array shape: (1, 512)\n",
            "[PIXEL_0066] Raw sequence length: 57\n",
            "[PIXEL_0066] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0066] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0066] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0066] CLS token array shape: (1, 512)\n",
            "[PIXEL_0067] Raw sequence length: 120\n",
            "[PIXEL_0067] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0067] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0067] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0067] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0067] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0067] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0067] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0067] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0067] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0067] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0067] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0067] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0067] CLS token array shape: (4, 512)\n",
            "[PIXEL_0068] Raw sequence length: 56\n",
            "[PIXEL_0068] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0068] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0068] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0068] CLS token array shape: (1, 512)\n",
            "[PIXEL_0069] Raw sequence length: 50\n",
            "[PIXEL_0069] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0069] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0069] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0069] CLS token array shape: (1, 512)\n",
            "[PIXEL_0070] Raw sequence length: 44\n",
            "[PIXEL_0070] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0070] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0070] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0070] CLS token array shape: (1, 512)\n",
            "[PIXEL_0071] Raw sequence length: 55\n",
            "[PIXEL_0071] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0071] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0071] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0071] CLS token array shape: (1, 512)\n",
            "[PIXEL_0072] Raw sequence length: 47\n",
            "[PIXEL_0072] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0072] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0072] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0072] CLS token array shape: (1, 512)\n",
            "[PIXEL_0073] Raw sequence length: 57\n",
            "[PIXEL_0073] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0073] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0073] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0073] CLS token array shape: (1, 512)\n",
            "[PIXEL_0074] Raw sequence length: 55\n",
            "[PIXEL_0074] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0074] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0074] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0074] CLS token array shape: (1, 512)\n",
            "[PIXEL_0075] Raw sequence length: 43\n",
            "[PIXEL_0075] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0075] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0075] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0075] CLS token array shape: (1, 512)\n",
            "[PIXEL_0076] Raw sequence length: 96\n",
            "[PIXEL_0076] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0076] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0076] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0076] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0076] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0076] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0076] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0076] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0076] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0076] CLS token array shape: (3, 512)\n",
            "[PIXEL_0077] Raw sequence length: 53\n",
            "[PIXEL_0077] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0077] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0077] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0077] CLS token array shape: (1, 512)\n",
            "[PIXEL_0078] Raw sequence length: 46\n",
            "[PIXEL_0078] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0078] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0078] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0078] CLS token array shape: (1, 512)\n",
            "[PIXEL_0079] Raw sequence length: 54\n",
            "[PIXEL_0079] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0079] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0079] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0079] CLS token array shape: (1, 512)\n",
            "[PIXEL_0080] Raw sequence length: 103\n",
            "[PIXEL_0080] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0080] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0080] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0080] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0080] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0080] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0080] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0080] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0080] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0080] CLS token array shape: (3, 512)\n",
            "[PIXEL_0081] Raw sequence length: 53\n",
            "[PIXEL_0081] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0081] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0081] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0081] CLS token array shape: (1, 512)\n",
            "[PIXEL_0082] Raw sequence length: 108\n",
            "[PIXEL_0082] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0082] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0082] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0082] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0082] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0082] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0082] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0082] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0082] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0082] CLS token array shape: (3, 512)\n",
            "[PIXEL_0083] Raw sequence length: 43\n",
            "[PIXEL_0083] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0083] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0083] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0083] CLS token array shape: (1, 512)\n",
            "[PIXEL_0084] Raw sequence length: 51\n",
            "[PIXEL_0084] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0084] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0084] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0084] CLS token array shape: (1, 512)\n",
            "[PIXEL_0085] Raw sequence length: 52\n",
            "[PIXEL_0085] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0085] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0085] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0085] CLS token array shape: (1, 512)\n",
            "[PIXEL_0086] Raw sequence length: 54\n",
            "[PIXEL_0086] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0086] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0086] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0086] CLS token array shape: (1, 512)\n",
            "[PIXEL_0087] Raw sequence length: 56\n",
            "[PIXEL_0087] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0087] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0087] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0087] CLS token array shape: (1, 512)\n",
            "[PIXEL_0088] Raw sequence length: 114\n",
            "[PIXEL_0088] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0088] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0088] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0088] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0088] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0088] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0088] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0088] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0088] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0088] CLS token array shape: (3, 512)\n",
            "[PIXEL_0089] Raw sequence length: 115\n",
            "[PIXEL_0089] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0089] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0089] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0089] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0089] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0089] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0089] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0089] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0089] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0089] CLS token array shape: (3, 512)\n",
            "[PIXEL_0090] Raw sequence length: 43\n",
            "[PIXEL_0090] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0090] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0090] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0090] CLS token array shape: (1, 512)\n",
            "[PIXEL_0091] Raw sequence length: 53\n",
            "[PIXEL_0091] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0091] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0091] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0091] CLS token array shape: (1, 512)\n",
            "[PIXEL_0092] Raw sequence length: 59\n",
            "[PIXEL_0092] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0092] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0092] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0092] CLS token array shape: (1, 512)\n",
            "[PIXEL_0093] Raw sequence length: 49\n",
            "[PIXEL_0093] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0093] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0093] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0093] CLS token array shape: (1, 512)\n",
            "[PIXEL_0094] Raw sequence length: 53\n",
            "[PIXEL_0094] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0094] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0094] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0094] CLS token array shape: (1, 512)\n",
            "[PIXEL_0095] Raw sequence length: 101\n",
            "[PIXEL_0095] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0095] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0095] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0095] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0095] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0095] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0095] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0095] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0095] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0095] CLS token array shape: (3, 512)\n",
            "[PIXEL_0096] Raw sequence length: 44\n",
            "[PIXEL_0096] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0096] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0096] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0096] CLS token array shape: (1, 512)\n",
            "[PIXEL_0097] Raw sequence length: 50\n",
            "[PIXEL_0097] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0097] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0097] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0097] CLS token array shape: (1, 512)\n",
            "[PIXEL_0098] Raw sequence length: 117\n",
            "[PIXEL_0098] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0098] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0098] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0098] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0098] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0098] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0098] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0098] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0098] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0098] CLS token array shape: (3, 512)\n",
            "[PIXEL_0099] Raw sequence length: 48\n",
            "[PIXEL_0099] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0099] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0099] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0099] CLS token array shape: (1, 512)\n",
            "[PIXEL_0100] Raw sequence length: 61\n",
            "[PIXEL_0100] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0100] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0100] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0100] CLS token array shape: (1, 512)\n",
            "[PIXEL_0101] Raw sequence length: 50\n",
            "[PIXEL_0101] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0101] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0101] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0101] CLS token array shape: (1, 512)\n",
            "[PIXEL_0102] Raw sequence length: 43\n",
            "[PIXEL_0102] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0102] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0102] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0102] CLS token array shape: (1, 512)\n",
            "[PIXEL_0103] Raw sequence length: 49\n",
            "[PIXEL_0103] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0103] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0103] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0103] CLS token array shape: (1, 512)\n",
            "[PIXEL_0104] Raw sequence length: 53\n",
            "[PIXEL_0104] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0104] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0104] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0104] CLS token array shape: (1, 512)\n",
            "[PIXEL_0105] Raw sequence length: 50\n",
            "[PIXEL_0105] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0105] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0105] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0105] CLS token array shape: (1, 512)\n",
            "[PIXEL_0106] Raw sequence length: 56\n",
            "[PIXEL_0106] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0106] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0106] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0106] CLS token array shape: (1, 512)\n",
            "[PIXEL_0107] Raw sequence length: 47\n",
            "[PIXEL_0107] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0107] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0107] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0107] CLS token array shape: (1, 512)\n",
            "[PIXEL_0108] Raw sequence length: 54\n",
            "[PIXEL_0108] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0108] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0108] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0108] CLS token array shape: (1, 512)\n",
            "[PIXEL_0109] Raw sequence length: 106\n",
            "[PIXEL_0109] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0109] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0109] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0109] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0109] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0109] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0109] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0109] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0109] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0109] CLS token array shape: (3, 512)\n",
            "[PIXEL_0110] Raw sequence length: 54\n",
            "[PIXEL_0110] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0110] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0110] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0110] CLS token array shape: (1, 512)\n",
            "[PIXEL_0111] Raw sequence length: 95\n",
            "[PIXEL_0111] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0111] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0111] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0111] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0111] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0111] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0111] CLS token array shape: (2, 512)\n",
            "[PIXEL_0112] Raw sequence length: 51\n",
            "[PIXEL_0112] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0112] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0112] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0112] CLS token array shape: (1, 512)\n",
            "[PIXEL_0113] Raw sequence length: 99\n",
            "[PIXEL_0113] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0113] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0113] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0113] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0113] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0113] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0113] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0113] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0113] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0113] CLS token array shape: (3, 512)\n",
            "[PIXEL_0114] Raw sequence length: 116\n",
            "[PIXEL_0114] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0114] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0114] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0114] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0114] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0114] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0114] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0114] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0114] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0114] CLS token array shape: (3, 512)\n",
            "[PIXEL_0115] Raw sequence length: 49\n",
            "[PIXEL_0115] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0115] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0115] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0115] CLS token array shape: (1, 512)\n",
            "[PIXEL_0116] Raw sequence length: 64\n",
            "[PIXEL_0116] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0116] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0116] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0116] CLS token array shape: (1, 512)\n",
            "[PIXEL_0117] Raw sequence length: 55\n",
            "[PIXEL_0117] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0117] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0117] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0117] CLS token array shape: (1, 512)\n",
            "[PIXEL_0118] Raw sequence length: 41\n",
            "[PIXEL_0118] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0118] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0118] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0118] CLS token array shape: (1, 512)\n",
            "[PIXEL_0119] Raw sequence length: 49\n",
            "[PIXEL_0119] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0119] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0119] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0119] CLS token array shape: (1, 512)\n",
            "[PIXEL_0120] Raw sequence length: 52\n",
            "[PIXEL_0120] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0120] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0120] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0120] CLS token array shape: (1, 512)\n",
            "[PIXEL_0121] Raw sequence length: 44\n",
            "[PIXEL_0121] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0121] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0121] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0121] CLS token array shape: (1, 512)\n",
            "[PIXEL_0122] Raw sequence length: 56\n",
            "[PIXEL_0122] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0122] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0122] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0122] CLS token array shape: (1, 512)\n",
            "[PIXEL_0123] Raw sequence length: 117\n",
            "[PIXEL_0123] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0123] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0123] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0123] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0123] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0123] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0123] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0123] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0123] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0123] CLS token array shape: (3, 512)\n",
            "[PIXEL_0124] Raw sequence length: 56\n",
            "[PIXEL_0124] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0124] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0124] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0124] CLS token array shape: (1, 512)\n",
            "[PIXEL_0125] Raw sequence length: 112\n",
            "[PIXEL_0125] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0125] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0125] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0125] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0125] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0125] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0125] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0125] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0125] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0125] CLS token array shape: (3, 512)\n",
            "[PIXEL_0126] Raw sequence length: 54\n",
            "[PIXEL_0126] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0126] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0126] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0126] CLS token array shape: (1, 512)\n",
            "[PIXEL_0127] Raw sequence length: 53\n",
            "[PIXEL_0127] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0127] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0127] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0127] CLS token array shape: (1, 512)\n",
            "[PIXEL_0128] Raw sequence length: 51\n",
            "[PIXEL_0128] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0128] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0128] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0128] CLS token array shape: (1, 512)\n",
            "[PIXEL_0129] Raw sequence length: 57\n",
            "[PIXEL_0129] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0129] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0129] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0129] CLS token array shape: (1, 512)\n",
            "[PIXEL_0130] Raw sequence length: 59\n",
            "[PIXEL_0130] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0130] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0130] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0130] CLS token array shape: (1, 512)\n",
            "[PIXEL_0131] Raw sequence length: 52\n",
            "[PIXEL_0131] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0131] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0131] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0131] CLS token array shape: (1, 512)\n",
            "[PIXEL_0132] Raw sequence length: 52\n",
            "[PIXEL_0132] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0132] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0132] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0132] CLS token array shape: (1, 512)\n",
            "[PIXEL_0133] Raw sequence length: 104\n",
            "[PIXEL_0133] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0133] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0133] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0133] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0133] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0133] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0133] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0133] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0133] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0133] CLS token array shape: (3, 512)\n",
            "[PIXEL_0134] Raw sequence length: 52\n",
            "[PIXEL_0134] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0134] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0134] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0134] CLS token array shape: (1, 512)\n",
            "[PIXEL_0135] Raw sequence length: 98\n",
            "[PIXEL_0135] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0135] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0135] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0135] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0135] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0135] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0135] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0135] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0135] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0135] CLS token array shape: (3, 512)\n",
            "[PIXEL_0136] Raw sequence length: 108\n",
            "[PIXEL_0136] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0136] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0136] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0136] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0136] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0136] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0136] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0136] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0136] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0136] CLS token array shape: (3, 512)\n",
            "[PIXEL_0137] Raw sequence length: 111\n",
            "[PIXEL_0137] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0137] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0137] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0137] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0137] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0137] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0137] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0137] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0137] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0137] CLS token array shape: (3, 512)\n",
            "[PIXEL_0138] Raw sequence length: 49\n",
            "[PIXEL_0138] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0138] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0138] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0138] CLS token array shape: (1, 512)\n",
            "[PIXEL_0139] Raw sequence length: 50\n",
            "[PIXEL_0139] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0139] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0139] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0139] CLS token array shape: (1, 512)\n",
            "[PIXEL_0140] Raw sequence length: 52\n",
            "[PIXEL_0140] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0140] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0140] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0140] CLS token array shape: (1, 512)\n",
            "[PIXEL_0141] Raw sequence length: 47\n",
            "[PIXEL_0141] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0141] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0141] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0141] CLS token array shape: (1, 512)\n",
            "[PIXEL_0142] Raw sequence length: 48\n",
            "[PIXEL_0142] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0142] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0142] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0142] CLS token array shape: (1, 512)\n",
            "[PIXEL_0143] Raw sequence length: 50\n",
            "[PIXEL_0143] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0143] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0143] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0143] CLS token array shape: (1, 512)\n",
            "[PIXEL_0144] Raw sequence length: 49\n",
            "[PIXEL_0144] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0144] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0144] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0144] CLS token array shape: (1, 512)\n",
            "[PIXEL_0145] Raw sequence length: 45\n",
            "[PIXEL_0145] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0145] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0145] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0145] CLS token array shape: (1, 512)\n",
            "[PIXEL_0146] Raw sequence length: 52\n",
            "[PIXEL_0146] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0146] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0146] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0146] CLS token array shape: (1, 512)\n",
            "[PIXEL_0147] Raw sequence length: 50\n",
            "[PIXEL_0147] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0147] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0147] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0147] CLS token array shape: (1, 512)\n",
            "[PIXEL_0148] Raw sequence length: 48\n",
            "[PIXEL_0148] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0148] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0148] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0148] CLS token array shape: (1, 512)\n",
            "[PIXEL_0149] Raw sequence length: 115\n",
            "[PIXEL_0149] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0149] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0149] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0149] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0149] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0149] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0149] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0149] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0149] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0149] CLS token array shape: (3, 512)\n",
            "[PIXEL_0150] Raw sequence length: 100\n",
            "[PIXEL_0150] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0150] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0150] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0150] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0150] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0150] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0150] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0150] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0150] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0150] CLS token array shape: (3, 512)\n",
            "[PIXEL_0151] Raw sequence length: 112\n",
            "[PIXEL_0151] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0151] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0151] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0151] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0151] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0151] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0151] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0151] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0151] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0151] CLS token array shape: (3, 512)\n",
            "[PIXEL_0152] Raw sequence length: 59\n",
            "[PIXEL_0152] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0152] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0152] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0152] CLS token array shape: (1, 512)\n",
            "[PIXEL_0153] Raw sequence length: 53\n",
            "[PIXEL_0153] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0153] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0153] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0153] CLS token array shape: (1, 512)\n",
            "[PIXEL_0154] Raw sequence length: 51\n",
            "[PIXEL_0154] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0154] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0154] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0154] CLS token array shape: (1, 512)\n",
            "[PIXEL_0155] Raw sequence length: 57\n",
            "[PIXEL_0155] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0155] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0155] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0155] CLS token array shape: (1, 512)\n",
            "[PIXEL_0156] Raw sequence length: 103\n",
            "[PIXEL_0156] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0156] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0156] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0156] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0156] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0156] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0156] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0156] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0156] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0156] CLS token array shape: (3, 512)\n",
            "[PIXEL_0157] Raw sequence length: 49\n",
            "[PIXEL_0157] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0157] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0157] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0157] CLS token array shape: (1, 512)\n",
            "[PIXEL_0158] Raw sequence length: 51\n",
            "[PIXEL_0158] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0158] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0158] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0158] CLS token array shape: (1, 512)\n",
            "[PIXEL_0159] Raw sequence length: 31\n",
            "[PIXEL_0159] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0159] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0159] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0159] CLS token array shape: (1, 512)\n",
            "[PIXEL_0160] Raw sequence length: 50\n",
            "[PIXEL_0160] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0160] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0160] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0160] CLS token array shape: (1, 512)\n",
            "[PIXEL_0161] Raw sequence length: 52\n",
            "[PIXEL_0161] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0161] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0161] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0161] CLS token array shape: (1, 512)\n",
            "[PIXEL_0162] Raw sequence length: 51\n",
            "[PIXEL_0162] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0162] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0162] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0162] CLS token array shape: (1, 512)\n",
            "[PIXEL_0163] Raw sequence length: 53\n",
            "[PIXEL_0163] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0163] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0163] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0163] CLS token array shape: (1, 512)\n",
            "[PIXEL_0164] Raw sequence length: 50\n",
            "[PIXEL_0164] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0164] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0164] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0164] CLS token array shape: (1, 512)\n",
            "[PIXEL_0165] Raw sequence length: 57\n",
            "[PIXEL_0165] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0165] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0165] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0165] CLS token array shape: (1, 512)\n",
            "[PIXEL_0166] Raw sequence length: 50\n",
            "[PIXEL_0166] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0166] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0166] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0166] CLS token array shape: (1, 512)\n",
            "[PIXEL_0167] Raw sequence length: 60\n",
            "[PIXEL_0167] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0167] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0167] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0167] CLS token array shape: (1, 512)\n",
            "[PIXEL_0168] Raw sequence length: 49\n",
            "[PIXEL_0168] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0168] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0168] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0168] CLS token array shape: (1, 512)\n",
            "[PIXEL_0169] Raw sequence length: 45\n",
            "[PIXEL_0169] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0169] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0169] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0169] CLS token array shape: (1, 512)\n",
            "[PIXEL_0170] Raw sequence length: 51\n",
            "[PIXEL_0170] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0170] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0170] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0170] CLS token array shape: (1, 512)\n",
            "[PIXEL_0171] Raw sequence length: 110\n",
            "[PIXEL_0171] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0171] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0171] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0171] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0171] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0171] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0171] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0171] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0171] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0171] CLS token array shape: (3, 512)\n",
            "[PIXEL_0172] Raw sequence length: 46\n",
            "[PIXEL_0172] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0172] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0172] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0172] CLS token array shape: (1, 512)\n",
            "[PIXEL_0173] Raw sequence length: 56\n",
            "[PIXEL_0173] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0173] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0173] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0173] CLS token array shape: (1, 512)\n",
            "[PIXEL_0174] Raw sequence length: 52\n",
            "[PIXEL_0174] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0174] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0174] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0174] CLS token array shape: (1, 512)\n",
            "[PIXEL_0175] Raw sequence length: 59\n",
            "[PIXEL_0175] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0175] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0175] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0175] CLS token array shape: (1, 512)\n",
            "[PIXEL_0176] Raw sequence length: 52\n",
            "[PIXEL_0176] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0176] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0176] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0176] CLS token array shape: (1, 512)\n",
            "[PIXEL_0177] Raw sequence length: 48\n",
            "[PIXEL_0177] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0177] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0177] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0177] CLS token array shape: (1, 512)\n",
            "[PIXEL_0178] Raw sequence length: 45\n",
            "[PIXEL_0178] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0178] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0178] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0178] CLS token array shape: (1, 512)\n",
            "[PIXEL_0179] Raw sequence length: 58\n",
            "[PIXEL_0179] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0179] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0179] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0179] CLS token array shape: (1, 512)\n",
            "[PIXEL_0180] Raw sequence length: 47\n",
            "[PIXEL_0180] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0180] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0180] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0180] CLS token array shape: (1, 512)\n",
            "[PIXEL_0181] Raw sequence length: 61\n",
            "[PIXEL_0181] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0181] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0181] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0181] CLS token array shape: (1, 512)\n",
            "[PIXEL_0182] Raw sequence length: 51\n",
            "[PIXEL_0182] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0182] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0182] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0182] CLS token array shape: (1, 512)\n",
            "[PIXEL_0183] Raw sequence length: 61\n",
            "[PIXEL_0183] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0183] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0183] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0183] CLS token array shape: (1, 512)\n",
            "[PIXEL_0184] Raw sequence length: 50\n",
            "[PIXEL_0184] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0184] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0184] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0184] CLS token array shape: (1, 512)\n",
            "[PIXEL_0185] Raw sequence length: 47\n",
            "[PIXEL_0185] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0185] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0185] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0185] CLS token array shape: (1, 512)\n",
            "[PIXEL_0186] Raw sequence length: 109\n",
            "[PIXEL_0186] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0186] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0186] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0186] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0186] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0186] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0186] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0186] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0186] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0186] CLS token array shape: (3, 512)\n",
            "[PIXEL_0187] Raw sequence length: 57\n",
            "[PIXEL_0187] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0187] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0187] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0187] CLS token array shape: (1, 512)\n",
            "[PIXEL_0188] Raw sequence length: 101\n",
            "[PIXEL_0188] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0188] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0188] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0188] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0188] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0188] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0188] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0188] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0188] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0188] CLS token array shape: (3, 512)\n",
            "[PIXEL_0189] Raw sequence length: 41\n",
            "[PIXEL_0189] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0189] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0189] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0189] CLS token array shape: (1, 512)\n",
            "[PIXEL_0190] Raw sequence length: 53\n",
            "[PIXEL_0190] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0190] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0190] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0190] CLS token array shape: (1, 512)\n",
            "[PIXEL_0191] Raw sequence length: 48\n",
            "[PIXEL_0191] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0191] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0191] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0191] CLS token array shape: (1, 512)\n",
            "[PIXEL_0192] Raw sequence length: 61\n",
            "[PIXEL_0192] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0192] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0192] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0192] CLS token array shape: (1, 512)\n",
            "[PIXEL_0193] Raw sequence length: 52\n",
            "[PIXEL_0193] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0193] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0193] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0193] CLS token array shape: (1, 512)\n",
            "[PIXEL_0194] Raw sequence length: 57\n",
            "[PIXEL_0194] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0194] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0194] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0194] CLS token array shape: (1, 512)\n",
            "[PIXEL_0195] Raw sequence length: 49\n",
            "[PIXEL_0195] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0195] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0195] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0195] CLS token array shape: (1, 512)\n",
            "[PIXEL_0196] Raw sequence length: 54\n",
            "[PIXEL_0196] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0196] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0196] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0196] CLS token array shape: (1, 512)\n",
            "[PIXEL_0197] Raw sequence length: 111\n",
            "[PIXEL_0197] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0197] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0197] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0197] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0197] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0197] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0197] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0197] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0197] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0197] CLS token array shape: (3, 512)\n",
            "[PIXEL_0198] Raw sequence length: 119\n",
            "[PIXEL_0198] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0198] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0198] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0198] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0198] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0198] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0198] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0198] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0198] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0198] CLS token array shape: (3, 512)\n",
            "[PIXEL_0199] Raw sequence length: 57\n",
            "[PIXEL_0199] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0199] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0199] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0199] CLS token array shape: (1, 512)\n",
            "[PIXEL_0200] Raw sequence length: 113\n",
            "[PIXEL_0200] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0200] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0200] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0200] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0200] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0200] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0200] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0200] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0200] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0200] CLS token array shape: (3, 512)\n",
            "[PIXEL_0201] Raw sequence length: 50\n",
            "[PIXEL_0201] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0201] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0201] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0201] CLS token array shape: (1, 512)\n",
            "[PIXEL_0202] Raw sequence length: 46\n",
            "[PIXEL_0202] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0202] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0202] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0202] CLS token array shape: (1, 512)\n",
            "[PIXEL_0203] Raw sequence length: 51\n",
            "[PIXEL_0203] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0203] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0203] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0203] CLS token array shape: (1, 512)\n",
            "[PIXEL_0204] Raw sequence length: 49\n",
            "[PIXEL_0204] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0204] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0204] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0204] CLS token array shape: (1, 512)\n",
            "[PIXEL_0205] Raw sequence length: 49\n",
            "[PIXEL_0205] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0205] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0205] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0205] CLS token array shape: (1, 512)\n",
            "[PIXEL_0206] Raw sequence length: 57\n",
            "[PIXEL_0206] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0206] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0206] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0206] CLS token array shape: (1, 512)\n",
            "[PIXEL_0207] Raw sequence length: 58\n",
            "[PIXEL_0207] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0207] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0207] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0207] CLS token array shape: (1, 512)\n",
            "[PIXEL_0208] Raw sequence length: 53\n",
            "[PIXEL_0208] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0208] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0208] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0208] CLS token array shape: (1, 512)\n",
            "[PIXEL_0209] Raw sequence length: 54\n",
            "[PIXEL_0209] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0209] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0209] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0209] CLS token array shape: (1, 512)\n",
            "[PIXEL_0210] Raw sequence length: 53\n",
            "[PIXEL_0210] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0210] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0210] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0210] CLS token array shape: (1, 512)\n",
            "[PIXEL_0211] Raw sequence length: 50\n",
            "[PIXEL_0211] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0211] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0211] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0211] CLS token array shape: (1, 512)\n",
            "[PIXEL_0212] Raw sequence length: 52\n",
            "[PIXEL_0212] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0212] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0212] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0212] CLS token array shape: (1, 512)\n",
            "[PIXEL_0213] Raw sequence length: 51\n",
            "[PIXEL_0213] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0213] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0213] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0213] CLS token array shape: (1, 512)\n",
            "[PIXEL_0214] Raw sequence length: 53\n",
            "[PIXEL_0214] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0214] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0214] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0214] CLS token array shape: (1, 512)\n",
            "[PIXEL_0215] Raw sequence length: 54\n",
            "[PIXEL_0215] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0215] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0215] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0215] CLS token array shape: (1, 512)\n",
            "[PIXEL_0216] Raw sequence length: 53\n",
            "[PIXEL_0216] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0216] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0216] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0216] CLS token array shape: (1, 512)\n",
            "[PIXEL_0217] Raw sequence length: 54\n",
            "[PIXEL_0217] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0217] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0217] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0217] CLS token array shape: (1, 512)\n",
            "[PIXEL_0218] Raw sequence length: 36\n",
            "[PIXEL_0218] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0218] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0218] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0218] CLS token array shape: (1, 512)\n",
            "[PIXEL_0219] Raw sequence length: 50\n",
            "[PIXEL_0219] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0219] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0219] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0219] CLS token array shape: (1, 512)\n",
            "[PIXEL_0220] Raw sequence length: 108\n",
            "[PIXEL_0220] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0220] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0220] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0220] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0220] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0220] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0220] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0220] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0220] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0220] CLS token array shape: (3, 512)\n",
            "[PIXEL_0221] Raw sequence length: 56\n",
            "[PIXEL_0221] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0221] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0221] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0221] CLS token array shape: (1, 512)\n",
            "[PIXEL_0222] Raw sequence length: 113\n",
            "[PIXEL_0222] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0222] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0222] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0222] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0222] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0222] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0222] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0222] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0222] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0222] CLS token array shape: (3, 512)\n",
            "[PIXEL_0223] Raw sequence length: 52\n",
            "[PIXEL_0223] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0223] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0223] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0223] CLS token array shape: (1, 512)\n",
            "[PIXEL_0224] Raw sequence length: 52\n",
            "[PIXEL_0224] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0224] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0224] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0224] CLS token array shape: (1, 512)\n",
            "[PIXEL_0225] Raw sequence length: 59\n",
            "[PIXEL_0225] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0225] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0225] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0225] CLS token array shape: (1, 512)\n",
            "[PIXEL_0226] Raw sequence length: 56\n",
            "[PIXEL_0226] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0226] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0226] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0226] CLS token array shape: (1, 512)\n",
            "[PIXEL_0227] Raw sequence length: 108\n",
            "[PIXEL_0227] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0227] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0227] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0227] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0227] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0227] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0227] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0227] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0227] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0227] CLS token array shape: (3, 512)\n",
            "[PIXEL_0228] Raw sequence length: 53\n",
            "[PIXEL_0228] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0228] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0228] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0228] CLS token array shape: (1, 512)\n",
            "[PIXEL_0229] Raw sequence length: 52\n",
            "[PIXEL_0229] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0229] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0229] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0229] CLS token array shape: (1, 512)\n",
            "[PIXEL_0230] Raw sequence length: 54\n",
            "[PIXEL_0230] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0230] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0230] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0230] CLS token array shape: (1, 512)\n",
            "[PIXEL_0231] Raw sequence length: 48\n",
            "[PIXEL_0231] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0231] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0231] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0231] CLS token array shape: (1, 512)\n",
            "[PIXEL_0232] Raw sequence length: 47\n",
            "[PIXEL_0232] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0232] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0232] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0232] CLS token array shape: (1, 512)\n",
            "[PIXEL_0233] Raw sequence length: 54\n",
            "[PIXEL_0233] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0233] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0233] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0233] CLS token array shape: (1, 512)\n",
            "[PIXEL_0234] Raw sequence length: 55\n",
            "[PIXEL_0234] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0234] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0234] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0234] CLS token array shape: (1, 512)\n",
            "[PIXEL_0235] Raw sequence length: 47\n",
            "[PIXEL_0235] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0235] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0235] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0235] CLS token array shape: (1, 512)\n",
            "[PIXEL_0236] Raw sequence length: 48\n",
            "[PIXEL_0236] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0236] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0236] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0236] CLS token array shape: (1, 512)\n",
            "[PIXEL_0237] Raw sequence length: 50\n",
            "[PIXEL_0237] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0237] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0237] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0237] CLS token array shape: (1, 512)\n",
            "[PIXEL_0238] Raw sequence length: 54\n",
            "[PIXEL_0238] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0238] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0238] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0238] CLS token array shape: (1, 512)\n",
            "[PIXEL_0239] Raw sequence length: 47\n",
            "[PIXEL_0239] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0239] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0239] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0239] CLS token array shape: (1, 512)\n",
            "[PIXEL_0240] Raw sequence length: 45\n",
            "[PIXEL_0240] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0240] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0240] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0240] CLS token array shape: (1, 512)\n",
            "[PIXEL_0241] Raw sequence length: 60\n",
            "[PIXEL_0241] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0241] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0241] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0241] CLS token array shape: (1, 512)\n",
            "[PIXEL_0242] Raw sequence length: 113\n",
            "[PIXEL_0242] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0242] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0242] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0242] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0242] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0242] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0242] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0242] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0242] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0242] CLS token array shape: (3, 512)\n",
            "[PIXEL_0243] Raw sequence length: 47\n",
            "[PIXEL_0243] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0243] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0243] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0243] CLS token array shape: (1, 512)\n",
            "[PIXEL_0244] Raw sequence length: 42\n",
            "[PIXEL_0244] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0244] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0244] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0244] CLS token array shape: (1, 512)\n",
            "[PIXEL_0245] Raw sequence length: 52\n",
            "[PIXEL_0245] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0245] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0245] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0245] CLS token array shape: (1, 512)\n",
            "[PIXEL_0246] Raw sequence length: 43\n",
            "[PIXEL_0246] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0246] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0246] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0246] CLS token array shape: (1, 512)\n",
            "[PIXEL_0247] Raw sequence length: 57\n",
            "[PIXEL_0247] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0247] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0247] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0247] CLS token array shape: (1, 512)\n",
            "[PIXEL_0248] Raw sequence length: 51\n",
            "[PIXEL_0248] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0248] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0248] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0248] CLS token array shape: (1, 512)\n",
            "[PIXEL_0249] Raw sequence length: 108\n",
            "[PIXEL_0249] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0249] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0249] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0249] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0249] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0249] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0249] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0249] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0249] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0249] CLS token array shape: (3, 512)\n",
            "[PIXEL_0250] Raw sequence length: 46\n",
            "[PIXEL_0250] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0250] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0250] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0250] CLS token array shape: (1, 512)\n",
            "[PIXEL_0251] Raw sequence length: 120\n",
            "[PIXEL_0251] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0251] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0251] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0251] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0251] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0251] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0251] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0251] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0251] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0251] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0251] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0251] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0251] CLS token array shape: (4, 512)\n",
            "[PIXEL_0252] Raw sequence length: 55\n",
            "[PIXEL_0252] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0252] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0252] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0252] CLS token array shape: (1, 512)\n",
            "[PIXEL_0253] Raw sequence length: 48\n",
            "[PIXEL_0253] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0253] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0253] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0253] CLS token array shape: (1, 512)\n",
            "[PIXEL_0254] Raw sequence length: 41\n",
            "[PIXEL_0254] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0254] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0254] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0254] CLS token array shape: (1, 512)\n",
            "[PIXEL_0255] Raw sequence length: 51\n",
            "[PIXEL_0255] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0255] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0255] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0255] CLS token array shape: (1, 512)\n",
            "[PIXEL_0256] Raw sequence length: 52\n",
            "[PIXEL_0256] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0256] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0256] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0256] CLS token array shape: (1, 512)\n",
            "[PIXEL_0257] Raw sequence length: 48\n",
            "[PIXEL_0257] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0257] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0257] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0257] CLS token array shape: (1, 512)\n",
            "[PIXEL_0258] Raw sequence length: 53\n",
            "[PIXEL_0258] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0258] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0258] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0258] CLS token array shape: (1, 512)\n",
            "[PIXEL_0259] Raw sequence length: 50\n",
            "[PIXEL_0259] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0259] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0259] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0259] CLS token array shape: (1, 512)\n",
            "[PIXEL_0260] Raw sequence length: 45\n",
            "[PIXEL_0260] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0260] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0260] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0260] CLS token array shape: (1, 512)\n",
            "[PIXEL_0261] Raw sequence length: 58\n",
            "[PIXEL_0261] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0261] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0261] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0261] CLS token array shape: (1, 512)\n",
            "[PIXEL_0262] Raw sequence length: 53\n",
            "[PIXEL_0262] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0262] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0262] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0262] CLS token array shape: (1, 512)\n",
            "[PIXEL_0263] Raw sequence length: 45\n",
            "[PIXEL_0263] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0263] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0263] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0263] CLS token array shape: (1, 512)\n",
            "[PIXEL_0264] Raw sequence length: 50\n",
            "[PIXEL_0264] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0264] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0264] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0264] CLS token array shape: (1, 512)\n",
            "[PIXEL_0265] Raw sequence length: 41\n",
            "[PIXEL_0265] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0265] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0265] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0265] CLS token array shape: (1, 512)\n",
            "[PIXEL_0266] Raw sequence length: 60\n",
            "[PIXEL_0266] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0266] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0266] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0266] CLS token array shape: (1, 512)\n",
            "[PIXEL_0267] Raw sequence length: 50\n",
            "[PIXEL_0267] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0267] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0267] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0267] CLS token array shape: (1, 512)\n",
            "[PIXEL_0268] Raw sequence length: 49\n",
            "[PIXEL_0268] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0268] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0268] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0268] CLS token array shape: (1, 512)\n",
            "[PIXEL_0269] Raw sequence length: 54\n",
            "[PIXEL_0269] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0269] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0269] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0269] CLS token array shape: (1, 512)\n",
            "[PIXEL_0270] Raw sequence length: 57\n",
            "[PIXEL_0270] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0270] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0270] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0270] CLS token array shape: (1, 512)\n",
            "[PIXEL_0271] Raw sequence length: 48\n",
            "[PIXEL_0271] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0271] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0271] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0271] CLS token array shape: (1, 512)\n",
            "[PIXEL_0272] Raw sequence length: 48\n",
            "[PIXEL_0272] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0272] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0272] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0272] CLS token array shape: (1, 512)\n",
            "[PIXEL_0273] Raw sequence length: 52\n",
            "[PIXEL_0273] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0273] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0273] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0273] CLS token array shape: (1, 512)\n",
            "[PIXEL_0274] Raw sequence length: 51\n",
            "[PIXEL_0274] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0274] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0274] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0274] CLS token array shape: (1, 512)\n",
            "[PIXEL_0275] Raw sequence length: 49\n",
            "[PIXEL_0275] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0275] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0275] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0275] CLS token array shape: (1, 512)\n",
            "[PIXEL_0276] Raw sequence length: 91\n",
            "[PIXEL_0276] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0276] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0276] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0276] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0276] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0276] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0276] CLS token array shape: (2, 512)\n",
            "[PIXEL_0277] Raw sequence length: 54\n",
            "[PIXEL_0277] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0277] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0277] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0277] CLS token array shape: (1, 512)\n",
            "[PIXEL_0278] Raw sequence length: 50\n",
            "[PIXEL_0278] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0278] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0278] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0278] CLS token array shape: (1, 512)\n",
            "[PIXEL_0279] Raw sequence length: 53\n",
            "[PIXEL_0279] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0279] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0279] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0279] CLS token array shape: (1, 512)\n",
            "[PIXEL_0280] Raw sequence length: 59\n",
            "[PIXEL_0280] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0280] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0280] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0280] CLS token array shape: (1, 512)\n",
            "[PIXEL_0281] Raw sequence length: 56\n",
            "[PIXEL_0281] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0281] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0281] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0281] CLS token array shape: (1, 512)\n",
            "[PIXEL_0282] Raw sequence length: 111\n",
            "[PIXEL_0282] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0282] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0282] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0282] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0282] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0282] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0282] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0282] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0282] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0282] CLS token array shape: (3, 512)\n",
            "[PIXEL_0283] Raw sequence length: 61\n",
            "[PIXEL_0283] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0283] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0283] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0283] CLS token array shape: (1, 512)\n",
            "[PIXEL_0284] Raw sequence length: 48\n",
            "[PIXEL_0284] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0284] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0284] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0284] CLS token array shape: (1, 512)\n",
            "[PIXEL_0285] Raw sequence length: 51\n",
            "[PIXEL_0285] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0285] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0285] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0285] CLS token array shape: (1, 512)\n",
            "[PIXEL_0286] Raw sequence length: 105\n",
            "[PIXEL_0286] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0286] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0286] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0286] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0286] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0286] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0286] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0286] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0286] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0286] CLS token array shape: (3, 512)\n",
            "[PIXEL_0287] Raw sequence length: 112\n",
            "[PIXEL_0287] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0287] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0287] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0287] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0287] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0287] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0287] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0287] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0287] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0287] CLS token array shape: (3, 512)\n",
            "[PIXEL_0288] Raw sequence length: 54\n",
            "[PIXEL_0288] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0288] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0288] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0288] CLS token array shape: (1, 512)\n",
            "[PIXEL_0289] Raw sequence length: 102\n",
            "[PIXEL_0289] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0289] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0289] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0289] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0289] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0289] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0289] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0289] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0289] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0289] CLS token array shape: (3, 512)\n",
            "[PIXEL_0290] Raw sequence length: 42\n",
            "[PIXEL_0290] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0290] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0290] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0290] CLS token array shape: (1, 512)\n",
            "[PIXEL_0291] Raw sequence length: 52\n",
            "[PIXEL_0291] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0291] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0291] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0291] CLS token array shape: (1, 512)\n",
            "[PIXEL_0292] Raw sequence length: 49\n",
            "[PIXEL_0292] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0292] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0292] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0292] CLS token array shape: (1, 512)\n",
            "[PIXEL_0293] Raw sequence length: 101\n",
            "[PIXEL_0293] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0293] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0293] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0293] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0293] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0293] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0293] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0293] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0293] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0293] CLS token array shape: (3, 512)\n",
            "[PIXEL_0294] Raw sequence length: 61\n",
            "[PIXEL_0294] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0294] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0294] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0294] CLS token array shape: (1, 512)\n",
            "[PIXEL_0295] Raw sequence length: 47\n",
            "[PIXEL_0295] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0295] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0295] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0295] CLS token array shape: (1, 512)\n",
            "[PIXEL_0296] Raw sequence length: 50\n",
            "[PIXEL_0296] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0296] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0296] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0296] CLS token array shape: (1, 512)\n",
            "[PIXEL_0297] Raw sequence length: 58\n",
            "[PIXEL_0297] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0297] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0297] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0297] CLS token array shape: (1, 512)\n",
            "[PIXEL_0298] Raw sequence length: 48\n",
            "[PIXEL_0298] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0298] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0298] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0298] CLS token array shape: (1, 512)\n",
            "[PIXEL_0299] Raw sequence length: 55\n",
            "[PIXEL_0299] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0299] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0299] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0299] CLS token array shape: (1, 512)\n",
            "[PIXEL_0300] Raw sequence length: 52\n",
            "[PIXEL_0300] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0300] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0300] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0300] CLS token array shape: (1, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls_embeddings_test = generate_embeddings_sliding_window(test_df, model, max_length=48, stride=24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfcsOGqZ7lJf",
        "outputId": "6ebf5800-3b8a-47ae-b478-75cb61794cf0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] CLS token array shape: (5, 512)\n",
            "[ID_YOH896] Raw sequence length: 80\n",
            "[ID_YOH896] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOH896] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOH896] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOH896] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOH896] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOH896] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOH896] CLS token array shape: (2, 512)\n",
            "[ID_YOJ4XB] Raw sequence length: 154\n",
            "[ID_YOJ4XB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] CLS token array shape: (5, 512)\n",
            "[ID_YOVR14] Raw sequence length: 79\n",
            "[ID_YOVR14] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOVR14] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOVR14] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOVR14] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOVR14] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOVR14] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOVR14] CLS token array shape: (2, 512)\n",
            "[ID_YP7FJ8] Raw sequence length: 79\n",
            "[ID_YP7FJ8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP7FJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP7FJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP7FJ8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP7FJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP7FJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP7FJ8] CLS token array shape: (2, 512)\n",
            "[ID_YP8EB8] Raw sequence length: 154\n",
            "[ID_YP8EB8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] CLS token array shape: (5, 512)\n",
            "[ID_YP9H9B] Raw sequence length: 144\n",
            "[ID_YP9H9B] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] CLS token array shape: (5, 512)\n",
            "[ID_YPCPC0] Raw sequence length: 80\n",
            "[ID_YPCPC0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPCPC0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPCPC0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPCPC0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPCPC0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPCPC0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPCPC0] CLS token array shape: (2, 512)\n",
            "[ID_YPG5B2] Raw sequence length: 79\n",
            "[ID_YPG5B2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPG5B2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPG5B2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPG5B2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPG5B2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPG5B2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPG5B2] CLS token array shape: (2, 512)\n",
            "[ID_YPJM6K] Raw sequence length: 80\n",
            "[ID_YPJM6K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPJM6K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPJM6K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPJM6K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPJM6K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPJM6K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPJM6K] CLS token array shape: (2, 512)\n",
            "[ID_YPQR34] Raw sequence length: 145\n",
            "[ID_YPQR34] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] CLS token array shape: (5, 512)\n",
            "[ID_YPR6IK] Raw sequence length: 74\n",
            "[ID_YPR6IK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPR6IK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPR6IK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPR6IK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPR6IK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPR6IK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPR6IK] CLS token array shape: (2, 512)\n",
            "[ID_YQ3LBT] Raw sequence length: 79\n",
            "[ID_YQ3LBT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ3LBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ3LBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ3LBT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ3LBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ3LBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ3LBT] CLS token array shape: (2, 512)\n",
            "[ID_YQ56PS] Raw sequence length: 292\n",
            "[ID_YQ56PS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] CLS token array shape: (11, 512)\n",
            "[ID_YQ5ETE] Raw sequence length: 146\n",
            "[ID_YQ5ETE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] CLS token array shape: (5, 512)\n",
            "[ID_YQ6M4Y] Raw sequence length: 129\n",
            "[ID_YQ6M4Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ6M4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ6M4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ6M4Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ6M4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ6M4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ6M4Y] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ6M4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ6M4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ6M4Y] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ6M4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ6M4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ6M4Y] CLS token array shape: (4, 512)\n",
            "[ID_YQ7GUH] Raw sequence length: 80\n",
            "[ID_YQ7GUH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ7GUH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ7GUH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ7GUH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ7GUH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ7GUH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ7GUH] CLS token array shape: (2, 512)\n",
            "[ID_YQCRGR] Raw sequence length: 145\n",
            "[ID_YQCRGR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] CLS token array shape: (5, 512)\n",
            "[ID_YQLZCV] Raw sequence length: 153\n",
            "[ID_YQLZCV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] CLS token array shape: (5, 512)\n",
            "[ID_YQMMOX] Raw sequence length: 146\n",
            "[ID_YQMMOX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] CLS token array shape: (5, 512)\n",
            "[ID_YQMYHH] Raw sequence length: 80\n",
            "[ID_YQMYHH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMYHH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMYHH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMYHH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMYHH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMYHH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMYHH] CLS token array shape: (2, 512)\n",
            "[ID_YQNLF2] Raw sequence length: 80\n",
            "[ID_YQNLF2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQNLF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQNLF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQNLF2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQNLF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQNLF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQNLF2] CLS token array shape: (2, 512)\n",
            "[ID_YQONXC] Raw sequence length: 80\n",
            "[ID_YQONXC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQONXC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQONXC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQONXC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQONXC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQONXC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQONXC] CLS token array shape: (2, 512)\n",
            "[ID_YQP70R] Raw sequence length: 292\n",
            "[ID_YQP70R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] CLS token array shape: (11, 512)\n",
            "[ID_YQTI49] Raw sequence length: 154\n",
            "[ID_YQTI49] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] CLS token array shape: (5, 512)\n",
            "[ID_YQWUBF] Raw sequence length: 80\n",
            "[ID_YQWUBF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQWUBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQWUBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQWUBF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQWUBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQWUBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQWUBF] CLS token array shape: (2, 512)\n",
            "[ID_YQY1KH] Raw sequence length: 80\n",
            "[ID_YQY1KH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY1KH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY1KH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY1KH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY1KH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY1KH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY1KH] CLS token array shape: (2, 512)\n",
            "[ID_YQY93B] Raw sequence length: 145\n",
            "[ID_YQY93B] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] CLS token array shape: (5, 512)\n",
            "[ID_YR0Y59] Raw sequence length: 80\n",
            "[ID_YR0Y59] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR0Y59] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR0Y59] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR0Y59] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR0Y59] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR0Y59] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR0Y59] CLS token array shape: (2, 512)\n",
            "[ID_YR2YNZ] Raw sequence length: 154\n",
            "[ID_YR2YNZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] CLS token array shape: (5, 512)\n",
            "[ID_YR9JMP] Raw sequence length: 80\n",
            "[ID_YR9JMP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR9JMP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR9JMP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR9JMP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR9JMP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR9JMP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR9JMP] CLS token array shape: (2, 512)\n",
            "[ID_YRC0ZS] Raw sequence length: 79\n",
            "[ID_YRC0ZS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRC0ZS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRC0ZS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRC0ZS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRC0ZS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRC0ZS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRC0ZS] CLS token array shape: (2, 512)\n",
            "[ID_YRPT7Y] Raw sequence length: 79\n",
            "[ID_YRPT7Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRPT7Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRPT7Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRPT7Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRPT7Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRPT7Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRPT7Y] CLS token array shape: (2, 512)\n",
            "[ID_YRR3I4] Raw sequence length: 74\n",
            "[ID_YRR3I4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRR3I4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRR3I4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRR3I4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRR3I4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRR3I4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRR3I4] CLS token array shape: (2, 512)\n",
            "[ID_YRVNFY] Raw sequence length: 129\n",
            "[ID_YRVNFY] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRVNFY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRVNFY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRVNFY] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRVNFY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRVNFY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRVNFY] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRVNFY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRVNFY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRVNFY] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRVNFY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRVNFY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRVNFY] CLS token array shape: (4, 512)\n",
            "[ID_YSFE2A] Raw sequence length: 80\n",
            "[ID_YSFE2A] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSFE2A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSFE2A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSFE2A] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSFE2A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSFE2A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSFE2A] CLS token array shape: (2, 512)\n",
            "[ID_YSH3D0] Raw sequence length: 79\n",
            "[ID_YSH3D0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSH3D0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSH3D0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSH3D0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSH3D0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSH3D0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSH3D0] CLS token array shape: (2, 512)\n",
            "[ID_YSU8UN] Raw sequence length: 79\n",
            "[ID_YSU8UN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSU8UN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSU8UN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSU8UN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSU8UN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSU8UN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSU8UN] CLS token array shape: (2, 512)\n",
            "[ID_YSWZ8C] Raw sequence length: 79\n",
            "[ID_YSWZ8C] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSWZ8C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSWZ8C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSWZ8C] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSWZ8C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSWZ8C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSWZ8C] CLS token array shape: (2, 512)\n",
            "[ID_YSYB21] Raw sequence length: 145\n",
            "[ID_YSYB21] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] CLS token array shape: (5, 512)\n",
            "[ID_YSYH7U] Raw sequence length: 148\n",
            "[ID_YSYH7U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] CLS token array shape: (5, 512)\n",
            "[ID_YT8OI2] Raw sequence length: 80\n",
            "[ID_YT8OI2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YT8OI2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YT8OI2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YT8OI2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YT8OI2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YT8OI2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YT8OI2] CLS token array shape: (2, 512)\n",
            "[ID_YTD703] Raw sequence length: 79\n",
            "[ID_YTD703] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTD703] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTD703] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTD703] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTD703] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTD703] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTD703] CLS token array shape: (2, 512)\n",
            "[ID_YTE997] Raw sequence length: 79\n",
            "[ID_YTE997] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTE997] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTE997] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTE997] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTE997] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTE997] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTE997] CLS token array shape: (2, 512)\n",
            "[ID_YTFG6G] Raw sequence length: 154\n",
            "[ID_YTFG6G] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] CLS token array shape: (5, 512)\n",
            "[ID_YTFOYC] Raw sequence length: 145\n",
            "[ID_YTFOYC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] CLS token array shape: (5, 512)\n",
            "[ID_YTGT9U] Raw sequence length: 74\n",
            "[ID_YTGT9U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTGT9U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTGT9U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTGT9U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTGT9U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTGT9U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTGT9U] CLS token array shape: (2, 512)\n",
            "[ID_YTIACC] Raw sequence length: 77\n",
            "[ID_YTIACC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTIACC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTIACC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTIACC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTIACC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTIACC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTIACC] CLS token array shape: (2, 512)\n",
            "[ID_YTJ7BX] Raw sequence length: 80\n",
            "[ID_YTJ7BX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTJ7BX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTJ7BX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTJ7BX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTJ7BX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTJ7BX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTJ7BX] CLS token array shape: (2, 512)\n",
            "[ID_YTOIQ7] Raw sequence length: 80\n",
            "[ID_YTOIQ7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTOIQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTOIQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTOIQ7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTOIQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTOIQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTOIQ7] CLS token array shape: (2, 512)\n",
            "[ID_YU0FMO] Raw sequence length: 80\n",
            "[ID_YU0FMO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU0FMO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU0FMO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU0FMO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU0FMO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU0FMO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU0FMO] CLS token array shape: (2, 512)\n",
            "[ID_YU2SBF] Raw sequence length: 129\n",
            "[ID_YU2SBF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU2SBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU2SBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU2SBF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU2SBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU2SBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU2SBF] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU2SBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU2SBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU2SBF] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU2SBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU2SBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU2SBF] CLS token array shape: (4, 512)\n",
            "[ID_YUB0MN] Raw sequence length: 80\n",
            "[ID_YUB0MN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUB0MN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUB0MN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUB0MN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUB0MN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUB0MN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUB0MN] CLS token array shape: (2, 512)\n",
            "[ID_YUBIZV] Raw sequence length: 220\n",
            "[ID_YUBIZV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] CLS token array shape: (8, 512)\n",
            "[ID_YUBTOY] Raw sequence length: 74\n",
            "[ID_YUBTOY] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBTOY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBTOY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBTOY] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBTOY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBTOY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBTOY] CLS token array shape: (2, 512)\n",
            "[ID_YUCAFX] Raw sequence length: 80\n",
            "[ID_YUCAFX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUCAFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUCAFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUCAFX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUCAFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUCAFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUCAFX] CLS token array shape: (2, 512)\n",
            "[ID_YULBY9] Raw sequence length: 80\n",
            "[ID_YULBY9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YULBY9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YULBY9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YULBY9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YULBY9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YULBY9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YULBY9] CLS token array shape: (2, 512)\n",
            "[ID_YUMOK6] Raw sequence length: 80\n",
            "[ID_YUMOK6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUMOK6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUMOK6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUMOK6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUMOK6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUMOK6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUMOK6] CLS token array shape: (2, 512)\n",
            "[ID_YVF78B] Raw sequence length: 80\n",
            "[ID_YVF78B] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVF78B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVF78B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVF78B] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVF78B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVF78B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVF78B] CLS token array shape: (2, 512)\n",
            "[ID_YVHAWQ] Raw sequence length: 146\n",
            "[ID_YVHAWQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] CLS token array shape: (5, 512)\n",
            "[ID_YVJD8B] Raw sequence length: 79\n",
            "[ID_YVJD8B] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVJD8B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVJD8B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVJD8B] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVJD8B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVJD8B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVJD8B] CLS token array shape: (2, 512)\n",
            "[ID_YVLS89] Raw sequence length: 80\n",
            "[ID_YVLS89] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVLS89] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVLS89] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVLS89] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVLS89] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVLS89] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVLS89] CLS token array shape: (2, 512)\n",
            "[ID_YVLVT6] Raw sequence length: 80\n",
            "[ID_YVLVT6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVLVT6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVLVT6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVLVT6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVLVT6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVLVT6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVLVT6] CLS token array shape: (2, 512)\n",
            "[ID_YVREWQ] Raw sequence length: 154\n",
            "[ID_YVREWQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] CLS token array shape: (5, 512)\n",
            "[ID_YVSNMF] Raw sequence length: 292\n",
            "[ID_YVSNMF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] CLS token array shape: (11, 512)\n",
            "[ID_YVVBZL] Raw sequence length: 80\n",
            "[ID_YVVBZL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVVBZL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVVBZL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVVBZL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVVBZL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVVBZL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVVBZL] CLS token array shape: (2, 512)\n",
            "[ID_YW64I4] Raw sequence length: 80\n",
            "[ID_YW64I4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YW64I4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YW64I4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YW64I4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YW64I4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YW64I4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YW64I4] CLS token array shape: (2, 512)\n",
            "[ID_YWFOAM] Raw sequence length: 146\n",
            "[ID_YWFOAM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] CLS token array shape: (5, 512)\n",
            "[ID_YWPQTW] Raw sequence length: 80\n",
            "[ID_YWPQTW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPQTW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPQTW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPQTW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPQTW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPQTW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPQTW] CLS token array shape: (2, 512)\n",
            "[ID_YWPZUL] Raw sequence length: 146\n",
            "[ID_YWPZUL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] CLS token array shape: (5, 512)\n",
            "[ID_YWQ3UT] Raw sequence length: 80\n",
            "[ID_YWQ3UT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWQ3UT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWQ3UT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWQ3UT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWQ3UT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWQ3UT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWQ3UT] CLS token array shape: (2, 512)\n",
            "[ID_YWSBVQ] Raw sequence length: 146\n",
            "[ID_YWSBVQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] CLS token array shape: (5, 512)\n",
            "[ID_YWU5GO] Raw sequence length: 145\n",
            "[ID_YWU5GO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] CLS token array shape: (5, 512)\n",
            "[ID_YX3BGD] Raw sequence length: 80\n",
            "[ID_YX3BGD] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YX3BGD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YX3BGD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YX3BGD] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YX3BGD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YX3BGD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YX3BGD] CLS token array shape: (2, 512)\n",
            "[ID_YXAWZM] Raw sequence length: 79\n",
            "[ID_YXAWZM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXAWZM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXAWZM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXAWZM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXAWZM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXAWZM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXAWZM] CLS token array shape: (2, 512)\n",
            "[ID_YXBJP8] Raw sequence length: 80\n",
            "[ID_YXBJP8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXBJP8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXBJP8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXBJP8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXBJP8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXBJP8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXBJP8] CLS token array shape: (2, 512)\n",
            "[ID_YXL2U8] Raw sequence length: 80\n",
            "[ID_YXL2U8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL2U8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL2U8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL2U8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL2U8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL2U8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL2U8] CLS token array shape: (2, 512)\n",
            "[ID_YXL3UW] Raw sequence length: 146\n",
            "[ID_YXL3UW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] CLS token array shape: (5, 512)\n",
            "[ID_YXQ731] Raw sequence length: 154\n",
            "[ID_YXQ731] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] CLS token array shape: (5, 512)\n",
            "[ID_YXUD84] Raw sequence length: 80\n",
            "[ID_YXUD84] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXUD84] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXUD84] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXUD84] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXUD84] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXUD84] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXUD84] CLS token array shape: (2, 512)\n",
            "[ID_YY3711] Raw sequence length: 74\n",
            "[ID_YY3711] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY3711] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY3711] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY3711] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY3711] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY3711] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY3711] CLS token array shape: (2, 512)\n",
            "[ID_YY5XNQ] Raw sequence length: 146\n",
            "[ID_YY5XNQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] CLS token array shape: (5, 512)\n",
            "[ID_YY7P4S] Raw sequence length: 80\n",
            "[ID_YY7P4S] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY7P4S] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY7P4S] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY7P4S] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY7P4S] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY7P4S] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY7P4S] CLS token array shape: (2, 512)\n",
            "[ID_YYA72I] Raw sequence length: 146\n",
            "[ID_YYA72I] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] CLS token array shape: (5, 512)\n",
            "[ID_YYB0YC] Raw sequence length: 146\n",
            "[ID_YYB0YC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] CLS token array shape: (5, 512)\n",
            "[ID_YYMNV9] Raw sequence length: 80\n",
            "[ID_YYMNV9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYMNV9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYMNV9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYMNV9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYMNV9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYMNV9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYMNV9] CLS token array shape: (2, 512)\n",
            "[ID_YYQ6FM] Raw sequence length: 78\n",
            "[ID_YYQ6FM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYQ6FM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYQ6FM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYQ6FM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYQ6FM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYQ6FM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYQ6FM] CLS token array shape: (2, 512)\n",
            "[ID_YYRORS] Raw sequence length: 80\n",
            "[ID_YYRORS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYRORS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYRORS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYRORS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYRORS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYRORS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYRORS] CLS token array shape: (2, 512)\n",
            "[ID_YYTMEQ] Raw sequence length: 80\n",
            "[ID_YYTMEQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYTMEQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYTMEQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYTMEQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYTMEQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYTMEQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYTMEQ] CLS token array shape: (2, 512)\n",
            "[ID_YYUZD8] Raw sequence length: 79\n",
            "[ID_YYUZD8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYUZD8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYUZD8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYUZD8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYUZD8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYUZD8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYUZD8] CLS token array shape: (2, 512)\n",
            "[ID_YYV2T4] Raw sequence length: 80\n",
            "[ID_YYV2T4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYV2T4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYV2T4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYV2T4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYV2T4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYV2T4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYV2T4] CLS token array shape: (2, 512)\n",
            "[ID_YYW3C1] Raw sequence length: 79\n",
            "[ID_YYW3C1] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYW3C1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYW3C1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYW3C1] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYW3C1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYW3C1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYW3C1] CLS token array shape: (2, 512)\n",
            "[ID_YZEZXQ] Raw sequence length: 146\n",
            "[ID_YZEZXQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] CLS token array shape: (5, 512)\n",
            "[ID_YZP0VO] Raw sequence length: 79\n",
            "[ID_YZP0VO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZP0VO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZP0VO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZP0VO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZP0VO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZP0VO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZP0VO] CLS token array shape: (2, 512)\n",
            "[ID_YZRQZQ] Raw sequence length: 154\n",
            "[ID_YZRQZQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] CLS token array shape: (5, 512)\n",
            "[ID_YZSI0I] Raw sequence length: 79\n",
            "[ID_YZSI0I] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZSI0I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZSI0I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZSI0I] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZSI0I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZSI0I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZSI0I] CLS token array shape: (2, 512)\n",
            "[ID_Z01LKJ] Raw sequence length: 145\n",
            "[ID_Z01LKJ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] CLS token array shape: (5, 512)\n",
            "[ID_Z0HRWF] Raw sequence length: 80\n",
            "[ID_Z0HRWF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0HRWF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0HRWF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0HRWF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0HRWF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0HRWF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0HRWF] CLS token array shape: (2, 512)\n",
            "[ID_Z0IT3R] Raw sequence length: 80\n",
            "[ID_Z0IT3R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0IT3R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0IT3R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0IT3R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0IT3R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0IT3R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0IT3R] CLS token array shape: (2, 512)\n",
            "[ID_Z0M7V2] Raw sequence length: 291\n",
            "[ID_Z0M7V2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] CLS token array shape: (11, 512)\n",
            "[ID_Z0MAFE] Raw sequence length: 74\n",
            "[ID_Z0MAFE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0MAFE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0MAFE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0MAFE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0MAFE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0MAFE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0MAFE] CLS token array shape: (2, 512)\n",
            "[ID_Z0O190] Raw sequence length: 80\n",
            "[ID_Z0O190] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0O190] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0O190] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0O190] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0O190] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0O190] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0O190] CLS token array shape: (2, 512)\n",
            "[ID_Z0P94M] Raw sequence length: 126\n",
            "[ID_Z0P94M] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0P94M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0P94M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0P94M] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0P94M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0P94M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0P94M] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0P94M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0P94M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0P94M] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0P94M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0P94M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0P94M] CLS token array shape: (4, 512)\n",
            "[ID_Z0R053] Raw sequence length: 154\n",
            "[ID_Z0R053] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] CLS token array shape: (5, 512)\n",
            "[ID_Z0TP71] Raw sequence length: 79\n",
            "[ID_Z0TP71] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0TP71] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0TP71] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0TP71] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0TP71] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0TP71] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0TP71] CLS token array shape: (2, 512)\n",
            "[ID_Z0XND2] Raw sequence length: 80\n",
            "[ID_Z0XND2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0XND2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0XND2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0XND2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0XND2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0XND2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0XND2] CLS token array shape: (2, 512)\n",
            "[ID_Z0Y4DL] Raw sequence length: 79\n",
            "[ID_Z0Y4DL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0Y4DL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0Y4DL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0Y4DL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0Y4DL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0Y4DL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0Y4DL] CLS token array shape: (2, 512)\n",
            "[ID_Z0ZJOB] Raw sequence length: 146\n",
            "[ID_Z0ZJOB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] CLS token array shape: (5, 512)\n",
            "[ID_Z1A2YU] Raw sequence length: 146\n",
            "[ID_Z1A2YU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] CLS token array shape: (5, 512)\n",
            "[ID_Z1FXRX] Raw sequence length: 159\n",
            "[ID_Z1FXRX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] CLS token array shape: (5, 512)\n",
            "[ID_Z1I75U] Raw sequence length: 80\n",
            "[ID_Z1I75U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1I75U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1I75U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1I75U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1I75U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1I75U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1I75U] CLS token array shape: (2, 512)\n",
            "[ID_Z1MI0A] Raw sequence length: 80\n",
            "[ID_Z1MI0A] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1MI0A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1MI0A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1MI0A] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1MI0A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1MI0A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1MI0A] CLS token array shape: (2, 512)\n",
            "[ID_Z1PF7L] Raw sequence length: 80\n",
            "[ID_Z1PF7L] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1PF7L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1PF7L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1PF7L] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1PF7L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1PF7L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1PF7L] CLS token array shape: (2, 512)\n",
            "[ID_Z23MT4] Raw sequence length: 80\n",
            "[ID_Z23MT4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z23MT4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z23MT4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z23MT4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z23MT4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z23MT4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z23MT4] CLS token array shape: (2, 512)\n",
            "[ID_Z24RIY] Raw sequence length: 80\n",
            "[ID_Z24RIY] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z24RIY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z24RIY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z24RIY] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z24RIY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z24RIY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z24RIY] CLS token array shape: (2, 512)\n",
            "[ID_Z29S2I] Raw sequence length: 145\n",
            "[ID_Z29S2I] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] CLS token array shape: (5, 512)\n",
            "[ID_Z2AN8X] Raw sequence length: 80\n",
            "[ID_Z2AN8X] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2AN8X] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2AN8X] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2AN8X] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2AN8X] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2AN8X] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2AN8X] CLS token array shape: (2, 512)\n",
            "[ID_Z2HS7V] Raw sequence length: 146\n",
            "[ID_Z2HS7V] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] CLS token array shape: (5, 512)\n",
            "[ID_Z2HYHG] Raw sequence length: 80\n",
            "[ID_Z2HYHG] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HYHG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HYHG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HYHG] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HYHG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HYHG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HYHG] CLS token array shape: (2, 512)\n",
            "[ID_Z2J82F] Raw sequence length: 146\n",
            "[ID_Z2J82F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] CLS token array shape: (5, 512)\n",
            "[ID_Z2X8BK] Raw sequence length: 291\n",
            "[ID_Z2X8BK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] CLS token array shape: (11, 512)\n",
            "[ID_Z338MU] Raw sequence length: 80\n",
            "[ID_Z338MU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z338MU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z338MU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z338MU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z338MU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z338MU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z338MU] CLS token array shape: (2, 512)\n",
            "[ID_Z39YGK] Raw sequence length: 129\n",
            "[ID_Z39YGK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z39YGK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z39YGK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z39YGK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z39YGK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z39YGK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z39YGK] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z39YGK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z39YGK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z39YGK] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z39YGK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z39YGK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z39YGK] CLS token array shape: (4, 512)\n",
            "[ID_Z3O3Z7] Raw sequence length: 145\n",
            "[ID_Z3O3Z7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] CLS token array shape: (5, 512)\n",
            "[ID_Z3XOA5] Raw sequence length: 77\n",
            "[ID_Z3XOA5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3XOA5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3XOA5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3XOA5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3XOA5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3XOA5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3XOA5] CLS token array shape: (2, 512)\n",
            "[ID_Z3YI97] Raw sequence length: 80\n",
            "[ID_Z3YI97] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3YI97] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3YI97] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3YI97] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3YI97] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3YI97] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3YI97] CLS token array shape: (2, 512)\n",
            "[ID_Z44FNL] Raw sequence length: 291\n",
            "[ID_Z44FNL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] CLS token array shape: (11, 512)\n",
            "[ID_Z49DFD] Raw sequence length: 79\n",
            "[ID_Z49DFD] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z49DFD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z49DFD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z49DFD] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z49DFD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z49DFD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z49DFD] CLS token array shape: (2, 512)\n",
            "[ID_Z4GP7F] Raw sequence length: 154\n",
            "[ID_Z4GP7F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] CLS token array shape: (5, 512)\n",
            "[ID_Z4HNQ7] Raw sequence length: 154\n",
            "[ID_Z4HNQ7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] CLS token array shape: (5, 512)\n",
            "[ID_Z4J06N] Raw sequence length: 80\n",
            "[ID_Z4J06N] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4J06N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4J06N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4J06N] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4J06N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4J06N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4J06N] CLS token array shape: (2, 512)\n",
            "[ID_Z4P56Y] Raw sequence length: 146\n",
            "[ID_Z4P56Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] CLS token array shape: (5, 512)\n",
            "[ID_Z4POMD] Raw sequence length: 80\n",
            "[ID_Z4POMD] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4POMD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4POMD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4POMD] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4POMD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4POMD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4POMD] CLS token array shape: (2, 512)\n",
            "[ID_Z50CA4] Raw sequence length: 147\n",
            "[ID_Z50CA4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] CLS token array shape: (5, 512)\n",
            "[ID_Z537AC] Raw sequence length: 146\n",
            "[ID_Z537AC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] CLS token array shape: (5, 512)\n",
            "[ID_Z55RRH] Raw sequence length: 146\n",
            "[ID_Z55RRH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] CLS token array shape: (5, 512)\n",
            "[ID_Z5AM0O] Raw sequence length: 79\n",
            "[ID_Z5AM0O] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5AM0O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5AM0O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5AM0O] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5AM0O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5AM0O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5AM0O] CLS token array shape: (2, 512)\n",
            "[ID_Z5EFFX] Raw sequence length: 173\n",
            "[ID_Z5EFFX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] CLS token array shape: (6, 512)\n",
            "[ID_Z5GJ9F] Raw sequence length: 80\n",
            "[ID_Z5GJ9F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5GJ9F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5GJ9F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5GJ9F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5GJ9F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5GJ9F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5GJ9F] CLS token array shape: (2, 512)\n",
            "[ID_Z5MPPB] Raw sequence length: 126\n",
            "[ID_Z5MPPB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5MPPB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5MPPB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5MPPB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5MPPB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5MPPB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5MPPB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5MPPB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5MPPB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5MPPB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5MPPB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5MPPB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5MPPB] CLS token array shape: (4, 512)\n",
            "[ID_Z5NHZW] Raw sequence length: 79\n",
            "[ID_Z5NHZW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5NHZW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5NHZW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5NHZW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5NHZW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5NHZW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5NHZW] CLS token array shape: (2, 512)\n",
            "[ID_Z5PW8D] Raw sequence length: 78\n",
            "[ID_Z5PW8D] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5PW8D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5PW8D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5PW8D] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5PW8D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5PW8D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5PW8D] CLS token array shape: (2, 512)\n",
            "[ID_Z5WXF0] Raw sequence length: 80\n",
            "[ID_Z5WXF0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5WXF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5WXF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5WXF0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5WXF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5WXF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5WXF0] CLS token array shape: (2, 512)\n",
            "[ID_Z5ZL7G] Raw sequence length: 80\n",
            "[ID_Z5ZL7G] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZL7G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZL7G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZL7G] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZL7G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZL7G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZL7G] CLS token array shape: (2, 512)\n",
            "[ID_Z5ZUXO] Raw sequence length: 129\n",
            "[ID_Z5ZUXO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZUXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZUXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZUXO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZUXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZUXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZUXO] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZUXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZUXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZUXO] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZUXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZUXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZUXO] CLS token array shape: (4, 512)\n",
            "[ID_Z622TK] Raw sequence length: 144\n",
            "[ID_Z622TK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] CLS token array shape: (5, 512)\n",
            "[ID_Z63WD7] Raw sequence length: 80\n",
            "[ID_Z63WD7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z63WD7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z63WD7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z63WD7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z63WD7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z63WD7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z63WD7] CLS token array shape: (2, 512)\n",
            "[ID_Z644AP] Raw sequence length: 80\n",
            "[ID_Z644AP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z644AP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z644AP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z644AP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z644AP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z644AP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z644AP] CLS token array shape: (2, 512)\n",
            "[ID_Z667ZQ] Raw sequence length: 79\n",
            "[ID_Z667ZQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z667ZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z667ZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z667ZQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z667ZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z667ZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z667ZQ] CLS token array shape: (2, 512)\n",
            "[ID_Z697Z8] Raw sequence length: 74\n",
            "[ID_Z697Z8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z697Z8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z697Z8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z697Z8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z697Z8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z697Z8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z697Z8] CLS token array shape: (2, 512)\n",
            "[ID_Z6B4FC] Raw sequence length: 162\n",
            "[ID_Z6B4FC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] CLS token array shape: (5, 512)\n",
            "[ID_Z6MXIL] Raw sequence length: 80\n",
            "[ID_Z6MXIL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6MXIL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6MXIL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6MXIL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6MXIL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6MXIL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6MXIL] CLS token array shape: (2, 512)\n",
            "[ID_Z6NUGT] Raw sequence length: 80\n",
            "[ID_Z6NUGT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6NUGT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6NUGT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6NUGT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6NUGT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6NUGT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6NUGT] CLS token array shape: (2, 512)\n",
            "[ID_Z6QI77] Raw sequence length: 80\n",
            "[ID_Z6QI77] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6QI77] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6QI77] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6QI77] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6QI77] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6QI77] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6QI77] CLS token array shape: (2, 512)\n",
            "[ID_Z6SR0U] Raw sequence length: 292\n",
            "[ID_Z6SR0U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] CLS token array shape: (11, 512)\n",
            "[ID_Z6VCXO] Raw sequence length: 79\n",
            "[ID_Z6VCXO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6VCXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6VCXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6VCXO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6VCXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6VCXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6VCXO] CLS token array shape: (2, 512)\n",
            "[ID_Z7DRSO] Raw sequence length: 80\n",
            "[ID_Z7DRSO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7DRSO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7DRSO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7DRSO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7DRSO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7DRSO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7DRSO] CLS token array shape: (2, 512)\n",
            "[ID_Z7DXME] Raw sequence length: 79\n",
            "[ID_Z7DXME] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7DXME] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7DXME] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7DXME] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7DXME] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7DXME] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7DXME] CLS token array shape: (2, 512)\n",
            "[ID_Z7EE4M] Raw sequence length: 80\n",
            "[ID_Z7EE4M] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7EE4M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7EE4M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7EE4M] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7EE4M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7EE4M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7EE4M] CLS token array shape: (2, 512)\n",
            "[ID_Z7IK9D] Raw sequence length: 146\n",
            "[ID_Z7IK9D] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] CLS token array shape: (5, 512)\n",
            "[ID_Z7KVFS] Raw sequence length: 80\n",
            "[ID_Z7KVFS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KVFS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KVFS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KVFS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KVFS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KVFS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KVFS] CLS token array shape: (2, 512)\n",
            "[ID_Z7KYC3] Raw sequence length: 131\n",
            "[ID_Z7KYC3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KYC3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KYC3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KYC3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KYC3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KYC3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KYC3] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KYC3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KYC3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KYC3] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KYC3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KYC3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KYC3] CLS token array shape: (4, 512)\n",
            "[ID_Z7LYX9] Raw sequence length: 146\n",
            "[ID_Z7LYX9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] CLS token array shape: (5, 512)\n",
            "[ID_Z7R7YX] Raw sequence length: 79\n",
            "[ID_Z7R7YX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7R7YX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7R7YX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7R7YX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7R7YX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7R7YX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7R7YX] CLS token array shape: (2, 512)\n",
            "[ID_Z7RSEW] Raw sequence length: 79\n",
            "[ID_Z7RSEW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7RSEW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7RSEW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7RSEW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7RSEW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7RSEW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7RSEW] CLS token array shape: (2, 512)\n",
            "[ID_Z7T2GU] Raw sequence length: 79\n",
            "[ID_Z7T2GU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7T2GU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7T2GU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7T2GU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7T2GU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7T2GU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7T2GU] CLS token array shape: (2, 512)\n",
            "[ID_Z7UHRK] Raw sequence length: 129\n",
            "[ID_Z7UHRK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7UHRK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7UHRK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7UHRK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7UHRK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7UHRK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7UHRK] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7UHRK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7UHRK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7UHRK] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7UHRK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7UHRK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7UHRK] CLS token array shape: (4, 512)\n",
            "[ID_Z7WBUF] Raw sequence length: 80\n",
            "[ID_Z7WBUF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7WBUF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7WBUF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7WBUF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7WBUF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7WBUF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7WBUF] CLS token array shape: (2, 512)\n",
            "[ID_Z7ZHD2] Raw sequence length: 291\n",
            "[ID_Z7ZHD2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] CLS token array shape: (11, 512)\n",
            "[ID_Z886NP] Raw sequence length: 146\n",
            "[ID_Z886NP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] CLS token array shape: (5, 512)\n",
            "[ID_Z8BB1K] Raw sequence length: 271\n",
            "[ID_Z8BB1K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] CLS token array shape: (10, 512)\n",
            "[ID_Z8EX2O] Raw sequence length: 79\n",
            "[ID_Z8EX2O] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8EX2O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8EX2O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8EX2O] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8EX2O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8EX2O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8EX2O] CLS token array shape: (2, 512)\n",
            "[ID_Z8SDAM] Raw sequence length: 80\n",
            "[ID_Z8SDAM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SDAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SDAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SDAM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SDAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SDAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SDAM] CLS token array shape: (2, 512)\n",
            "[ID_Z8SSZN] Raw sequence length: 292\n",
            "[ID_Z8SSZN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] CLS token array shape: (11, 512)\n",
            "[ID_Z92F0M] Raw sequence length: 77\n",
            "[ID_Z92F0M] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z92F0M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z92F0M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z92F0M] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z92F0M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z92F0M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z92F0M] CLS token array shape: (2, 512)\n",
            "[ID_Z9O519] Raw sequence length: 79\n",
            "[ID_Z9O519] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9O519] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9O519] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9O519] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9O519] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9O519] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9O519] CLS token array shape: (2, 512)\n",
            "[ID_Z9QXNB] Raw sequence length: 154\n",
            "[ID_Z9QXNB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] CLS token array shape: (5, 512)\n",
            "[ID_Z9VP2K] Raw sequence length: 80\n",
            "[ID_Z9VP2K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9VP2K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9VP2K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9VP2K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9VP2K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9VP2K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9VP2K] CLS token array shape: (2, 512)\n",
            "[ID_Z9XFWV] Raw sequence length: 98\n",
            "[ID_Z9XFWV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9XFWV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9XFWV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9XFWV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9XFWV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9XFWV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9XFWV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9XFWV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9XFWV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9XFWV] CLS token array shape: (3, 512)\n",
            "[ID_ZA0VE3] Raw sequence length: 77\n",
            "[ID_ZA0VE3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA0VE3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA0VE3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA0VE3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA0VE3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA0VE3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA0VE3] CLS token array shape: (2, 512)\n",
            "[ID_ZA1QDN] Raw sequence length: 80\n",
            "[ID_ZA1QDN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA1QDN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA1QDN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA1QDN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA1QDN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA1QDN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA1QDN] CLS token array shape: (2, 512)\n",
            "[ID_ZA5EHV] Raw sequence length: 80\n",
            "[ID_ZA5EHV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA5EHV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA5EHV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA5EHV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA5EHV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA5EHV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA5EHV] CLS token array shape: (2, 512)\n",
            "[ID_ZA8SVZ] Raw sequence length: 292\n",
            "[ID_ZA8SVZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] CLS token array shape: (11, 512)\n",
            "[ID_ZA9DQW] Raw sequence length: 146\n",
            "[ID_ZA9DQW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] CLS token array shape: (5, 512)\n",
            "[ID_ZAEH10] Raw sequence length: 154\n",
            "[ID_ZAEH10] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] CLS token array shape: (5, 512)\n",
            "[ID_ZAK70R] Raw sequence length: 80\n",
            "[ID_ZAK70R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAK70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAK70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAK70R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAK70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAK70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAK70R] CLS token array shape: (2, 512)\n",
            "[ID_ZAXEMX] Raw sequence length: 292\n",
            "[ID_ZAXEMX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] CLS token array shape: (11, 512)\n",
            "[ID_ZAXSAZ] Raw sequence length: 79\n",
            "[ID_ZAXSAZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXSAZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXSAZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXSAZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXSAZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXSAZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXSAZ] CLS token array shape: (2, 512)\n",
            "[ID_ZBAY9R] Raw sequence length: 79\n",
            "[ID_ZBAY9R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBAY9R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBAY9R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBAY9R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBAY9R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBAY9R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBAY9R] CLS token array shape: (2, 512)\n",
            "[ID_ZBB9X7] Raw sequence length: 80\n",
            "[ID_ZBB9X7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBB9X7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBB9X7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBB9X7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBB9X7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBB9X7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBB9X7] CLS token array shape: (2, 512)\n",
            "[ID_ZBJPAL] Raw sequence length: 79\n",
            "[ID_ZBJPAL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBJPAL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBJPAL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBJPAL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBJPAL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBJPAL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBJPAL] CLS token array shape: (2, 512)\n",
            "[ID_ZBLEG3] Raw sequence length: 80\n",
            "[ID_ZBLEG3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBLEG3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBLEG3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBLEG3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBLEG3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBLEG3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBLEG3] CLS token array shape: (2, 512)\n",
            "[ID_ZBNDFT] Raw sequence length: 74\n",
            "[ID_ZBNDFT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBNDFT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBNDFT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBNDFT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBNDFT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBNDFT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBNDFT] CLS token array shape: (2, 512)\n",
            "[ID_ZBNE1C] Raw sequence length: 80\n",
            "[ID_ZBNE1C] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBNE1C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBNE1C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBNE1C] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBNE1C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBNE1C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBNE1C] CLS token array shape: (2, 512)\n",
            "[ID_ZBPBLO] Raw sequence length: 79\n",
            "[ID_ZBPBLO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBPBLO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBPBLO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBPBLO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBPBLO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBPBLO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBPBLO] CLS token array shape: (2, 512)\n",
            "[ID_ZBQCNN] Raw sequence length: 80\n",
            "[ID_ZBQCNN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBQCNN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBQCNN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBQCNN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBQCNN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBQCNN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBQCNN] CLS token array shape: (2, 512)\n",
            "[ID_ZBUDYL] Raw sequence length: 292\n",
            "[ID_ZBUDYL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] CLS token array shape: (11, 512)\n",
            "[ID_ZC0R1A] Raw sequence length: 154\n",
            "[ID_ZC0R1A] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] CLS token array shape: (5, 512)\n",
            "[ID_ZC80ZC] Raw sequence length: 80\n",
            "[ID_ZC80ZC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC80ZC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC80ZC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC80ZC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC80ZC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC80ZC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC80ZC] CLS token array shape: (2, 512)\n",
            "[ID_ZCTFA4] Raw sequence length: 146\n",
            "[ID_ZCTFA4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] CLS token array shape: (5, 512)\n",
            "[ID_ZCTSNV] Raw sequence length: 80\n",
            "[ID_ZCTSNV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTSNV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTSNV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTSNV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTSNV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTSNV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTSNV] CLS token array shape: (2, 512)\n",
            "[ID_ZCV4D4] Raw sequence length: 74\n",
            "[ID_ZCV4D4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCV4D4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCV4D4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCV4D4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCV4D4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCV4D4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCV4D4] CLS token array shape: (2, 512)\n",
            "[ID_ZCY9XS] Raw sequence length: 79\n",
            "[ID_ZCY9XS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCY9XS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCY9XS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCY9XS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCY9XS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCY9XS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCY9XS] CLS token array shape: (2, 512)\n",
            "[ID_ZD6SS2] Raw sequence length: 292\n",
            "[ID_ZD6SS2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] CLS token array shape: (11, 512)\n",
            "[ID_ZD7489] Raw sequence length: 80\n",
            "[ID_ZD7489] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD7489] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD7489] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD7489] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD7489] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD7489] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD7489] CLS token array shape: (2, 512)\n",
            "[ID_ZDBJ7L] Raw sequence length: 80\n",
            "[ID_ZDBJ7L] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDBJ7L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDBJ7L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDBJ7L] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDBJ7L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDBJ7L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDBJ7L] CLS token array shape: (2, 512)\n",
            "[ID_ZDE6LC] Raw sequence length: 154\n",
            "[ID_ZDE6LC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] CLS token array shape: (5, 512)\n",
            "[ID_ZDFPML] Raw sequence length: 79\n",
            "[ID_ZDFPML] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDFPML] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDFPML] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDFPML] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDFPML] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDFPML] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDFPML] CLS token array shape: (2, 512)\n",
            "[ID_ZDGIQV] Raw sequence length: 146\n",
            "[ID_ZDGIQV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] CLS token array shape: (5, 512)\n",
            "[ID_ZDIFBT] Raw sequence length: 146\n",
            "[ID_ZDIFBT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] CLS token array shape: (5, 512)\n",
            "[ID_ZDILV4] Raw sequence length: 146\n",
            "[ID_ZDILV4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] CLS token array shape: (5, 512)\n",
            "[ID_ZDQTLM] Raw sequence length: 291\n",
            "[ID_ZDQTLM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] CLS token array shape: (11, 512)\n",
            "[ID_ZDSORC] Raw sequence length: 146\n",
            "[ID_ZDSORC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] CLS token array shape: (5, 512)\n",
            "[ID_ZDVVHP] Raw sequence length: 148\n",
            "[ID_ZDVVHP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] CLS token array shape: (5, 512)\n",
            "[ID_ZDZ4CT] Raw sequence length: 79\n",
            "[ID_ZDZ4CT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDZ4CT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDZ4CT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDZ4CT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDZ4CT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDZ4CT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDZ4CT] CLS token array shape: (2, 512)\n",
            "[ID_ZE0H7E] Raw sequence length: 79\n",
            "[ID_ZE0H7E] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE0H7E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE0H7E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE0H7E] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE0H7E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE0H7E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE0H7E] CLS token array shape: (2, 512)\n",
            "[ID_ZE3LN6] Raw sequence length: 291\n",
            "[ID_ZE3LN6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] CLS token array shape: (11, 512)\n",
            "[ID_ZE8JB3] Raw sequence length: 79\n",
            "[ID_ZE8JB3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE8JB3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE8JB3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE8JB3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE8JB3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE8JB3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE8JB3] CLS token array shape: (2, 512)\n",
            "[ID_ZEEK19] Raw sequence length: 80\n",
            "[ID_ZEEK19] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEEK19] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEEK19] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEEK19] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEEK19] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEEK19] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEEK19] CLS token array shape: (2, 512)\n",
            "[ID_ZEFI0E] Raw sequence length: 145\n",
            "[ID_ZEFI0E] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] CLS token array shape: (5, 512)\n",
            "[ID_ZEHKBI] Raw sequence length: 292\n",
            "[ID_ZEHKBI] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] CLS token array shape: (11, 512)\n",
            "[ID_ZEKY5S] Raw sequence length: 79\n",
            "[ID_ZEKY5S] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEKY5S] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEKY5S] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEKY5S] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEKY5S] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEKY5S] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEKY5S] CLS token array shape: (2, 512)\n",
            "[ID_ZELAJP] Raw sequence length: 256\n",
            "[ID_ZELAJP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] CLS token array shape: (9, 512)\n",
            "[ID_ZFJVT5] Raw sequence length: 80\n",
            "[ID_ZFJVT5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFJVT5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFJVT5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFJVT5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFJVT5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFJVT5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFJVT5] CLS token array shape: (2, 512)\n",
            "[ID_ZFMEM5] Raw sequence length: 146\n",
            "[ID_ZFMEM5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] CLS token array shape: (5, 512)\n",
            "[ID_ZFT7UF] Raw sequence length: 80\n",
            "[ID_ZFT7UF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFT7UF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFT7UF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFT7UF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFT7UF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFT7UF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFT7UF] CLS token array shape: (2, 512)\n",
            "[ID_ZG033J] Raw sequence length: 79\n",
            "[ID_ZG033J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG033J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG033J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG033J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG033J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG033J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG033J] CLS token array shape: (2, 512)\n",
            "[ID_ZG0XJH] Raw sequence length: 80\n",
            "[ID_ZG0XJH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG0XJH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG0XJH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG0XJH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG0XJH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG0XJH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG0XJH] CLS token array shape: (2, 512)\n",
            "[ID_ZG31D9] Raw sequence length: 146\n",
            "[ID_ZG31D9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] CLS token array shape: (5, 512)\n",
            "[ID_ZG8JYK] Raw sequence length: 80\n",
            "[ID_ZG8JYK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG8JYK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG8JYK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG8JYK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG8JYK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG8JYK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG8JYK] CLS token array shape: (2, 512)\n",
            "[ID_ZGAD8R] Raw sequence length: 80\n",
            "[ID_ZGAD8R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGAD8R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGAD8R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGAD8R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGAD8R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGAD8R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGAD8R] CLS token array shape: (2, 512)\n",
            "[ID_ZGKQ83] Raw sequence length: 80\n",
            "[ID_ZGKQ83] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGKQ83] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGKQ83] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGKQ83] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGKQ83] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGKQ83] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGKQ83] CLS token array shape: (2, 512)\n",
            "[ID_ZGKSFK] Raw sequence length: 80\n",
            "[ID_ZGKSFK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGKSFK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGKSFK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGKSFK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGKSFK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGKSFK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGKSFK] CLS token array shape: (2, 512)\n",
            "[ID_ZGM7VU] Raw sequence length: 79\n",
            "[ID_ZGM7VU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGM7VU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGM7VU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGM7VU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGM7VU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGM7VU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGM7VU] CLS token array shape: (2, 512)\n",
            "[ID_ZGPMDW] Raw sequence length: 79\n",
            "[ID_ZGPMDW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGPMDW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGPMDW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGPMDW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGPMDW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGPMDW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGPMDW] CLS token array shape: (2, 512)\n",
            "[ID_ZGR643] Raw sequence length: 79\n",
            "[ID_ZGR643] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGR643] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGR643] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGR643] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGR643] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGR643] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGR643] CLS token array shape: (2, 512)\n",
            "[ID_ZH9J6J] Raw sequence length: 146\n",
            "[ID_ZH9J6J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] CLS token array shape: (5, 512)\n",
            "[ID_ZHJ8MA] Raw sequence length: 146\n",
            "[ID_ZHJ8MA] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] CLS token array shape: (5, 512)\n",
            "[ID_ZHMQYN] Raw sequence length: 80\n",
            "[ID_ZHMQYN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHMQYN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHMQYN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHMQYN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHMQYN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHMQYN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHMQYN] CLS token array shape: (2, 512)\n",
            "[ID_ZHOZJE] Raw sequence length: 74\n",
            "[ID_ZHOZJE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHOZJE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHOZJE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHOZJE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHOZJE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHOZJE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHOZJE] CLS token array shape: (2, 512)\n",
            "[ID_ZHR76K] Raw sequence length: 79\n",
            "[ID_ZHR76K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHR76K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHR76K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHR76K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHR76K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHR76K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHR76K] CLS token array shape: (2, 512)\n",
            "[ID_ZHVUNB] Raw sequence length: 204\n",
            "[ID_ZHVUNB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] CLS token array shape: (7, 512)\n",
            "[ID_ZHXTJI] Raw sequence length: 144\n",
            "[ID_ZHXTJI] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] CLS token array shape: (5, 512)\n",
            "[ID_ZHYRV7] Raw sequence length: 145\n",
            "[ID_ZHYRV7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] CLS token array shape: (5, 512)\n",
            "[ID_ZI10A7] Raw sequence length: 80\n",
            "[ID_ZI10A7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI10A7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI10A7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI10A7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI10A7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI10A7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI10A7] CLS token array shape: (2, 512)\n",
            "[ID_ZI4M2D] Raw sequence length: 80\n",
            "[ID_ZI4M2D] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI4M2D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI4M2D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI4M2D] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI4M2D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI4M2D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI4M2D] CLS token array shape: (2, 512)\n",
            "[ID_ZI89A7] Raw sequence length: 80\n",
            "[ID_ZI89A7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI89A7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI89A7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI89A7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI89A7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI89A7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI89A7] CLS token array shape: (2, 512)\n",
            "[ID_ZI8RNO] Raw sequence length: 80\n",
            "[ID_ZI8RNO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI8RNO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI8RNO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI8RNO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI8RNO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI8RNO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI8RNO] CLS token array shape: (2, 512)\n",
            "[ID_ZIKO2K] Raw sequence length: 79\n",
            "[ID_ZIKO2K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIKO2K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIKO2K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIKO2K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIKO2K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIKO2K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIKO2K] CLS token array shape: (2, 512)\n",
            "[ID_ZIQ5M1] Raw sequence length: 80\n",
            "[ID_ZIQ5M1] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIQ5M1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIQ5M1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIQ5M1] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIQ5M1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIQ5M1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIQ5M1] CLS token array shape: (2, 512)\n",
            "[ID_ZITA1Z] Raw sequence length: 154\n",
            "[ID_ZITA1Z] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] CLS token array shape: (5, 512)\n",
            "[ID_ZITXBE] Raw sequence length: 292\n",
            "[ID_ZITXBE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] CLS token array shape: (11, 512)\n",
            "[ID_ZIVO0K] Raw sequence length: 79\n",
            "[ID_ZIVO0K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIVO0K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIVO0K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIVO0K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIVO0K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIVO0K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIVO0K] CLS token array shape: (2, 512)\n",
            "[ID_ZIXDCB] Raw sequence length: 145\n",
            "[ID_ZIXDCB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] CLS token array shape: (5, 512)\n",
            "[ID_ZJ00U3] Raw sequence length: 146\n",
            "[ID_ZJ00U3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] CLS token array shape: (5, 512)\n",
            "[ID_ZJ7UN9] Raw sequence length: 145\n",
            "[ID_ZJ7UN9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] CLS token array shape: (5, 512)\n",
            "[ID_ZJ9U9V] Raw sequence length: 146\n",
            "[ID_ZJ9U9V] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] CLS token array shape: (5, 512)\n",
            "[ID_ZJDFWZ] Raw sequence length: 80\n",
            "[ID_ZJDFWZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJDFWZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJDFWZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJDFWZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJDFWZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJDFWZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJDFWZ] CLS token array shape: (2, 512)\n",
            "[ID_ZJPD8O] Raw sequence length: 292\n",
            "[ID_ZJPD8O] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] CLS token array shape: (11, 512)\n",
            "[ID_ZJTGHR] Raw sequence length: 78\n",
            "[ID_ZJTGHR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJTGHR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJTGHR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJTGHR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJTGHR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJTGHR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJTGHR] CLS token array shape: (2, 512)\n",
            "[ID_ZK0MV8] Raw sequence length: 79\n",
            "[ID_ZK0MV8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK0MV8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK0MV8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK0MV8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK0MV8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK0MV8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK0MV8] CLS token array shape: (2, 512)\n",
            "[ID_ZK0SMK] Raw sequence length: 80\n",
            "[ID_ZK0SMK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK0SMK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK0SMK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK0SMK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK0SMK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK0SMK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK0SMK] CLS token array shape: (2, 512)\n",
            "[ID_ZK3NRI] Raw sequence length: 79\n",
            "[ID_ZK3NRI] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK3NRI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK3NRI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK3NRI] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK3NRI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK3NRI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK3NRI] CLS token array shape: (2, 512)\n",
            "[ID_ZK9XJJ] Raw sequence length: 146\n",
            "[ID_ZK9XJJ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] CLS token array shape: (5, 512)\n",
            "[ID_ZKHBJR] Raw sequence length: 80\n",
            "[ID_ZKHBJR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKHBJR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKHBJR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKHBJR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKHBJR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKHBJR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKHBJR] CLS token array shape: (2, 512)\n",
            "[ID_ZKNTJ8] Raw sequence length: 292\n",
            "[ID_ZKNTJ8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] CLS token array shape: (11, 512)\n",
            "[ID_ZKS1Y8] Raw sequence length: 80\n",
            "[ID_ZKS1Y8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKS1Y8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKS1Y8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKS1Y8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKS1Y8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKS1Y8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKS1Y8] CLS token array shape: (2, 512)\n",
            "[ID_ZKUVPM] Raw sequence length: 145\n",
            "[ID_ZKUVPM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] CLS token array shape: (5, 512)\n",
            "[ID_ZKVAUE] Raw sequence length: 146\n",
            "[ID_ZKVAUE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] CLS token array shape: (5, 512)\n",
            "[ID_ZKXXJ5] Raw sequence length: 79\n",
            "[ID_ZKXXJ5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKXXJ5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKXXJ5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKXXJ5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKXXJ5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKXXJ5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKXXJ5] CLS token array shape: (2, 512)\n",
            "[ID_ZL3BCT] Raw sequence length: 79\n",
            "[ID_ZL3BCT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZL3BCT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZL3BCT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZL3BCT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZL3BCT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZL3BCT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZL3BCT] CLS token array shape: (2, 512)\n",
            "[ID_ZL9XX2] Raw sequence length: 80\n",
            "[ID_ZL9XX2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZL9XX2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZL9XX2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZL9XX2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZL9XX2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZL9XX2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZL9XX2] CLS token array shape: (2, 512)\n",
            "[ID_ZLB0W3] Raw sequence length: 126\n",
            "[ID_ZLB0W3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLB0W3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLB0W3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLB0W3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLB0W3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLB0W3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLB0W3] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLB0W3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLB0W3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLB0W3] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLB0W3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLB0W3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLB0W3] CLS token array shape: (4, 512)\n",
            "[ID_ZLBEWE] Raw sequence length: 80\n",
            "[ID_ZLBEWE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBEWE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBEWE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBEWE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBEWE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBEWE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBEWE] CLS token array shape: (2, 512)\n",
            "[ID_ZLBJPC] Raw sequence length: 291\n",
            "[ID_ZLBJPC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] CLS token array shape: (11, 512)\n",
            "[ID_ZLJ7PL] Raw sequence length: 80\n",
            "[ID_ZLJ7PL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLJ7PL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLJ7PL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLJ7PL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLJ7PL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLJ7PL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLJ7PL] CLS token array shape: (2, 512)\n",
            "[ID_ZLKX3Q] Raw sequence length: 154\n",
            "[ID_ZLKX3Q] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] CLS token array shape: (5, 512)\n",
            "[ID_ZLM59I] Raw sequence length: 79\n",
            "[ID_ZLM59I] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLM59I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLM59I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLM59I] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLM59I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLM59I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLM59I] CLS token array shape: (2, 512)\n",
            "[ID_ZLOP6A] Raw sequence length: 146\n",
            "[ID_ZLOP6A] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] CLS token array shape: (5, 512)\n",
            "[ID_ZLX9CR] Raw sequence length: 80\n",
            "[ID_ZLX9CR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLX9CR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLX9CR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLX9CR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLX9CR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLX9CR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLX9CR] CLS token array shape: (2, 512)\n",
            "[ID_ZM3XJQ] Raw sequence length: 146\n",
            "[ID_ZM3XJQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] CLS token array shape: (5, 512)\n",
            "[ID_ZM6H38] Raw sequence length: 80\n",
            "[ID_ZM6H38] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM6H38] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM6H38] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM6H38] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM6H38] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM6H38] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM6H38] CLS token array shape: (2, 512)\n",
            "[ID_ZM8JLB] Raw sequence length: 80\n",
            "[ID_ZM8JLB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM8JLB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM8JLB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM8JLB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM8JLB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM8JLB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM8JLB] CLS token array shape: (2, 512)\n",
            "[ID_ZMA4KV] Raw sequence length: 145\n",
            "[ID_ZMA4KV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] CLS token array shape: (5, 512)\n",
            "[ID_ZMG0QS] Raw sequence length: 77\n",
            "[ID_ZMG0QS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMG0QS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMG0QS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMG0QS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMG0QS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMG0QS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMG0QS] CLS token array shape: (2, 512)\n",
            "[ID_ZMJOYK] Raw sequence length: 80\n",
            "[ID_ZMJOYK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMJOYK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMJOYK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMJOYK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMJOYK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMJOYK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMJOYK] CLS token array shape: (2, 512)\n",
            "[ID_ZMKCQA] Raw sequence length: 80\n",
            "[ID_ZMKCQA] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMKCQA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMKCQA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMKCQA] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMKCQA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMKCQA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMKCQA] CLS token array shape: (2, 512)\n",
            "[ID_ZMT8IU] Raw sequence length: 129\n",
            "[ID_ZMT8IU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT8IU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT8IU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT8IU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT8IU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT8IU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT8IU] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT8IU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT8IU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT8IU] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT8IU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT8IU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT8IU] CLS token array shape: (4, 512)\n",
            "[ID_ZMT965] Raw sequence length: 292\n",
            "[ID_ZMT965] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] CLS token array shape: (11, 512)\n",
            "[ID_ZMW79D] Raw sequence length: 79\n",
            "[ID_ZMW79D] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMW79D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMW79D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMW79D] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMW79D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMW79D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMW79D] CLS token array shape: (2, 512)\n",
            "[ID_ZMYI7J] Raw sequence length: 79\n",
            "[ID_ZMYI7J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMYI7J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMYI7J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMYI7J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMYI7J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMYI7J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMYI7J] CLS token array shape: (2, 512)\n",
            "[ID_ZMZKA8] Raw sequence length: 146\n",
            "[ID_ZMZKA8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] CLS token array shape: (5, 512)\n",
            "[ID_ZNGE8W] Raw sequence length: 145\n",
            "[ID_ZNGE8W] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] CLS token array shape: (5, 512)\n",
            "[ID_ZNIU3V] Raw sequence length: 80\n",
            "[ID_ZNIU3V] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNIU3V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNIU3V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNIU3V] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNIU3V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNIU3V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNIU3V] CLS token array shape: (2, 512)\n",
            "[ID_ZNV5QM] Raw sequence length: 154\n",
            "[ID_ZNV5QM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] CLS token array shape: (5, 512)\n",
            "[ID_ZNW7TJ] Raw sequence length: 79\n",
            "[ID_ZNW7TJ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNW7TJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNW7TJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNW7TJ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNW7TJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNW7TJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNW7TJ] CLS token array shape: (2, 512)\n",
            "[ID_ZNWGRR] Raw sequence length: 146\n",
            "[ID_ZNWGRR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] CLS token array shape: (5, 512)\n",
            "[ID_ZNX7ZE] Raw sequence length: 79\n",
            "[ID_ZNX7ZE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNX7ZE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNX7ZE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNX7ZE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNX7ZE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNX7ZE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNX7ZE] CLS token array shape: (2, 512)\n",
            "[ID_ZNYAJN] Raw sequence length: 126\n",
            "[ID_ZNYAJN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNYAJN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNYAJN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNYAJN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNYAJN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNYAJN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNYAJN] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNYAJN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNYAJN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNYAJN] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNYAJN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNYAJN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNYAJN] CLS token array shape: (4, 512)\n",
            "[ID_ZO04I6] Raw sequence length: 79\n",
            "[ID_ZO04I6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO04I6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO04I6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO04I6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO04I6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO04I6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO04I6] CLS token array shape: (2, 512)\n",
            "[ID_ZO3TEW] Raw sequence length: 80\n",
            "[ID_ZO3TEW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO3TEW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO3TEW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO3TEW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO3TEW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO3TEW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO3TEW] CLS token array shape: (2, 512)\n",
            "[ID_ZO7767] Raw sequence length: 74\n",
            "[ID_ZO7767] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO7767] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO7767] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO7767] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO7767] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO7767] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO7767] CLS token array shape: (2, 512)\n",
            "[ID_ZOBXT0] Raw sequence length: 154\n",
            "[ID_ZOBXT0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] CLS token array shape: (5, 512)\n",
            "[ID_ZODZK2] Raw sequence length: 80\n",
            "[ID_ZODZK2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZODZK2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZODZK2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZODZK2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZODZK2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZODZK2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZODZK2] CLS token array shape: (2, 512)\n",
            "[ID_ZOE9G3] Raw sequence length: 79\n",
            "[ID_ZOE9G3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9G3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9G3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9G3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9G3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9G3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9G3] CLS token array shape: (2, 512)\n",
            "[ID_ZOE9X6] Raw sequence length: 290\n",
            "[ID_ZOE9X6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] CLS token array shape: (11, 512)\n",
            "[ID_ZOGEJU] Raw sequence length: 146\n",
            "[ID_ZOGEJU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] CLS token array shape: (5, 512)\n",
            "[ID_ZOKU5O] Raw sequence length: 145\n",
            "[ID_ZOKU5O] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] CLS token array shape: (5, 512)\n",
            "[ID_ZOLFUK] Raw sequence length: 79\n",
            "[ID_ZOLFUK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOLFUK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOLFUK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOLFUK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOLFUK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOLFUK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOLFUK] CLS token array shape: (2, 512)\n",
            "[ID_ZOLH5W] Raw sequence length: 79\n",
            "[ID_ZOLH5W] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOLH5W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOLH5W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOLH5W] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOLH5W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOLH5W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOLH5W] CLS token array shape: (2, 512)\n",
            "[ID_ZOP96N] Raw sequence length: 146\n",
            "[ID_ZOP96N] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] CLS token array shape: (5, 512)\n",
            "[ID_ZOQ80F] Raw sequence length: 78\n",
            "[ID_ZOQ80F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOQ80F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOQ80F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOQ80F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOQ80F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOQ80F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOQ80F] CLS token array shape: (2, 512)\n",
            "[ID_ZPAYBZ] Raw sequence length: 154\n",
            "[ID_ZPAYBZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] CLS token array shape: (5, 512)\n",
            "[ID_ZPGN0E] Raw sequence length: 79\n",
            "[ID_ZPGN0E] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPGN0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPGN0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPGN0E] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPGN0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPGN0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPGN0E] CLS token array shape: (2, 512)\n",
            "[ID_ZPNB5H] Raw sequence length: 155\n",
            "[ID_ZPNB5H] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] CLS token array shape: (5, 512)\n",
            "[ID_ZPQ51R] Raw sequence length: 80\n",
            "[ID_ZPQ51R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPQ51R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPQ51R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPQ51R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPQ51R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPQ51R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPQ51R] CLS token array shape: (2, 512)\n",
            "[ID_ZPQ5MZ] Raw sequence length: 77\n",
            "[ID_ZPQ5MZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPQ5MZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPQ5MZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPQ5MZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPQ5MZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPQ5MZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPQ5MZ] CLS token array shape: (2, 512)\n",
            "[ID_ZPRPO3] Raw sequence length: 80\n",
            "[ID_ZPRPO3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPRPO3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPRPO3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPRPO3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPRPO3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPRPO3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPRPO3] CLS token array shape: (2, 512)\n",
            "[ID_ZPY671] Raw sequence length: 80\n",
            "[ID_ZPY671] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPY671] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPY671] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPY671] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPY671] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPY671] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPY671] CLS token array shape: (2, 512)\n",
            "[ID_ZQ5H4U] Raw sequence length: 80\n",
            "[ID_ZQ5H4U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ5H4U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ5H4U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ5H4U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ5H4U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ5H4U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ5H4U] CLS token array shape: (2, 512)\n",
            "[ID_ZQ6CO6] Raw sequence length: 79\n",
            "[ID_ZQ6CO6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ6CO6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ6CO6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ6CO6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ6CO6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ6CO6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ6CO6] CLS token array shape: (2, 512)\n",
            "[ID_ZQ97GG] Raw sequence length: 145\n",
            "[ID_ZQ97GG] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] CLS token array shape: (5, 512)\n",
            "[ID_ZQCPFH] Raw sequence length: 145\n",
            "[ID_ZQCPFH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] CLS token array shape: (5, 512)\n",
            "[ID_ZQEHWQ] Raw sequence length: 146\n",
            "[ID_ZQEHWQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] CLS token array shape: (5, 512)\n",
            "[ID_ZQI5RF] Raw sequence length: 78\n",
            "[ID_ZQI5RF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQI5RF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQI5RF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQI5RF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQI5RF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQI5RF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQI5RF] CLS token array shape: (2, 512)\n",
            "[ID_ZQLNHD] Raw sequence length: 80\n",
            "[ID_ZQLNHD] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQLNHD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQLNHD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQLNHD] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQLNHD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQLNHD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQLNHD] CLS token array shape: (2, 512)\n",
            "[ID_ZQPZR4] Raw sequence length: 80\n",
            "[ID_ZQPZR4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQPZR4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQPZR4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQPZR4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQPZR4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQPZR4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQPZR4] CLS token array shape: (2, 512)\n",
            "[ID_ZQXI2E] Raw sequence length: 79\n",
            "[ID_ZQXI2E] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQXI2E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQXI2E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQXI2E] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQXI2E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQXI2E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQXI2E] CLS token array shape: (2, 512)\n",
            "[ID_ZR4NS4] Raw sequence length: 159\n",
            "[ID_ZR4NS4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] CLS token array shape: (5, 512)\n",
            "[ID_ZRC5N0] Raw sequence length: 145\n",
            "[ID_ZRC5N0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] CLS token array shape: (5, 512)\n",
            "[ID_ZRCNS2] Raw sequence length: 101\n",
            "[ID_ZRCNS2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRCNS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRCNS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRCNS2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRCNS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRCNS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRCNS2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRCNS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRCNS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRCNS2] CLS token array shape: (3, 512)\n",
            "[ID_ZRDJLE] Raw sequence length: 146\n",
            "[ID_ZRDJLE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] CLS token array shape: (5, 512)\n",
            "[ID_ZREWKM] Raw sequence length: 145\n",
            "[ID_ZREWKM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] CLS token array shape: (5, 512)\n",
            "[ID_ZRFS2P] Raw sequence length: 154\n",
            "[ID_ZRFS2P] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] CLS token array shape: (5, 512)\n",
            "[ID_ZRGG3F] Raw sequence length: 74\n",
            "[ID_ZRGG3F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRGG3F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRGG3F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRGG3F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRGG3F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRGG3F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRGG3F] CLS token array shape: (2, 512)\n",
            "[ID_ZRH3Z5] Raw sequence length: 79\n",
            "[ID_ZRH3Z5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRH3Z5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRH3Z5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRH3Z5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRH3Z5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRH3Z5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRH3Z5] CLS token array shape: (2, 512)\n",
            "[ID_ZRKJ5U] Raw sequence length: 79\n",
            "[ID_ZRKJ5U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRKJ5U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRKJ5U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRKJ5U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRKJ5U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRKJ5U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRKJ5U] CLS token array shape: (2, 512)\n",
            "[ID_ZRSC7M] Raw sequence length: 145\n",
            "[ID_ZRSC7M] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] CLS token array shape: (5, 512)\n",
            "[ID_ZRUPK5] Raw sequence length: 79\n",
            "[ID_ZRUPK5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRUPK5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRUPK5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRUPK5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRUPK5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRUPK5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRUPK5] CLS token array shape: (2, 512)\n",
            "[ID_ZRZ410] Raw sequence length: 80\n",
            "[ID_ZRZ410] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRZ410] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRZ410] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRZ410] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRZ410] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRZ410] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRZ410] CLS token array shape: (2, 512)\n",
            "[ID_ZRZPXA] Raw sequence length: 79\n",
            "[ID_ZRZPXA] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRZPXA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRZPXA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRZPXA] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRZPXA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRZPXA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRZPXA] CLS token array shape: (2, 512)\n",
            "[ID_ZS17RR] Raw sequence length: 80\n",
            "[ID_ZS17RR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS17RR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS17RR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS17RR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS17RR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS17RR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS17RR] CLS token array shape: (2, 512)\n",
            "[ID_ZS4ATE] Raw sequence length: 80\n",
            "[ID_ZS4ATE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS4ATE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS4ATE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS4ATE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS4ATE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS4ATE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS4ATE] CLS token array shape: (2, 512)\n",
            "[ID_ZS963Y] Raw sequence length: 80\n",
            "[ID_ZS963Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS963Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS963Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS963Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS963Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS963Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS963Y] CLS token array shape: (2, 512)\n",
            "[ID_ZSCAPE] Raw sequence length: 291\n",
            "[ID_ZSCAPE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] CLS token array shape: (11, 512)\n",
            "[ID_ZSK2V0] Raw sequence length: 79\n",
            "[ID_ZSK2V0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSK2V0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSK2V0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSK2V0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSK2V0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSK2V0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSK2V0] CLS token array shape: (2, 512)\n",
            "[ID_ZSKVWC] Raw sequence length: 80\n",
            "[ID_ZSKVWC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSKVWC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSKVWC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSKVWC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSKVWC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSKVWC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSKVWC] CLS token array shape: (2, 512)\n",
            "[ID_ZSMUJP] Raw sequence length: 80\n",
            "[ID_ZSMUJP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSMUJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSMUJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSMUJP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSMUJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSMUJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSMUJP] CLS token array shape: (2, 512)\n",
            "[ID_ZSW9R5] Raw sequence length: 79\n",
            "[ID_ZSW9R5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSW9R5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSW9R5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSW9R5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSW9R5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSW9R5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSW9R5] CLS token array shape: (2, 512)\n",
            "[ID_ZSWVZ8] Raw sequence length: 154\n",
            "[ID_ZSWVZ8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] CLS token array shape: (5, 512)\n",
            "[ID_ZTD5W2] Raw sequence length: 79\n",
            "[ID_ZTD5W2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTD5W2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTD5W2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTD5W2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTD5W2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTD5W2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTD5W2] CLS token array shape: (2, 512)\n",
            "[ID_ZTHFDF] Raw sequence length: 80\n",
            "[ID_ZTHFDF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTHFDF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTHFDF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTHFDF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTHFDF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTHFDF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTHFDF] CLS token array shape: (2, 512)\n",
            "[ID_ZTNT6L] Raw sequence length: 154\n",
            "[ID_ZTNT6L] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] CLS token array shape: (5, 512)\n",
            "[ID_ZTS34F] Raw sequence length: 79\n",
            "[ID_ZTS34F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTS34F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTS34F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTS34F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTS34F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTS34F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTS34F] CLS token array shape: (2, 512)\n",
            "[ID_ZU8KEC] Raw sequence length: 80\n",
            "[ID_ZU8KEC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZU8KEC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZU8KEC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZU8KEC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZU8KEC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZU8KEC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZU8KEC] CLS token array shape: (2, 512)\n",
            "[ID_ZUCM2J] Raw sequence length: 78\n",
            "[ID_ZUCM2J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUCM2J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUCM2J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUCM2J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUCM2J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUCM2J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUCM2J] CLS token array shape: (2, 512)\n",
            "[ID_ZUFF8P] Raw sequence length: 80\n",
            "[ID_ZUFF8P] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUFF8P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUFF8P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUFF8P] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUFF8P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUFF8P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUFF8P] CLS token array shape: (2, 512)\n",
            "[ID_ZUIN5P] Raw sequence length: 79\n",
            "[ID_ZUIN5P] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUIN5P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUIN5P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUIN5P] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUIN5P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUIN5P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUIN5P] CLS token array shape: (2, 512)\n",
            "[ID_ZV61RS] Raw sequence length: 129\n",
            "[ID_ZV61RS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZV61RS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZV61RS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZV61RS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZV61RS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZV61RS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZV61RS] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZV61RS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZV61RS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZV61RS] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZV61RS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZV61RS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZV61RS] CLS token array shape: (4, 512)\n",
            "[ID_ZVGXX0] Raw sequence length: 80\n",
            "[ID_ZVGXX0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVGXX0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVGXX0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVGXX0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVGXX0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVGXX0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVGXX0] CLS token array shape: (2, 512)\n",
            "[ID_ZVKBF5] Raw sequence length: 79\n",
            "[ID_ZVKBF5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVKBF5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVKBF5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVKBF5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVKBF5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVKBF5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVKBF5] CLS token array shape: (2, 512)\n",
            "[ID_ZVU1ZI] Raw sequence length: 79\n",
            "[ID_ZVU1ZI] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVU1ZI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVU1ZI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVU1ZI] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVU1ZI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVU1ZI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVU1ZI] CLS token array shape: (2, 512)\n",
            "[ID_ZVUPSK] Raw sequence length: 80\n",
            "[ID_ZVUPSK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVUPSK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVUPSK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVUPSK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVUPSK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVUPSK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVUPSK] CLS token array shape: (2, 512)\n",
            "[ID_ZW2YU4] Raw sequence length: 79\n",
            "[ID_ZW2YU4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZW2YU4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZW2YU4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZW2YU4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZW2YU4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZW2YU4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZW2YU4] CLS token array shape: (2, 512)\n",
            "[ID_ZW6U4C] Raw sequence length: 79\n",
            "[ID_ZW6U4C] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZW6U4C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZW6U4C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZW6U4C] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZW6U4C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZW6U4C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZW6U4C] CLS token array shape: (2, 512)\n",
            "[ID_ZWBNJE] Raw sequence length: 80\n",
            "[ID_ZWBNJE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWBNJE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWBNJE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWBNJE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWBNJE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWBNJE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWBNJE] CLS token array shape: (2, 512)\n",
            "[ID_ZWECCO] Raw sequence length: 292\n",
            "[ID_ZWECCO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] CLS token array shape: (11, 512)\n",
            "[ID_ZWHNOT] Raw sequence length: 146\n",
            "[ID_ZWHNOT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] CLS token array shape: (5, 512)\n",
            "[ID_ZWHOG6] Raw sequence length: 74\n",
            "[ID_ZWHOG6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHOG6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHOG6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHOG6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHOG6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHOG6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHOG6] CLS token array shape: (2, 512)\n",
            "[ID_ZWHV0R] Raw sequence length: 80\n",
            "[ID_ZWHV0R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHV0R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHV0R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHV0R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHV0R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHV0R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHV0R] CLS token array shape: (2, 512)\n",
            "[ID_ZWM728] Raw sequence length: 256\n",
            "[ID_ZWM728] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] CLS token array shape: (9, 512)\n",
            "[ID_ZWQENE] Raw sequence length: 146\n",
            "[ID_ZWQENE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] CLS token array shape: (5, 512)\n",
            "[ID_ZWR2AH] Raw sequence length: 129\n",
            "[ID_ZWR2AH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWR2AH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWR2AH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWR2AH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWR2AH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWR2AH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWR2AH] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWR2AH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWR2AH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWR2AH] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWR2AH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWR2AH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWR2AH] CLS token array shape: (4, 512)\n",
            "[ID_ZWSJF0] Raw sequence length: 168\n",
            "[ID_ZWSJF0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] CLS token array shape: (6, 512)\n",
            "[ID_ZX6I2U] Raw sequence length: 84\n",
            "[ID_ZX6I2U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZX6I2U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZX6I2U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZX6I2U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZX6I2U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZX6I2U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZX6I2U] CLS token array shape: (2, 512)\n",
            "[ID_ZXDC0J] Raw sequence length: 152\n",
            "[ID_ZXDC0J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] CLS token array shape: (5, 512)\n",
            "[ID_ZXM3J1] Raw sequence length: 129\n",
            "[ID_ZXM3J1] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXM3J1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXM3J1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXM3J1] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXM3J1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXM3J1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXM3J1] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXM3J1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXM3J1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXM3J1] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXM3J1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXM3J1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXM3J1] CLS token array shape: (4, 512)\n",
            "[ID_ZXRISS] Raw sequence length: 79\n",
            "[ID_ZXRISS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXRISS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXRISS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXRISS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXRISS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXRISS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXRISS] CLS token array shape: (2, 512)\n",
            "[ID_ZXTIGY] Raw sequence length: 79\n",
            "[ID_ZXTIGY] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXTIGY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXTIGY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXTIGY] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXTIGY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXTIGY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXTIGY] CLS token array shape: (2, 512)\n",
            "[ID_ZY2Z4Y] Raw sequence length: 146\n",
            "[ID_ZY2Z4Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] CLS token array shape: (5, 512)\n",
            "[ID_ZY8T54] Raw sequence length: 292\n",
            "[ID_ZY8T54] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] CLS token array shape: (11, 512)\n",
            "[ID_ZY907J] Raw sequence length: 79\n",
            "[ID_ZY907J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY907J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY907J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY907J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY907J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY907J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY907J] CLS token array shape: (2, 512)\n",
            "[ID_ZYH3ZG] Raw sequence length: 80\n",
            "[ID_ZYH3ZG] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYH3ZG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYH3ZG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYH3ZG] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYH3ZG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYH3ZG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYH3ZG] CLS token array shape: (2, 512)\n",
            "[ID_ZYN260] Raw sequence length: 77\n",
            "[ID_ZYN260] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYN260] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYN260] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYN260] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYN260] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYN260] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYN260] CLS token array shape: (2, 512)\n",
            "[ID_ZYZPJ4] Raw sequence length: 80\n",
            "[ID_ZYZPJ4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYZPJ4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYZPJ4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYZPJ4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYZPJ4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYZPJ4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYZPJ4] CLS token array shape: (2, 512)\n",
            "[ID_ZZ5C2L] Raw sequence length: 80\n",
            "[ID_ZZ5C2L] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZ5C2L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZ5C2L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZ5C2L] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZ5C2L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZ5C2L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZ5C2L] CLS token array shape: (2, 512)\n",
            "[ID_ZZDVEC] Raw sequence length: 80\n",
            "[ID_ZZDVEC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZDVEC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZDVEC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZDVEC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZDVEC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZDVEC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZDVEC] CLS token array shape: (2, 512)\n",
            "[ID_ZZK9QA] Raw sequence length: 80\n",
            "[ID_ZZK9QA] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZK9QA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZK9QA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZK9QA] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZK9QA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZK9QA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZK9QA] CLS token array shape: (2, 512)\n",
            "[ID_ZZNU8N] Raw sequence length: 79\n",
            "[ID_ZZNU8N] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZNU8N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZNU8N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZNU8N] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZNU8N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZNU8N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZNU8N] CLS token array shape: (2, 512)\n",
            "[ID_ZZPXSE] Raw sequence length: 79\n",
            "[ID_ZZPXSE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZPXSE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZPXSE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZPXSE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZPXSE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZPXSE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZPXSE] CLS token array shape: (2, 512)\n",
            "[ID_ZZUHF2] Raw sequence length: 154\n",
            "[ID_ZZUHF2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] CLS token array shape: (5, 512)\n",
            "[ID_ZZVJ91] Raw sequence length: 292\n",
            "[ID_ZZVJ91] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] CLS token array shape: (11, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for uid, cls_list in cls_embeddings.items():\n",
        "    arr = np.array(cls_list)\n",
        "    print(f\"{uid} → shape: {arr.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekNlJgQR0QaR",
        "outputId": "ccfa7e8e-354b-433b-e9a6-36a47ee202ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIXEL_0001 → shape: (1, 512)\n",
            "PIXEL_0002 → shape: (3, 512)\n",
            "PIXEL_0003 → shape: (3, 512)\n",
            "PIXEL_0004 → shape: (1, 512)\n",
            "PIXEL_0005 → shape: (1, 512)\n",
            "PIXEL_0006 → shape: (3, 512)\n",
            "PIXEL_0007 → shape: (1, 512)\n",
            "PIXEL_0008 → shape: (3, 512)\n",
            "PIXEL_0009 → shape: (1, 512)\n",
            "PIXEL_0010 → shape: (1, 512)\n",
            "PIXEL_0011 → shape: (1, 512)\n",
            "PIXEL_0012 → shape: (1, 512)\n",
            "PIXEL_0013 → shape: (1, 512)\n",
            "PIXEL_0014 → shape: (1, 512)\n",
            "PIXEL_0015 → shape: (1, 512)\n",
            "PIXEL_0016 → shape: (1, 512)\n",
            "PIXEL_0017 → shape: (1, 512)\n",
            "PIXEL_0018 → shape: (1, 512)\n",
            "PIXEL_0019 → shape: (1, 512)\n",
            "PIXEL_0020 → shape: (1, 512)\n",
            "PIXEL_0021 → shape: (1, 512)\n",
            "PIXEL_0022 → shape: (1, 512)\n",
            "PIXEL_0023 → shape: (1, 512)\n",
            "PIXEL_0024 → shape: (1, 512)\n",
            "PIXEL_0025 → shape: (3, 512)\n",
            "PIXEL_0026 → shape: (3, 512)\n",
            "PIXEL_0027 → shape: (3, 512)\n",
            "PIXEL_0028 → shape: (1, 512)\n",
            "PIXEL_0029 → shape: (1, 512)\n",
            "PIXEL_0030 → shape: (1, 512)\n",
            "PIXEL_0031 → shape: (1, 512)\n",
            "PIXEL_0032 → shape: (1, 512)\n",
            "PIXEL_0033 → shape: (1, 512)\n",
            "PIXEL_0034 → shape: (1, 512)\n",
            "PIXEL_0035 → shape: (1, 512)\n",
            "PIXEL_0036 → shape: (1, 512)\n",
            "PIXEL_0037 → shape: (1, 512)\n",
            "PIXEL_0038 → shape: (1, 512)\n",
            "PIXEL_0039 → shape: (1, 512)\n",
            "PIXEL_0040 → shape: (1, 512)\n",
            "PIXEL_0041 → shape: (1, 512)\n",
            "PIXEL_0042 → shape: (1, 512)\n",
            "PIXEL_0043 → shape: (3, 512)\n",
            "PIXEL_0044 → shape: (1, 512)\n",
            "PIXEL_0045 → shape: (1, 512)\n",
            "PIXEL_0046 → shape: (1, 512)\n",
            "PIXEL_0047 → shape: (1, 512)\n",
            "PIXEL_0048 → shape: (1, 512)\n",
            "PIXEL_0049 → shape: (3, 512)\n",
            "PIXEL_0050 → shape: (1, 512)\n",
            "PIXEL_0051 → shape: (1, 512)\n",
            "PIXEL_0052 → shape: (3, 512)\n",
            "PIXEL_0053 → shape: (1, 512)\n",
            "PIXEL_0054 → shape: (1, 512)\n",
            "PIXEL_0055 → shape: (1, 512)\n",
            "PIXEL_0056 → shape: (3, 512)\n",
            "PIXEL_0057 → shape: (3, 512)\n",
            "PIXEL_0058 → shape: (1, 512)\n",
            "PIXEL_0059 → shape: (1, 512)\n",
            "PIXEL_0060 → shape: (3, 512)\n",
            "PIXEL_0061 → shape: (1, 512)\n",
            "PIXEL_0062 → shape: (1, 512)\n",
            "PIXEL_0063 → shape: (1, 512)\n",
            "PIXEL_0064 → shape: (1, 512)\n",
            "PIXEL_0065 → shape: (1, 512)\n",
            "PIXEL_0066 → shape: (1, 512)\n",
            "PIXEL_0067 → shape: (4, 512)\n",
            "PIXEL_0068 → shape: (1, 512)\n",
            "PIXEL_0069 → shape: (1, 512)\n",
            "PIXEL_0070 → shape: (1, 512)\n",
            "PIXEL_0071 → shape: (1, 512)\n",
            "PIXEL_0072 → shape: (1, 512)\n",
            "PIXEL_0073 → shape: (1, 512)\n",
            "PIXEL_0074 → shape: (1, 512)\n",
            "PIXEL_0075 → shape: (1, 512)\n",
            "PIXEL_0076 → shape: (3, 512)\n",
            "PIXEL_0077 → shape: (1, 512)\n",
            "PIXEL_0078 → shape: (1, 512)\n",
            "PIXEL_0079 → shape: (1, 512)\n",
            "PIXEL_0080 → shape: (3, 512)\n",
            "PIXEL_0081 → shape: (1, 512)\n",
            "PIXEL_0082 → shape: (3, 512)\n",
            "PIXEL_0083 → shape: (1, 512)\n",
            "PIXEL_0084 → shape: (1, 512)\n",
            "PIXEL_0085 → shape: (1, 512)\n",
            "PIXEL_0086 → shape: (1, 512)\n",
            "PIXEL_0087 → shape: (1, 512)\n",
            "PIXEL_0088 → shape: (3, 512)\n",
            "PIXEL_0089 → shape: (3, 512)\n",
            "PIXEL_0090 → shape: (1, 512)\n",
            "PIXEL_0091 → shape: (1, 512)\n",
            "PIXEL_0092 → shape: (1, 512)\n",
            "PIXEL_0093 → shape: (1, 512)\n",
            "PIXEL_0094 → shape: (1, 512)\n",
            "PIXEL_0095 → shape: (3, 512)\n",
            "PIXEL_0096 → shape: (1, 512)\n",
            "PIXEL_0097 → shape: (1, 512)\n",
            "PIXEL_0098 → shape: (3, 512)\n",
            "PIXEL_0099 → shape: (1, 512)\n",
            "PIXEL_0100 → shape: (1, 512)\n",
            "PIXEL_0101 → shape: (1, 512)\n",
            "PIXEL_0102 → shape: (1, 512)\n",
            "PIXEL_0103 → shape: (1, 512)\n",
            "PIXEL_0104 → shape: (1, 512)\n",
            "PIXEL_0105 → shape: (1, 512)\n",
            "PIXEL_0106 → shape: (1, 512)\n",
            "PIXEL_0107 → shape: (1, 512)\n",
            "PIXEL_0108 → shape: (1, 512)\n",
            "PIXEL_0109 → shape: (3, 512)\n",
            "PIXEL_0110 → shape: (1, 512)\n",
            "PIXEL_0111 → shape: (2, 512)\n",
            "PIXEL_0112 → shape: (1, 512)\n",
            "PIXEL_0113 → shape: (3, 512)\n",
            "PIXEL_0114 → shape: (3, 512)\n",
            "PIXEL_0115 → shape: (1, 512)\n",
            "PIXEL_0116 → shape: (1, 512)\n",
            "PIXEL_0117 → shape: (1, 512)\n",
            "PIXEL_0118 → shape: (1, 512)\n",
            "PIXEL_0119 → shape: (1, 512)\n",
            "PIXEL_0120 → shape: (1, 512)\n",
            "PIXEL_0121 → shape: (1, 512)\n",
            "PIXEL_0122 → shape: (1, 512)\n",
            "PIXEL_0123 → shape: (3, 512)\n",
            "PIXEL_0124 → shape: (1, 512)\n",
            "PIXEL_0125 → shape: (3, 512)\n",
            "PIXEL_0126 → shape: (1, 512)\n",
            "PIXEL_0127 → shape: (1, 512)\n",
            "PIXEL_0128 → shape: (1, 512)\n",
            "PIXEL_0129 → shape: (1, 512)\n",
            "PIXEL_0130 → shape: (1, 512)\n",
            "PIXEL_0131 → shape: (1, 512)\n",
            "PIXEL_0132 → shape: (1, 512)\n",
            "PIXEL_0133 → shape: (3, 512)\n",
            "PIXEL_0134 → shape: (1, 512)\n",
            "PIXEL_0135 → shape: (3, 512)\n",
            "PIXEL_0136 → shape: (3, 512)\n",
            "PIXEL_0137 → shape: (3, 512)\n",
            "PIXEL_0138 → shape: (1, 512)\n",
            "PIXEL_0139 → shape: (1, 512)\n",
            "PIXEL_0140 → shape: (1, 512)\n",
            "PIXEL_0141 → shape: (1, 512)\n",
            "PIXEL_0142 → shape: (1, 512)\n",
            "PIXEL_0143 → shape: (1, 512)\n",
            "PIXEL_0144 → shape: (1, 512)\n",
            "PIXEL_0145 → shape: (1, 512)\n",
            "PIXEL_0146 → shape: (1, 512)\n",
            "PIXEL_0147 → shape: (1, 512)\n",
            "PIXEL_0148 → shape: (1, 512)\n",
            "PIXEL_0149 → shape: (3, 512)\n",
            "PIXEL_0150 → shape: (3, 512)\n",
            "PIXEL_0151 → shape: (3, 512)\n",
            "PIXEL_0152 → shape: (1, 512)\n",
            "PIXEL_0153 → shape: (1, 512)\n",
            "PIXEL_0154 → shape: (1, 512)\n",
            "PIXEL_0155 → shape: (1, 512)\n",
            "PIXEL_0156 → shape: (3, 512)\n",
            "PIXEL_0157 → shape: (1, 512)\n",
            "PIXEL_0158 → shape: (1, 512)\n",
            "PIXEL_0159 → shape: (1, 512)\n",
            "PIXEL_0160 → shape: (1, 512)\n",
            "PIXEL_0161 → shape: (1, 512)\n",
            "PIXEL_0162 → shape: (1, 512)\n",
            "PIXEL_0163 → shape: (1, 512)\n",
            "PIXEL_0164 → shape: (1, 512)\n",
            "PIXEL_0165 → shape: (1, 512)\n",
            "PIXEL_0166 → shape: (1, 512)\n",
            "PIXEL_0167 → shape: (1, 512)\n",
            "PIXEL_0168 → shape: (1, 512)\n",
            "PIXEL_0169 → shape: (1, 512)\n",
            "PIXEL_0170 → shape: (1, 512)\n",
            "PIXEL_0171 → shape: (3, 512)\n",
            "PIXEL_0172 → shape: (1, 512)\n",
            "PIXEL_0173 → shape: (1, 512)\n",
            "PIXEL_0174 → shape: (1, 512)\n",
            "PIXEL_0175 → shape: (1, 512)\n",
            "PIXEL_0176 → shape: (1, 512)\n",
            "PIXEL_0177 → shape: (1, 512)\n",
            "PIXEL_0178 → shape: (1, 512)\n",
            "PIXEL_0179 → shape: (1, 512)\n",
            "PIXEL_0180 → shape: (1, 512)\n",
            "PIXEL_0181 → shape: (1, 512)\n",
            "PIXEL_0182 → shape: (1, 512)\n",
            "PIXEL_0183 → shape: (1, 512)\n",
            "PIXEL_0184 → shape: (1, 512)\n",
            "PIXEL_0185 → shape: (1, 512)\n",
            "PIXEL_0186 → shape: (3, 512)\n",
            "PIXEL_0187 → shape: (1, 512)\n",
            "PIXEL_0188 → shape: (3, 512)\n",
            "PIXEL_0189 → shape: (1, 512)\n",
            "PIXEL_0190 → shape: (1, 512)\n",
            "PIXEL_0191 → shape: (1, 512)\n",
            "PIXEL_0192 → shape: (1, 512)\n",
            "PIXEL_0193 → shape: (1, 512)\n",
            "PIXEL_0194 → shape: (1, 512)\n",
            "PIXEL_0195 → shape: (1, 512)\n",
            "PIXEL_0196 → shape: (1, 512)\n",
            "PIXEL_0197 → shape: (3, 512)\n",
            "PIXEL_0198 → shape: (3, 512)\n",
            "PIXEL_0199 → shape: (1, 512)\n",
            "PIXEL_0200 → shape: (3, 512)\n",
            "PIXEL_0201 → shape: (1, 512)\n",
            "PIXEL_0202 → shape: (1, 512)\n",
            "PIXEL_0203 → shape: (1, 512)\n",
            "PIXEL_0204 → shape: (1, 512)\n",
            "PIXEL_0205 → shape: (1, 512)\n",
            "PIXEL_0206 → shape: (1, 512)\n",
            "PIXEL_0207 → shape: (1, 512)\n",
            "PIXEL_0208 → shape: (1, 512)\n",
            "PIXEL_0209 → shape: (1, 512)\n",
            "PIXEL_0210 → shape: (1, 512)\n",
            "PIXEL_0211 → shape: (1, 512)\n",
            "PIXEL_0212 → shape: (1, 512)\n",
            "PIXEL_0213 → shape: (1, 512)\n",
            "PIXEL_0214 → shape: (1, 512)\n",
            "PIXEL_0215 → shape: (1, 512)\n",
            "PIXEL_0216 → shape: (1, 512)\n",
            "PIXEL_0217 → shape: (1, 512)\n",
            "PIXEL_0218 → shape: (1, 512)\n",
            "PIXEL_0219 → shape: (1, 512)\n",
            "PIXEL_0220 → shape: (3, 512)\n",
            "PIXEL_0221 → shape: (1, 512)\n",
            "PIXEL_0222 → shape: (3, 512)\n",
            "PIXEL_0223 → shape: (1, 512)\n",
            "PIXEL_0224 → shape: (1, 512)\n",
            "PIXEL_0225 → shape: (1, 512)\n",
            "PIXEL_0226 → shape: (1, 512)\n",
            "PIXEL_0227 → shape: (3, 512)\n",
            "PIXEL_0228 → shape: (1, 512)\n",
            "PIXEL_0229 → shape: (1, 512)\n",
            "PIXEL_0230 → shape: (1, 512)\n",
            "PIXEL_0231 → shape: (1, 512)\n",
            "PIXEL_0232 → shape: (1, 512)\n",
            "PIXEL_0233 → shape: (1, 512)\n",
            "PIXEL_0234 → shape: (1, 512)\n",
            "PIXEL_0235 → shape: (1, 512)\n",
            "PIXEL_0236 → shape: (1, 512)\n",
            "PIXEL_0237 → shape: (1, 512)\n",
            "PIXEL_0238 → shape: (1, 512)\n",
            "PIXEL_0239 → shape: (1, 512)\n",
            "PIXEL_0240 → shape: (1, 512)\n",
            "PIXEL_0241 → shape: (1, 512)\n",
            "PIXEL_0242 → shape: (3, 512)\n",
            "PIXEL_0243 → shape: (1, 512)\n",
            "PIXEL_0244 → shape: (1, 512)\n",
            "PIXEL_0245 → shape: (1, 512)\n",
            "PIXEL_0246 → shape: (1, 512)\n",
            "PIXEL_0247 → shape: (1, 512)\n",
            "PIXEL_0248 → shape: (1, 512)\n",
            "PIXEL_0249 → shape: (3, 512)\n",
            "PIXEL_0250 → shape: (1, 512)\n",
            "PIXEL_0251 → shape: (4, 512)\n",
            "PIXEL_0252 → shape: (1, 512)\n",
            "PIXEL_0253 → shape: (1, 512)\n",
            "PIXEL_0254 → shape: (1, 512)\n",
            "PIXEL_0255 → shape: (1, 512)\n",
            "PIXEL_0256 → shape: (1, 512)\n",
            "PIXEL_0257 → shape: (1, 512)\n",
            "PIXEL_0258 → shape: (1, 512)\n",
            "PIXEL_0259 → shape: (1, 512)\n",
            "PIXEL_0260 → shape: (1, 512)\n",
            "PIXEL_0261 → shape: (1, 512)\n",
            "PIXEL_0262 → shape: (1, 512)\n",
            "PIXEL_0263 → shape: (1, 512)\n",
            "PIXEL_0264 → shape: (1, 512)\n",
            "PIXEL_0265 → shape: (1, 512)\n",
            "PIXEL_0266 → shape: (1, 512)\n",
            "PIXEL_0267 → shape: (1, 512)\n",
            "PIXEL_0268 → shape: (1, 512)\n",
            "PIXEL_0269 → shape: (1, 512)\n",
            "PIXEL_0270 → shape: (1, 512)\n",
            "PIXEL_0271 → shape: (1, 512)\n",
            "PIXEL_0272 → shape: (1, 512)\n",
            "PIXEL_0273 → shape: (1, 512)\n",
            "PIXEL_0274 → shape: (1, 512)\n",
            "PIXEL_0275 → shape: (1, 512)\n",
            "PIXEL_0276 → shape: (2, 512)\n",
            "PIXEL_0277 → shape: (1, 512)\n",
            "PIXEL_0278 → shape: (1, 512)\n",
            "PIXEL_0279 → shape: (1, 512)\n",
            "PIXEL_0280 → shape: (1, 512)\n",
            "PIXEL_0281 → shape: (1, 512)\n",
            "PIXEL_0282 → shape: (3, 512)\n",
            "PIXEL_0283 → shape: (1, 512)\n",
            "PIXEL_0284 → shape: (1, 512)\n",
            "PIXEL_0285 → shape: (1, 512)\n",
            "PIXEL_0286 → shape: (3, 512)\n",
            "PIXEL_0287 → shape: (3, 512)\n",
            "PIXEL_0288 → shape: (1, 512)\n",
            "PIXEL_0289 → shape: (3, 512)\n",
            "PIXEL_0290 → shape: (1, 512)\n",
            "PIXEL_0291 → shape: (1, 512)\n",
            "PIXEL_0292 → shape: (1, 512)\n",
            "PIXEL_0293 → shape: (3, 512)\n",
            "PIXEL_0294 → shape: (1, 512)\n",
            "PIXEL_0295 → shape: (1, 512)\n",
            "PIXEL_0296 → shape: (1, 512)\n",
            "PIXEL_0297 → shape: (1, 512)\n",
            "PIXEL_0298 → shape: (1, 512)\n",
            "PIXEL_0299 → shape: (1, 512)\n",
            "PIXEL_0300 → shape: (1, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_train_embeddings = []\n",
        "labels = []\n",
        "\n",
        "for uid, cls_list in cls_embeddings.items():\n",
        "    agg_embedding = mean_aggregator(cls_list)  # ✅ Full mean pooling, no splitting\n",
        "    final_train_embeddings.append(agg_embedding)\n",
        "\n",
        "    crop_type = train_df.loc[train_df['unique_id'] == uid, 'crop_type'].iloc[0]\n",
        "    labels.append(crop_type)\n"
      ],
      "metadata": {
        "id": "JFCBi13v3zF0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_embeddings = []\n",
        "test_uids = []\n",
        "\n",
        "for uid, cls_list in cls_embeddings_test.items():\n",
        "    agg_embedding = mean_aggregator(cls_list)  # ✅ Full mean over all CLS tokens\n",
        "    final_test_embeddings.append(agg_embedding)\n",
        "    test_uids.append(uid)  # Optional: useful for mapping back later\n"
      ],
      "metadata": {
        "id": "FSuPwTM08L4O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Updated label map with correct crop type names\n",
        "label_map = {'cocoa': 0, 'rubber': 1, 'oil': 2}  # 'oil' instead of 'oil_palm'\n",
        "\n",
        "# Extract the first crop_type per unique_id\n",
        "pixel_labels = train_df.groupby('unique_id').first()['crop_type']\n",
        "\n",
        "# Map crop types to integer labels\n",
        "labels = pixel_labels.map(label_map)\n",
        "\n",
        "# Drop any unmapped values (NaN) and convert to integer array\n",
        "labels = labels.dropna().astype(int).values\n",
        "\n",
        "# Output shape and distribution\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "print(\"Label distribution:\", np.bincount(labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXCjhzJFks5e",
        "outputId": "37712ed5-f9e5-44ed-84e4-d5cda4c95dc4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels shape: (300,)\n",
            "Label distribution: [100 100 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.array(final_train_embeddings)  # shape: [num_pixels, 512]\n",
        "y_train = np.array(labels)  # shape: [num_pixels]\n"
      ],
      "metadata": {
        "id": "_xpjOaSA_fWy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sQxtxSy_i2M",
        "outputId": "f391b65d-f245-40d8-cb5c-f27487f06851"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 512) (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "\n",
        "# Optional: get label → crop name mapping\n",
        "class_names = le.classes_\n"
      ],
      "metadata": {
        "id": "6j3RxypcAklc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(final_train_embeddings)\n",
        "\n",
        "# Flatten from shape [N, 1, 512] → [N, 512] if needed\n",
        "if X_train.ndim == 3 and X_train.shape[1] == 1:\n",
        "    X_train = X_train.squeeze(1)\n"
      ],
      "metadata": {
        "id": "GGly67JFBIgL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)  # should be (N, 512)\n",
        "print(\"y_train shape:\", y_train.shape)  # should be (N,)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFJPMz4joo_X",
        "outputId": "5dec9ca2-7ab9-435a-f29a-47938ce71275"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (300, 512)\n",
            "y_train shape: (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train = np.array(final_train_embeddings)\n",
        "y_train = np.array(y_train_encoded)\n",
        "\n",
        "# ✅ FIX THE SHAPE\n",
        "if X_train.ndim == 3 and X_train.shape[1] == 1:\n",
        "    X_train = X_train.squeeze(1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial',class_weight='balanced')\n",
        "clf.fit(X_tr, y_tr)\n"
      ],
      "metadata": {
        "id": "2kKV26OOPyUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e15d3a38-a8b5-46ac-d542-21264d083a07"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(class_weight='balanced', max_iter=1000,\n",
              "                   multi_class='multinomial')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   multi_class=&#x27;multinomial&#x27;)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "y_pred_val = clf.predict(X_val)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred_val):.4f}\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred_val)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Validation Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "KEgc7_DNkJ2b",
        "outputId": "c4909bbb-601d-49b2-882f-4da26aecce5a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2833\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.20      0.20        20\n",
            "           1       0.39      0.45      0.42        20\n",
            "           2       0.25      0.20      0.22        20\n",
            "\n",
            "    accuracy                           0.28        60\n",
            "   macro avg       0.28      0.28      0.28        60\n",
            "weighted avg       0.28      0.28      0.28        60\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "clf.fit(X_tr, y_tr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "oMmjfjV5nArp",
        "outputId": "da4a1293-7227-479b-b40a-a955db8b058b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Predict class probabilities on validation set\n",
        "y_proba_val = clf.predict_proba(X_val)\n",
        "\n",
        "# Compute log loss\n",
        "val_log_loss = log_loss(y_val, y_proba_val)\n",
        "\n",
        "print(f\"Validation Log Loss: {val_log_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZLgPnzJnSZF",
        "outputId": "5397e7a7-df1b-4015-9c5d-8b32cd9426fe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Log Loss: 1.0999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict using trained model\n",
        "y_pred = clf.predict(X_train)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_train, y_pred)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "# Plot it\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "CHX4Sp2gcWK_",
        "outputId": "205de6e5-eb62-48e5-cc63-3228f1f05a70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9433\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94       100\n",
            "           1       0.92      0.94      0.93       100\n",
            "           2       0.96      0.95      0.95       100\n",
            "\n",
            "    accuracy                           0.94       300\n",
            "   macro avg       0.94      0.94      0.94       300\n",
            "weighted avg       0.94      0.94      0.94       300\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Ensure X_test is ready\n",
        "X_test = np.array(final_test_embeddings)\n",
        "if X_test.ndim == 3 and X_test.shape[1] == 1:\n",
        "    X_test = X_test.squeeze(1)\n",
        "\n",
        "# 2️⃣ Get class probabilities using predict_proba\n",
        "probs = clf.predict_proba(X_test)  # shape: [N, 3]\n",
        "\n",
        "# 3️⃣ Map columns to class names from LabelEncoder\n",
        "class_names = le.inverse_transform(np.arange(probs.shape[1]))  # ['cocoa', 'rubber', 'oil']\n",
        "\n",
        "# 4️⃣ Create DataFrame with unique_id and class probabilities\n",
        "probs_df = pd.DataFrame(probs, columns=class_names)\n",
        "probs_df.insert(0, \"unique_id\", test_uids)  # Add UIDs to front\n",
        "\n",
        "# 5️⃣ Optional: round for presentation\n",
        "probs_df = probs_df.round(3)\n",
        "\n",
        "# Preview\n",
        "print(probs_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CsO6skrhF_B",
        "outputId": "cca32aee-b552-4e67-abb5-790b49391202"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   unique_id      0      1      2\n",
            "0  ID_002AIV  0.174  0.699  0.127\n",
            "1  ID_0042EI  0.491  0.361  0.148\n",
            "2  ID_008SD4  0.408  0.363  0.229\n",
            "3  ID_00AQE9  0.254  0.632  0.114\n",
            "4  ID_00F4A9  0.656  0.303  0.041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs_df.to_csv(\"test_probabilities.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "KsefkRyShF82"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IrWVsmG_hF6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKb5hzV6hF1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19c5799fdc7f40258f28f1568a967de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79099b1ded42423fb22479cd36217db6",
              "IPY_MODEL_f41396ad91fd41e5848fbdbbc263b358",
              "IPY_MODEL_18a0d4c6ef4a42bba8f996c090accc19"
            ],
            "layout": "IPY_MODEL_942f9db83e2d48e3a3812f5c2c873a05"
          }
        },
        "79099b1ded42423fb22479cd36217db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d14bd34c3484a188062a12c82a91ba8",
            "placeholder": "​",
            "style": "IPY_MODEL_5518ec3258d14c75b5e663ee7c0bb0c5",
            "value": "config.json: "
          }
        },
        "f41396ad91fd41e5848fbdbbc263b358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a88839dce48f4ff38353a64edc9be18c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f14d99d894cc4a4c9abd2e77b0bd3fbe",
            "value": 1
          }
        },
        "18a0d4c6ef4a42bba8f996c090accc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c63246cbff45d28042aae86152eeba",
            "placeholder": "​",
            "style": "IPY_MODEL_24e8273d1b8a4348a95fbf4d48f6c6e2",
            "value": " 1.19k/? [00:00&lt;00:00, 90.2kB/s]"
          }
        },
        "942f9db83e2d48e3a3812f5c2c873a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d14bd34c3484a188062a12c82a91ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5518ec3258d14c75b5e663ee7c0bb0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a88839dce48f4ff38353a64edc9be18c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f14d99d894cc4a4c9abd2e77b0bd3fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29c63246cbff45d28042aae86152eeba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e8273d1b8a4348a95fbf4d48f6c6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb9c4ef904548eaaaa8fe37c94588ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2337e161ffbc4334af4b948da716ea59",
              "IPY_MODEL_5dcd8406094547f7b9cf788beba99dba",
              "IPY_MODEL_d24dacc1c21e4418ade4fecf1aa21040"
            ],
            "layout": "IPY_MODEL_ff8072efb457436696c3df1f40111063"
          }
        },
        "2337e161ffbc4334af4b948da716ea59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4df50ccb6249c7bd4b829139440b4d",
            "placeholder": "​",
            "style": "IPY_MODEL_dfae76d3452049c5b70c762abb8d7f1c",
            "value": "model.safetensors: 100%"
          }
        },
        "5dcd8406094547f7b9cf788beba99dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c81114c28e6e471485edf3857e1ec627",
            "max": 75757968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_decbf00bc3a84733a166c28443073881",
            "value": 75757968
          }
        },
        "d24dacc1c21e4418ade4fecf1aa21040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7885ae2379044158dcec2d28a331fb1",
            "placeholder": "​",
            "style": "IPY_MODEL_f23293cddadc4e80a8636a80d79fa68d",
            "value": " 75.8M/75.8M [00:00&lt;00:00, 97.1MB/s]"
          }
        },
        "ff8072efb457436696c3df1f40111063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4df50ccb6249c7bd4b829139440b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfae76d3452049c5b70c762abb8d7f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c81114c28e6e471485edf3857e1ec627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "decbf00bc3a84733a166c28443073881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7885ae2379044158dcec2d28a331fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23293cddadc4e80a8636a80d79fa68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}