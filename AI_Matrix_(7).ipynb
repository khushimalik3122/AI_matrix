{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3lwk4UU5gSa",
        "outputId": "93af95d3-24bf-49f1-d35c-0b5236f855ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23iQnn8b1Kow",
        "outputId": "dc31963c-ed66-42a1-e6ae-9f97868868ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# Accessing the secret key from Colab secrets\n",
        "hf_token = userdata.get(\"HF_API_KEY\")\n",
        "\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "else:\n",
        "    raise ValueError(\"Hugging Face token not found in Colab secrets 'Colab_HF_token'\")"
      ],
      "metadata": {
        "id": "k1q0nSXb057Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oOAb5mFbpTjj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOla_bDCnG5Y"
      },
      "source": [
        "**Load and Preprocess Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SjCvvAZb9HkY",
        "outputId": "00908850-aab0-49e3-f56e-42ca16778aba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unique_id                     time         x         y     red     nir  \\\n",
              "0  ID_01FHV4  2018-01-03 10:59:22.851 -296455.0  846395.0  0.2920  0.3686   \n",
              "1  ID_01FHV4  2018-01-03 10:59:22.851 -296455.0  846395.0  0.2920  0.3686   \n",
              "2  ID_01FHV4  2018-02-12 10:59:25.232 -296455.0  846395.0  0.3510  0.3426   \n",
              "3  ID_01FHV4  2018-02-12 10:59:25.232 -296455.0  846395.0  0.3510  0.3426   \n",
              "4  ID_01FHV4  2018-03-14 10:59:24.436 -296455.0  846395.0  0.5312  0.6296   \n",
              "\n",
              "   swir16  swir22    blue   green  rededge1  rededge2  rededge3   nir08  \n",
              "0  0.4173  0.3869  0.2488  0.2708    0.3211    0.3555    0.3752  0.3862  \n",
              "1  0.4173  0.3869  0.2488  0.2708    0.3211    0.3555    0.3752  0.3862  \n",
              "2  0.4817  0.4577  0.2538  0.2914    0.3684    0.3484    0.3588  0.3628  \n",
              "3  0.4817  0.4577  0.2538  0.2914    0.3684    0.3484    0.3588  0.3628  \n",
              "4  0.6643  0.5882  0.5244  0.5308    0.6016    0.6217    0.6401  0.6404  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bddb84e-96c0-4b05-9b47-f169d3f597df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>time</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>red</th>\n",
              "      <th>nir</th>\n",
              "      <th>swir16</th>\n",
              "      <th>swir22</th>\n",
              "      <th>blue</th>\n",
              "      <th>green</th>\n",
              "      <th>rededge1</th>\n",
              "      <th>rededge2</th>\n",
              "      <th>rededge3</th>\n",
              "      <th>nir08</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-01-03 10:59:22.851</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>0.3686</td>\n",
              "      <td>0.4173</td>\n",
              "      <td>0.3869</td>\n",
              "      <td>0.2488</td>\n",
              "      <td>0.2708</td>\n",
              "      <td>0.3211</td>\n",
              "      <td>0.3555</td>\n",
              "      <td>0.3752</td>\n",
              "      <td>0.3862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-01-03 10:59:22.851</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>0.3686</td>\n",
              "      <td>0.4173</td>\n",
              "      <td>0.3869</td>\n",
              "      <td>0.2488</td>\n",
              "      <td>0.2708</td>\n",
              "      <td>0.3211</td>\n",
              "      <td>0.3555</td>\n",
              "      <td>0.3752</td>\n",
              "      <td>0.3862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-02-12 10:59:25.232</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.3510</td>\n",
              "      <td>0.3426</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.4577</td>\n",
              "      <td>0.2538</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.3684</td>\n",
              "      <td>0.3484</td>\n",
              "      <td>0.3588</td>\n",
              "      <td>0.3628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-02-12 10:59:25.232</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.3510</td>\n",
              "      <td>0.3426</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.4577</td>\n",
              "      <td>0.2538</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.3684</td>\n",
              "      <td>0.3484</td>\n",
              "      <td>0.3588</td>\n",
              "      <td>0.3628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_01FHV4</td>\n",
              "      <td>2018-03-14 10:59:24.436</td>\n",
              "      <td>-296455.0</td>\n",
              "      <td>846395.0</td>\n",
              "      <td>0.5312</td>\n",
              "      <td>0.6296</td>\n",
              "      <td>0.6643</td>\n",
              "      <td>0.5882</td>\n",
              "      <td>0.5244</td>\n",
              "      <td>0.5308</td>\n",
              "      <td>0.6016</td>\n",
              "      <td>0.6217</td>\n",
              "      <td>0.6401</td>\n",
              "      <td>0.6404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bddb84e-96c0-4b05-9b47-f169d3f597df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0bddb84e-96c0-4b05-9b47-f169d3f597df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0bddb84e-96c0-4b05-9b47-f169d3f597df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-769a766a-b44d-4dcc-8cb2-4d0efcb92dd0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-769a766a-b44d-4dcc-8cb2-4d0efcb92dd0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-769a766a-b44d-4dcc-8cb2-4d0efcb92dd0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/test (6).csv')\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4PfQfdag5ah3",
        "outputId": "59c714c3-78cc-4e16-89ef-57efe7b39bac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   blue crop_type  green   nir  nir08   red  rededge1  rededge2  rededge3  \\\n",
              "0   559     cocoa    771  2404   2585   846      1240      2006      2326   \n",
              "1   537     cocoa    916  2448   2750  1096      1464      2124      2390   \n",
              "2   540     cocoa    877  2402   2498  1084      1415      1943      2184   \n",
              "3  1944     cocoa   2094  3076   3307  2260      2537      2809      3043   \n",
              "4  2062     cocoa   2092  2484   2599  2210      2293      2371      2529   \n",
              "\n",
              "   swir16  swir22        time   unique_id         x         y  \n",
              "0    2630    1684  2022-01-03  PIXEL_0001  0.957526  6.899852  \n",
              "1    2851    1823  2022-01-08  PIXEL_0001  0.957526  6.899852  \n",
              "2    3069    2100  2022-01-23  PIXEL_0001  0.957526  6.899852  \n",
              "3    3887    2979  2022-01-28  PIXEL_0001  0.957526  6.899852  \n",
              "4    2837    2275  2022-02-12  PIXEL_0001  0.957526  6.899852  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6a54099-937f-4f53-897d-453afe2ea8c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>blue</th>\n",
              "      <th>crop_type</th>\n",
              "      <th>green</th>\n",
              "      <th>nir</th>\n",
              "      <th>nir08</th>\n",
              "      <th>red</th>\n",
              "      <th>rededge1</th>\n",
              "      <th>rededge2</th>\n",
              "      <th>rededge3</th>\n",
              "      <th>swir16</th>\n",
              "      <th>swir22</th>\n",
              "      <th>time</th>\n",
              "      <th>unique_id</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>559</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>771</td>\n",
              "      <td>2404</td>\n",
              "      <td>2585</td>\n",
              "      <td>846</td>\n",
              "      <td>1240</td>\n",
              "      <td>2006</td>\n",
              "      <td>2326</td>\n",
              "      <td>2630</td>\n",
              "      <td>1684</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>537</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>916</td>\n",
              "      <td>2448</td>\n",
              "      <td>2750</td>\n",
              "      <td>1096</td>\n",
              "      <td>1464</td>\n",
              "      <td>2124</td>\n",
              "      <td>2390</td>\n",
              "      <td>2851</td>\n",
              "      <td>1823</td>\n",
              "      <td>2022-01-08</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>540</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>877</td>\n",
              "      <td>2402</td>\n",
              "      <td>2498</td>\n",
              "      <td>1084</td>\n",
              "      <td>1415</td>\n",
              "      <td>1943</td>\n",
              "      <td>2184</td>\n",
              "      <td>3069</td>\n",
              "      <td>2100</td>\n",
              "      <td>2022-01-23</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1944</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>2094</td>\n",
              "      <td>3076</td>\n",
              "      <td>3307</td>\n",
              "      <td>2260</td>\n",
              "      <td>2537</td>\n",
              "      <td>2809</td>\n",
              "      <td>3043</td>\n",
              "      <td>3887</td>\n",
              "      <td>2979</td>\n",
              "      <td>2022-01-28</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2062</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>2092</td>\n",
              "      <td>2484</td>\n",
              "      <td>2599</td>\n",
              "      <td>2210</td>\n",
              "      <td>2293</td>\n",
              "      <td>2371</td>\n",
              "      <td>2529</td>\n",
              "      <td>2837</td>\n",
              "      <td>2275</td>\n",
              "      <td>2022-02-12</td>\n",
              "      <td>PIXEL_0001</td>\n",
              "      <td>0.957526</td>\n",
              "      <td>6.899852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6a54099-937f-4f53-897d-453afe2ea8c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6a54099-937f-4f53-897d-453afe2ea8c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6a54099-937f-4f53-897d-453afe2ea8c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e991a4c6-eddb-4dd6-abb8-00cb788a1d7c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e991a4c6-eddb-4dd6-abb8-00cb788a1d7c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e991a4c6-eddb-4dd6-abb8-00cb788a1d7c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 18442,\n  \"fields\": [\n    {\n      \"column\": \"blue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 488,\n        \"min\": 179,\n        \"max\": 10728,\n        \"num_unique_values\": 1935,\n        \"samples\": [\n          2580,\n          2090,\n          2228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crop_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"cocoa\",\n          \"rubber\",\n          \"oil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"green\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 464,\n        \"min\": 387,\n        \"max\": 9160,\n        \"num_unique_values\": 1718,\n        \"samples\": [\n          1572,\n          2710,\n          2300\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nir\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 836,\n        \"min\": 916,\n        \"max\": 8296,\n        \"num_unique_values\": 3092,\n        \"samples\": [\n          3317,\n          3101,\n          2518\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nir08\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 884,\n        \"min\": 1112,\n        \"max\": 8410,\n        \"num_unique_values\": 3989,\n        \"samples\": [\n          5043,\n          3969,\n          6066\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"red\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 513,\n        \"min\": 361,\n        \"max\": 8480,\n        \"num_unique_values\": 1990,\n        \"samples\": [\n          954,\n          2834,\n          1812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rededge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 482,\n        \"min\": 739,\n        \"max\": 8705,\n        \"num_unique_values\": 2545,\n        \"samples\": [\n          2370,\n          1323,\n          905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rededge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 743,\n        \"min\": 859,\n        \"max\": 8287,\n        \"num_unique_values\": 3522,\n        \"samples\": [\n          4057,\n          4277,\n          5480\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rededge3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 871,\n        \"min\": 978,\n        \"max\": 8146,\n        \"num_unique_values\": 3940,\n        \"samples\": [\n          2772,\n          5559,\n          5090\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"swir16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 621,\n        \"min\": 1509,\n        \"max\": 8174,\n        \"num_unique_values\": 3042,\n        \"samples\": [\n          3322,\n          4682,\n          3640\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"swir22\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 697,\n        \"min\": 875,\n        \"max\": 6929,\n        \"num_unique_values\": 3182,\n        \"samples\": [\n          2590,\n          1442,\n          2034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 94,\n        \"samples\": [\n          \"2023-06-12\",\n          \"2022-12-09\",\n          \"2022-02-17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"PIXEL_0204\",\n          \"PIXEL_0267\",\n          \"PIXEL_0153\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12941993225545187,\n        \"min\": 0.737631256617266,\n        \"max\": 1.1896215931644405,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          0.8558330501088164,\n          0.8653348628582926,\n          0.853572500546085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1333326103363097,\n        \"min\": 6.780823163721891,\n        \"max\": 7.231648189646034,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          7.083970461978835,\n          6.985528934655409,\n          6.965861127156559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Sentinel2_CropSamples_Reorganized.csv')\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "BUdSGsQz9U__",
        "outputId": "690feb6e-1d9c-4597-ad1b-11a1d9dde0f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "crop_type\n",
              "cocoa     6359\n",
              "rubber    6283\n",
              "oil       5800\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>crop_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cocoa</th>\n",
              "      <td>6359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rubber</th>\n",
              "      <td>6283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oil</th>\n",
              "      <td>5800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_df['crop_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoConfig\n",
        "\n",
        "model_name = \"AminiTech/amini-28M-v1\"\n",
        "\n",
        "# Load model config and model (for PatchTST, not a language model!)\n",
        "config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(model_name, config=config, trust_remote_code=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207,
          "referenced_widgets": [
            "19c5799fdc7f40258f28f1568a967de4",
            "79099b1ded42423fb22479cd36217db6",
            "f41396ad91fd41e5848fbdbbc263b358",
            "18a0d4c6ef4a42bba8f996c090accc19",
            "942f9db83e2d48e3a3812f5c2c873a05",
            "5d14bd34c3484a188062a12c82a91ba8",
            "5518ec3258d14c75b5e663ee7c0bb0c5",
            "a88839dce48f4ff38353a64edc9be18c",
            "f14d99d894cc4a4c9abd2e77b0bd3fbe",
            "29c63246cbff45d28042aae86152eeba",
            "24e8273d1b8a4348a95fbf4d48f6c6e2",
            "afb9c4ef904548eaaaa8fe37c94588ed",
            "2337e161ffbc4334af4b948da716ea59",
            "5dcd8406094547f7b9cf788beba99dba",
            "d24dacc1c21e4418ade4fecf1aa21040",
            "ff8072efb457436696c3df1f40111063",
            "fa4df50ccb6249c7bd4b829139440b4d",
            "dfae76d3452049c5b70c762abb8d7f1c",
            "c81114c28e6e471485edf3857e1ec627",
            "decbf00bc3a84733a166c28443073881",
            "b7885ae2379044158dcec2d28a331fb1",
            "f23293cddadc4e80a8636a80d79fa68d"
          ]
        },
        "id": "I9eOWlKD1NnV",
        "outputId": "ec9abd0e-7540-4c4a-8ce1-35139b5bdeee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19c5799fdc7f40258f28f1568a967de4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/75.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afb9c4ef904548eaaaa8fe37c94588ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J16b8-QjEHNq",
        "outputId": "296efc16-7d3f-4a5b-aaf8-c5e2615d8e1e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchTSTModel(\n",
              "  (scaler): PatchTSTScaler(\n",
              "    (scaler): PatchTSTMeanScaler()\n",
              "  )\n",
              "  (patchifier): PatchTSTPatchify()\n",
              "  (masking): PatchTSTMasking()\n",
              "  (encoder): PatchTSTEncoder(\n",
              "    (embedder): PatchTSTEmbedding(\n",
              "      (input_embedding): Linear(in_features=12, out_features=512, bias=True)\n",
              "    )\n",
              "    (positional_encoder): PatchTSTPositionalEncoding(\n",
              "      (positional_dropout): Identity()\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x PatchTSTEncoderLayer(\n",
              "        (self_attn): PatchTSTAttention(\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (dropout_path1): Identity()\n",
              "        (norm_sublayer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout_path2): Identity()\n",
              "        (norm_sublayer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Identity()\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (dropout_path3): Identity()\n",
              "        (norm_sublayer3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_aggregator(cls_embeddings):\n",
        "    \"\"\"\n",
        "    Fully averages all CLS embeddings, no splitting.\n",
        "    Handles extra dimensions safely.\n",
        "\n",
        "    Args:\n",
        "        cls_embeddings: list or array of CLS tokens [n, 512] or [1, n, 512]\n",
        "    Returns:\n",
        "        final_embedding: mean [512]-dim vector\n",
        "    \"\"\"\n",
        "    cls_embeddings = np.array(cls_embeddings)\n",
        "\n",
        "    # Handle possible extra dimensions\n",
        "    if cls_embeddings.ndim == 3 and cls_embeddings.shape[1] == 1:\n",
        "        cls_embeddings = cls_embeddings.squeeze(1)\n",
        "    elif cls_embeddings.ndim == 1:\n",
        "        cls_embeddings = cls_embeddings.reshape(1, -1)  # shape: [1, 512]\n",
        "\n",
        "    return np.mean(cls_embeddings, axis=0)\n"
      ],
      "metadata": {
        "id": "BF82AtG13qEG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings_sliding_window(df, model, max_length=48, stride=24):\n",
        "    grouped = df.groupby('unique_id')\n",
        "    all_embeddings = {}\n",
        "\n",
        "    for unique_id, group in grouped:\n",
        "        group = group.sort_values('time')\n",
        "        features = group[['blue', 'green', 'nir', 'nir08', 'red', 'rededge1',\n",
        "                          'rededge2', 'rededge3', 'swir16', 'swir22']].values\n",
        "        sequence_length = len(features)\n",
        "        print(f\"[{unique_id}] Raw sequence length: {sequence_length}\")\n",
        "\n",
        "        # Normalize\n",
        "        features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-6)\n",
        "        cls_list = []\n",
        "\n",
        "        if sequence_length < max_length:\n",
        "            # Pad to 48\n",
        "            pad_len = max_length - sequence_length\n",
        "            padding = np.zeros((pad_len, features.shape[1]))\n",
        "            features_padded = np.vstack([features, padding])\n",
        "\n",
        "            tensor_input = torch.tensor(features_padded, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            print(f\"[{unique_id}] Padded input shape: {tensor_input.shape}\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                try:\n",
        "                    output = model(tensor_input)\n",
        "                    print(f\"[{unique_id}] Output type: {type(output)}\")\n",
        "                    print(f\"[{unique_id}] Output shape: {output.last_hidden_state.shape}\")\n",
        "\n",
        "                    #  CLS patch (index 0), mean across bands\n",
        "                    cls_token = output.last_hidden_state[:, :, 0, :].mean(dim=1).squeeze(0).cpu().numpy()\n",
        "                    assert cls_token.shape == (512,)\n",
        "                    cls_list.append(cls_token)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"[{unique_id}] Error during padded input: {type(e).__name__} - {e}\")\n",
        "                    continue\n",
        "\n",
        "        else:\n",
        "            # Sliding windows\n",
        "            for i in range(0, sequence_length - max_length + 1, stride):\n",
        "                window = features[i : i + max_length]\n",
        "                tensor_input = torch.tensor(window, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "                print(f\"[{unique_id}] Window {i} input shape: {tensor_input.shape}\")\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    try:\n",
        "                        output = model(tensor_input)\n",
        "                        print(f\"[{unique_id}] Output type: {type(output)}\")\n",
        "                        print(f\"[{unique_id}] Output shape: {output.last_hidden_state.shape}\")\n",
        "\n",
        "                        #  CLS patch token = patch index 0\n",
        "                        cls_token = output.last_hidden_state[:, :, 0, :].mean(dim=1).squeeze(0).cpu().numpy()\n",
        "                        assert cls_token.shape == (512,)\n",
        "                        cls_list.append(cls_token)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"[{unique_id}] Error at window {i}: {type(e).__name__} - {e}\")\n",
        "                        continue\n",
        "\n",
        "        if cls_list:\n",
        "            cls_array = np.array(cls_list)\n",
        "            print(f\"[{unique_id}] CLS token array shape: {cls_array.shape}\")  # e.g., (3, 512)\n",
        "            all_embeddings[unique_id] = cls_list\n",
        "        else:\n",
        "            print(f\"[{unique_id}] No CLS tokens generated\")\n",
        "\n",
        "    return all_embeddings\n"
      ],
      "metadata": {
        "id": "YEHroeWVEIgv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_embeddings = generate_embeddings_sliding_window(train_df, model, max_length=48, stride=24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYhZepvN3wgb",
        "outputId": "93a09697-9d23-4915-9729-47307d207194"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PIXEL_0001] Raw sequence length: 54\n",
            "[PIXEL_0001] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0001] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0001] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0001] CLS token array shape: (1, 512)\n",
            "[PIXEL_0002] Raw sequence length: 108\n",
            "[PIXEL_0002] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0002] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0002] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0002] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0002] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0002] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0002] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0002] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0002] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0002] CLS token array shape: (3, 512)\n",
            "[PIXEL_0003] Raw sequence length: 112\n",
            "[PIXEL_0003] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0003] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0003] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0003] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0003] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0003] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0003] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0003] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0003] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0003] CLS token array shape: (3, 512)\n",
            "[PIXEL_0004] Raw sequence length: 55\n",
            "[PIXEL_0004] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0004] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0004] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0004] CLS token array shape: (1, 512)\n",
            "[PIXEL_0005] Raw sequence length: 46\n",
            "[PIXEL_0005] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0005] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0005] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0005] CLS token array shape: (1, 512)\n",
            "[PIXEL_0006] Raw sequence length: 110\n",
            "[PIXEL_0006] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0006] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0006] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0006] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0006] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0006] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0006] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0006] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0006] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0006] CLS token array shape: (3, 512)\n",
            "[PIXEL_0007] Raw sequence length: 54\n",
            "[PIXEL_0007] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0007] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0007] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0007] CLS token array shape: (1, 512)\n",
            "[PIXEL_0008] Raw sequence length: 109\n",
            "[PIXEL_0008] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0008] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0008] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0008] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0008] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0008] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0008] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0008] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0008] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0008] CLS token array shape: (3, 512)\n",
            "[PIXEL_0009] Raw sequence length: 51\n",
            "[PIXEL_0009] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0009] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0009] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0009] CLS token array shape: (1, 512)\n",
            "[PIXEL_0010] Raw sequence length: 51\n",
            "[PIXEL_0010] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0010] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0010] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0010] CLS token array shape: (1, 512)\n",
            "[PIXEL_0011] Raw sequence length: 57\n",
            "[PIXEL_0011] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0011] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0011] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0011] CLS token array shape: (1, 512)\n",
            "[PIXEL_0012] Raw sequence length: 43\n",
            "[PIXEL_0012] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0012] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0012] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0012] CLS token array shape: (1, 512)\n",
            "[PIXEL_0013] Raw sequence length: 55\n",
            "[PIXEL_0013] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0013] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0013] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0013] CLS token array shape: (1, 512)\n",
            "[PIXEL_0014] Raw sequence length: 55\n",
            "[PIXEL_0014] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0014] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0014] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0014] CLS token array shape: (1, 512)\n",
            "[PIXEL_0015] Raw sequence length: 56\n",
            "[PIXEL_0015] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0015] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0015] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0015] CLS token array shape: (1, 512)\n",
            "[PIXEL_0016] Raw sequence length: 54\n",
            "[PIXEL_0016] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0016] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0016] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0016] CLS token array shape: (1, 512)\n",
            "[PIXEL_0017] Raw sequence length: 46\n",
            "[PIXEL_0017] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0017] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0017] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0017] CLS token array shape: (1, 512)\n",
            "[PIXEL_0018] Raw sequence length: 44\n",
            "[PIXEL_0018] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0018] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0018] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0018] CLS token array shape: (1, 512)\n",
            "[PIXEL_0019] Raw sequence length: 56\n",
            "[PIXEL_0019] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0019] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0019] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0019] CLS token array shape: (1, 512)\n",
            "[PIXEL_0020] Raw sequence length: 49\n",
            "[PIXEL_0020] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0020] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0020] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0020] CLS token array shape: (1, 512)\n",
            "[PIXEL_0021] Raw sequence length: 46\n",
            "[PIXEL_0021] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0021] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0021] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0021] CLS token array shape: (1, 512)\n",
            "[PIXEL_0022] Raw sequence length: 51\n",
            "[PIXEL_0022] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0022] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0022] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0022] CLS token array shape: (1, 512)\n",
            "[PIXEL_0023] Raw sequence length: 54\n",
            "[PIXEL_0023] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0023] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0023] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0023] CLS token array shape: (1, 512)\n",
            "[PIXEL_0024] Raw sequence length: 46\n",
            "[PIXEL_0024] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0024] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0024] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0024] CLS token array shape: (1, 512)\n",
            "[PIXEL_0025] Raw sequence length: 108\n",
            "[PIXEL_0025] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0025] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0025] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0025] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0025] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0025] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0025] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0025] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0025] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0025] CLS token array shape: (3, 512)\n",
            "[PIXEL_0026] Raw sequence length: 110\n",
            "[PIXEL_0026] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0026] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0026] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0026] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0026] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0026] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0026] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0026] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0026] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0026] CLS token array shape: (3, 512)\n",
            "[PIXEL_0027] Raw sequence length: 111\n",
            "[PIXEL_0027] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0027] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0027] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0027] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0027] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0027] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0027] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0027] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0027] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0027] CLS token array shape: (3, 512)\n",
            "[PIXEL_0028] Raw sequence length: 45\n",
            "[PIXEL_0028] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0028] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0028] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0028] CLS token array shape: (1, 512)\n",
            "[PIXEL_0029] Raw sequence length: 49\n",
            "[PIXEL_0029] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0029] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0029] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0029] CLS token array shape: (1, 512)\n",
            "[PIXEL_0030] Raw sequence length: 58\n",
            "[PIXEL_0030] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0030] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0030] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0030] CLS token array shape: (1, 512)\n",
            "[PIXEL_0031] Raw sequence length: 51\n",
            "[PIXEL_0031] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0031] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0031] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0031] CLS token array shape: (1, 512)\n",
            "[PIXEL_0032] Raw sequence length: 49\n",
            "[PIXEL_0032] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0032] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0032] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0032] CLS token array shape: (1, 512)\n",
            "[PIXEL_0033] Raw sequence length: 64\n",
            "[PIXEL_0033] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0033] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0033] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0033] CLS token array shape: (1, 512)\n",
            "[PIXEL_0034] Raw sequence length: 47\n",
            "[PIXEL_0034] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0034] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0034] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0034] CLS token array shape: (1, 512)\n",
            "[PIXEL_0035] Raw sequence length: 46\n",
            "[PIXEL_0035] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0035] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0035] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0035] CLS token array shape: (1, 512)\n",
            "[PIXEL_0036] Raw sequence length: 58\n",
            "[PIXEL_0036] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0036] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0036] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0036] CLS token array shape: (1, 512)\n",
            "[PIXEL_0037] Raw sequence length: 57\n",
            "[PIXEL_0037] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0037] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0037] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0037] CLS token array shape: (1, 512)\n",
            "[PIXEL_0038] Raw sequence length: 49\n",
            "[PIXEL_0038] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0038] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0038] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0038] CLS token array shape: (1, 512)\n",
            "[PIXEL_0039] Raw sequence length: 46\n",
            "[PIXEL_0039] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0039] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0039] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0039] CLS token array shape: (1, 512)\n",
            "[PIXEL_0040] Raw sequence length: 46\n",
            "[PIXEL_0040] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0040] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0040] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0040] CLS token array shape: (1, 512)\n",
            "[PIXEL_0041] Raw sequence length: 48\n",
            "[PIXEL_0041] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0041] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0041] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0041] CLS token array shape: (1, 512)\n",
            "[PIXEL_0042] Raw sequence length: 54\n",
            "[PIXEL_0042] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0042] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0042] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0042] CLS token array shape: (1, 512)\n",
            "[PIXEL_0043] Raw sequence length: 100\n",
            "[PIXEL_0043] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0043] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0043] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0043] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0043] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0043] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0043] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0043] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0043] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0043] CLS token array shape: (3, 512)\n",
            "[PIXEL_0044] Raw sequence length: 48\n",
            "[PIXEL_0044] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0044] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0044] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0044] CLS token array shape: (1, 512)\n",
            "[PIXEL_0045] Raw sequence length: 52\n",
            "[PIXEL_0045] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0045] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0045] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0045] CLS token array shape: (1, 512)\n",
            "[PIXEL_0046] Raw sequence length: 48\n",
            "[PIXEL_0046] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0046] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0046] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0046] CLS token array shape: (1, 512)\n",
            "[PIXEL_0047] Raw sequence length: 56\n",
            "[PIXEL_0047] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0047] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0047] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0047] CLS token array shape: (1, 512)\n",
            "[PIXEL_0048] Raw sequence length: 58\n",
            "[PIXEL_0048] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0048] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0048] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0048] CLS token array shape: (1, 512)\n",
            "[PIXEL_0049] Raw sequence length: 111\n",
            "[PIXEL_0049] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0049] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0049] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0049] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0049] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0049] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0049] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0049] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0049] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0049] CLS token array shape: (3, 512)\n",
            "[PIXEL_0050] Raw sequence length: 41\n",
            "[PIXEL_0050] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0050] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0050] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0050] CLS token array shape: (1, 512)\n",
            "[PIXEL_0051] Raw sequence length: 51\n",
            "[PIXEL_0051] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0051] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0051] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0051] CLS token array shape: (1, 512)\n",
            "[PIXEL_0052] Raw sequence length: 113\n",
            "[PIXEL_0052] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0052] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0052] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0052] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0052] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0052] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0052] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0052] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0052] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0052] CLS token array shape: (3, 512)\n",
            "[PIXEL_0053] Raw sequence length: 52\n",
            "[PIXEL_0053] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0053] CLS token array shape: (1, 512)\n",
            "[PIXEL_0054] Raw sequence length: 54\n",
            "[PIXEL_0054] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0054] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0054] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0054] CLS token array shape: (1, 512)\n",
            "[PIXEL_0055] Raw sequence length: 55\n",
            "[PIXEL_0055] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0055] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0055] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0055] CLS token array shape: (1, 512)\n",
            "[PIXEL_0056] Raw sequence length: 107\n",
            "[PIXEL_0056] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0056] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0056] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0056] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0056] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0056] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0056] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0056] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0056] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0056] CLS token array shape: (3, 512)\n",
            "[PIXEL_0057] Raw sequence length: 117\n",
            "[PIXEL_0057] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0057] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0057] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0057] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0057] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0057] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0057] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0057] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0057] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0057] CLS token array shape: (3, 512)\n",
            "[PIXEL_0058] Raw sequence length: 49\n",
            "[PIXEL_0058] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0058] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0058] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0058] CLS token array shape: (1, 512)\n",
            "[PIXEL_0059] Raw sequence length: 50\n",
            "[PIXEL_0059] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0059] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0059] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0059] CLS token array shape: (1, 512)\n",
            "[PIXEL_0060] Raw sequence length: 119\n",
            "[PIXEL_0060] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0060] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0060] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0060] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0060] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0060] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0060] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0060] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0060] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0060] CLS token array shape: (3, 512)\n",
            "[PIXEL_0061] Raw sequence length: 62\n",
            "[PIXEL_0061] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0061] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0061] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0061] CLS token array shape: (1, 512)\n",
            "[PIXEL_0062] Raw sequence length: 43\n",
            "[PIXEL_0062] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0062] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0062] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0062] CLS token array shape: (1, 512)\n",
            "[PIXEL_0063] Raw sequence length: 53\n",
            "[PIXEL_0063] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0063] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0063] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0063] CLS token array shape: (1, 512)\n",
            "[PIXEL_0064] Raw sequence length: 53\n",
            "[PIXEL_0064] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0064] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0064] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0064] CLS token array shape: (1, 512)\n",
            "[PIXEL_0065] Raw sequence length: 49\n",
            "[PIXEL_0065] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0065] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0065] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0065] CLS token array shape: (1, 512)\n",
            "[PIXEL_0066] Raw sequence length: 57\n",
            "[PIXEL_0066] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0066] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0066] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0066] CLS token array shape: (1, 512)\n",
            "[PIXEL_0067] Raw sequence length: 120\n",
            "[PIXEL_0067] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0067] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0067] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0067] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0067] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0067] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0067] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0067] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0067] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0067] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0067] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0067] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0067] CLS token array shape: (4, 512)\n",
            "[PIXEL_0068] Raw sequence length: 56\n",
            "[PIXEL_0068] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0068] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0068] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0068] CLS token array shape: (1, 512)\n",
            "[PIXEL_0069] Raw sequence length: 50\n",
            "[PIXEL_0069] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0069] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0069] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0069] CLS token array shape: (1, 512)\n",
            "[PIXEL_0070] Raw sequence length: 44\n",
            "[PIXEL_0070] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0070] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0070] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0070] CLS token array shape: (1, 512)\n",
            "[PIXEL_0071] Raw sequence length: 55\n",
            "[PIXEL_0071] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0071] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0071] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0071] CLS token array shape: (1, 512)\n",
            "[PIXEL_0072] Raw sequence length: 47\n",
            "[PIXEL_0072] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0072] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0072] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0072] CLS token array shape: (1, 512)\n",
            "[PIXEL_0073] Raw sequence length: 57\n",
            "[PIXEL_0073] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0073] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0073] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0073] CLS token array shape: (1, 512)\n",
            "[PIXEL_0074] Raw sequence length: 55\n",
            "[PIXEL_0074] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0074] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0074] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0074] CLS token array shape: (1, 512)\n",
            "[PIXEL_0075] Raw sequence length: 43\n",
            "[PIXEL_0075] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0075] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0075] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0075] CLS token array shape: (1, 512)\n",
            "[PIXEL_0076] Raw sequence length: 96\n",
            "[PIXEL_0076] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0076] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0076] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0076] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0076] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0076] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0076] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0076] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0076] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0076] CLS token array shape: (3, 512)\n",
            "[PIXEL_0077] Raw sequence length: 53\n",
            "[PIXEL_0077] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0077] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0077] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0077] CLS token array shape: (1, 512)\n",
            "[PIXEL_0078] Raw sequence length: 46\n",
            "[PIXEL_0078] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0078] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0078] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0078] CLS token array shape: (1, 512)\n",
            "[PIXEL_0079] Raw sequence length: 54\n",
            "[PIXEL_0079] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0079] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0079] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0079] CLS token array shape: (1, 512)\n",
            "[PIXEL_0080] Raw sequence length: 103\n",
            "[PIXEL_0080] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0080] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0080] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0080] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0080] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0080] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0080] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0080] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0080] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0080] CLS token array shape: (3, 512)\n",
            "[PIXEL_0081] Raw sequence length: 53\n",
            "[PIXEL_0081] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0081] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0081] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0081] CLS token array shape: (1, 512)\n",
            "[PIXEL_0082] Raw sequence length: 108\n",
            "[PIXEL_0082] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0082] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0082] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0082] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0082] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0082] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0082] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0082] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0082] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0082] CLS token array shape: (3, 512)\n",
            "[PIXEL_0083] Raw sequence length: 43\n",
            "[PIXEL_0083] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0083] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0083] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0083] CLS token array shape: (1, 512)\n",
            "[PIXEL_0084] Raw sequence length: 51\n",
            "[PIXEL_0084] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0084] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0084] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0084] CLS token array shape: (1, 512)\n",
            "[PIXEL_0085] Raw sequence length: 52\n",
            "[PIXEL_0085] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0085] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0085] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0085] CLS token array shape: (1, 512)\n",
            "[PIXEL_0086] Raw sequence length: 54\n",
            "[PIXEL_0086] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0086] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0086] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0086] CLS token array shape: (1, 512)\n",
            "[PIXEL_0087] Raw sequence length: 56\n",
            "[PIXEL_0087] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0087] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0087] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0087] CLS token array shape: (1, 512)\n",
            "[PIXEL_0088] Raw sequence length: 114\n",
            "[PIXEL_0088] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0088] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0088] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0088] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0088] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0088] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0088] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0088] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0088] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0088] CLS token array shape: (3, 512)\n",
            "[PIXEL_0089] Raw sequence length: 115\n",
            "[PIXEL_0089] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0089] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0089] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0089] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0089] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0089] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0089] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0089] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0089] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0089] CLS token array shape: (3, 512)\n",
            "[PIXEL_0090] Raw sequence length: 43\n",
            "[PIXEL_0090] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0090] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0090] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0090] CLS token array shape: (1, 512)\n",
            "[PIXEL_0091] Raw sequence length: 53\n",
            "[PIXEL_0091] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0091] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0091] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0091] CLS token array shape: (1, 512)\n",
            "[PIXEL_0092] Raw sequence length: 59\n",
            "[PIXEL_0092] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0092] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0092] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0092] CLS token array shape: (1, 512)\n",
            "[PIXEL_0093] Raw sequence length: 49\n",
            "[PIXEL_0093] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0093] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0093] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0093] CLS token array shape: (1, 512)\n",
            "[PIXEL_0094] Raw sequence length: 53\n",
            "[PIXEL_0094] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0094] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0094] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0094] CLS token array shape: (1, 512)\n",
            "[PIXEL_0095] Raw sequence length: 101\n",
            "[PIXEL_0095] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0095] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0095] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0095] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0095] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0095] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0095] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0095] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0095] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0095] CLS token array shape: (3, 512)\n",
            "[PIXEL_0096] Raw sequence length: 44\n",
            "[PIXEL_0096] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0096] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0096] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0096] CLS token array shape: (1, 512)\n",
            "[PIXEL_0097] Raw sequence length: 50\n",
            "[PIXEL_0097] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0097] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0097] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0097] CLS token array shape: (1, 512)\n",
            "[PIXEL_0098] Raw sequence length: 117\n",
            "[PIXEL_0098] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0098] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0098] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0098] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0098] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0098] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0098] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0098] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0098] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0098] CLS token array shape: (3, 512)\n",
            "[PIXEL_0099] Raw sequence length: 48\n",
            "[PIXEL_0099] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0099] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0099] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0099] CLS token array shape: (1, 512)\n",
            "[PIXEL_0100] Raw sequence length: 61\n",
            "[PIXEL_0100] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0100] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0100] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0100] CLS token array shape: (1, 512)\n",
            "[PIXEL_0101] Raw sequence length: 50\n",
            "[PIXEL_0101] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0101] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0101] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0101] CLS token array shape: (1, 512)\n",
            "[PIXEL_0102] Raw sequence length: 43\n",
            "[PIXEL_0102] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0102] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0102] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0102] CLS token array shape: (1, 512)\n",
            "[PIXEL_0103] Raw sequence length: 49\n",
            "[PIXEL_0103] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0103] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0103] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0103] CLS token array shape: (1, 512)\n",
            "[PIXEL_0104] Raw sequence length: 53\n",
            "[PIXEL_0104] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0104] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0104] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0104] CLS token array shape: (1, 512)\n",
            "[PIXEL_0105] Raw sequence length: 50\n",
            "[PIXEL_0105] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0105] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0105] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0105] CLS token array shape: (1, 512)\n",
            "[PIXEL_0106] Raw sequence length: 56\n",
            "[PIXEL_0106] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0106] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0106] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0106] CLS token array shape: (1, 512)\n",
            "[PIXEL_0107] Raw sequence length: 47\n",
            "[PIXEL_0107] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0107] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0107] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0107] CLS token array shape: (1, 512)\n",
            "[PIXEL_0108] Raw sequence length: 54\n",
            "[PIXEL_0108] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0108] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0108] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0108] CLS token array shape: (1, 512)\n",
            "[PIXEL_0109] Raw sequence length: 106\n",
            "[PIXEL_0109] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0109] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0109] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0109] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0109] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0109] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0109] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0109] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0109] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0109] CLS token array shape: (3, 512)\n",
            "[PIXEL_0110] Raw sequence length: 54\n",
            "[PIXEL_0110] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0110] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0110] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0110] CLS token array shape: (1, 512)\n",
            "[PIXEL_0111] Raw sequence length: 95\n",
            "[PIXEL_0111] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0111] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0111] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0111] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0111] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0111] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0111] CLS token array shape: (2, 512)\n",
            "[PIXEL_0112] Raw sequence length: 51\n",
            "[PIXEL_0112] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0112] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0112] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0112] CLS token array shape: (1, 512)\n",
            "[PIXEL_0113] Raw sequence length: 99\n",
            "[PIXEL_0113] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0113] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0113] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0113] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0113] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0113] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0113] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0113] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0113] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0113] CLS token array shape: (3, 512)\n",
            "[PIXEL_0114] Raw sequence length: 116\n",
            "[PIXEL_0114] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0114] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0114] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0114] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0114] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0114] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0114] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0114] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0114] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0114] CLS token array shape: (3, 512)\n",
            "[PIXEL_0115] Raw sequence length: 49\n",
            "[PIXEL_0115] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0115] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0115] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0115] CLS token array shape: (1, 512)\n",
            "[PIXEL_0116] Raw sequence length: 64\n",
            "[PIXEL_0116] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0116] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0116] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0116] CLS token array shape: (1, 512)\n",
            "[PIXEL_0117] Raw sequence length: 55\n",
            "[PIXEL_0117] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0117] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0117] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0117] CLS token array shape: (1, 512)\n",
            "[PIXEL_0118] Raw sequence length: 41\n",
            "[PIXEL_0118] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0118] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0118] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0118] CLS token array shape: (1, 512)\n",
            "[PIXEL_0119] Raw sequence length: 49\n",
            "[PIXEL_0119] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0119] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0119] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0119] CLS token array shape: (1, 512)\n",
            "[PIXEL_0120] Raw sequence length: 52\n",
            "[PIXEL_0120] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0120] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0120] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0120] CLS token array shape: (1, 512)\n",
            "[PIXEL_0121] Raw sequence length: 44\n",
            "[PIXEL_0121] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0121] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0121] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0121] CLS token array shape: (1, 512)\n",
            "[PIXEL_0122] Raw sequence length: 56\n",
            "[PIXEL_0122] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0122] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0122] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0122] CLS token array shape: (1, 512)\n",
            "[PIXEL_0123] Raw sequence length: 117\n",
            "[PIXEL_0123] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0123] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0123] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0123] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0123] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0123] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0123] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0123] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0123] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0123] CLS token array shape: (3, 512)\n",
            "[PIXEL_0124] Raw sequence length: 56\n",
            "[PIXEL_0124] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0124] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0124] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0124] CLS token array shape: (1, 512)\n",
            "[PIXEL_0125] Raw sequence length: 112\n",
            "[PIXEL_0125] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0125] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0125] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0125] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0125] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0125] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0125] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0125] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0125] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0125] CLS token array shape: (3, 512)\n",
            "[PIXEL_0126] Raw sequence length: 54\n",
            "[PIXEL_0126] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0126] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0126] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0126] CLS token array shape: (1, 512)\n",
            "[PIXEL_0127] Raw sequence length: 53\n",
            "[PIXEL_0127] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0127] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0127] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0127] CLS token array shape: (1, 512)\n",
            "[PIXEL_0128] Raw sequence length: 51\n",
            "[PIXEL_0128] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0128] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0128] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0128] CLS token array shape: (1, 512)\n",
            "[PIXEL_0129] Raw sequence length: 57\n",
            "[PIXEL_0129] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0129] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0129] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0129] CLS token array shape: (1, 512)\n",
            "[PIXEL_0130] Raw sequence length: 59\n",
            "[PIXEL_0130] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0130] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0130] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0130] CLS token array shape: (1, 512)\n",
            "[PIXEL_0131] Raw sequence length: 52\n",
            "[PIXEL_0131] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0131] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0131] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0131] CLS token array shape: (1, 512)\n",
            "[PIXEL_0132] Raw sequence length: 52\n",
            "[PIXEL_0132] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0132] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0132] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0132] CLS token array shape: (1, 512)\n",
            "[PIXEL_0133] Raw sequence length: 104\n",
            "[PIXEL_0133] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0133] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0133] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0133] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0133] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0133] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0133] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0133] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0133] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0133] CLS token array shape: (3, 512)\n",
            "[PIXEL_0134] Raw sequence length: 52\n",
            "[PIXEL_0134] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0134] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0134] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0134] CLS token array shape: (1, 512)\n",
            "[PIXEL_0135] Raw sequence length: 98\n",
            "[PIXEL_0135] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0135] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0135] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0135] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0135] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0135] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0135] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0135] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0135] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0135] CLS token array shape: (3, 512)\n",
            "[PIXEL_0136] Raw sequence length: 108\n",
            "[PIXEL_0136] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0136] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0136] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0136] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0136] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0136] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0136] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0136] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0136] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0136] CLS token array shape: (3, 512)\n",
            "[PIXEL_0137] Raw sequence length: 111\n",
            "[PIXEL_0137] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0137] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0137] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0137] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0137] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0137] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0137] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0137] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0137] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0137] CLS token array shape: (3, 512)\n",
            "[PIXEL_0138] Raw sequence length: 49\n",
            "[PIXEL_0138] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0138] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0138] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0138] CLS token array shape: (1, 512)\n",
            "[PIXEL_0139] Raw sequence length: 50\n",
            "[PIXEL_0139] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0139] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0139] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0139] CLS token array shape: (1, 512)\n",
            "[PIXEL_0140] Raw sequence length: 52\n",
            "[PIXEL_0140] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0140] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0140] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0140] CLS token array shape: (1, 512)\n",
            "[PIXEL_0141] Raw sequence length: 47\n",
            "[PIXEL_0141] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0141] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0141] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0141] CLS token array shape: (1, 512)\n",
            "[PIXEL_0142] Raw sequence length: 48\n",
            "[PIXEL_0142] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0142] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0142] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0142] CLS token array shape: (1, 512)\n",
            "[PIXEL_0143] Raw sequence length: 50\n",
            "[PIXEL_0143] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0143] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0143] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0143] CLS token array shape: (1, 512)\n",
            "[PIXEL_0144] Raw sequence length: 49\n",
            "[PIXEL_0144] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0144] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0144] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0144] CLS token array shape: (1, 512)\n",
            "[PIXEL_0145] Raw sequence length: 45\n",
            "[PIXEL_0145] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0145] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0145] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0145] CLS token array shape: (1, 512)\n",
            "[PIXEL_0146] Raw sequence length: 52\n",
            "[PIXEL_0146] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0146] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0146] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0146] CLS token array shape: (1, 512)\n",
            "[PIXEL_0147] Raw sequence length: 50\n",
            "[PIXEL_0147] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0147] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0147] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0147] CLS token array shape: (1, 512)\n",
            "[PIXEL_0148] Raw sequence length: 48\n",
            "[PIXEL_0148] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0148] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0148] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0148] CLS token array shape: (1, 512)\n",
            "[PIXEL_0149] Raw sequence length: 115\n",
            "[PIXEL_0149] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0149] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0149] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0149] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0149] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0149] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0149] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0149] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0149] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0149] CLS token array shape: (3, 512)\n",
            "[PIXEL_0150] Raw sequence length: 100\n",
            "[PIXEL_0150] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0150] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0150] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0150] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0150] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0150] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0150] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0150] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0150] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0150] CLS token array shape: (3, 512)\n",
            "[PIXEL_0151] Raw sequence length: 112\n",
            "[PIXEL_0151] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0151] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0151] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0151] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0151] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0151] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0151] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0151] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0151] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0151] CLS token array shape: (3, 512)\n",
            "[PIXEL_0152] Raw sequence length: 59\n",
            "[PIXEL_0152] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0152] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0152] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0152] CLS token array shape: (1, 512)\n",
            "[PIXEL_0153] Raw sequence length: 53\n",
            "[PIXEL_0153] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0153] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0153] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0153] CLS token array shape: (1, 512)\n",
            "[PIXEL_0154] Raw sequence length: 51\n",
            "[PIXEL_0154] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0154] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0154] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0154] CLS token array shape: (1, 512)\n",
            "[PIXEL_0155] Raw sequence length: 57\n",
            "[PIXEL_0155] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0155] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0155] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0155] CLS token array shape: (1, 512)\n",
            "[PIXEL_0156] Raw sequence length: 103\n",
            "[PIXEL_0156] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0156] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0156] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0156] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0156] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0156] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0156] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0156] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0156] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0156] CLS token array shape: (3, 512)\n",
            "[PIXEL_0157] Raw sequence length: 49\n",
            "[PIXEL_0157] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0157] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0157] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0157] CLS token array shape: (1, 512)\n",
            "[PIXEL_0158] Raw sequence length: 51\n",
            "[PIXEL_0158] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0158] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0158] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0158] CLS token array shape: (1, 512)\n",
            "[PIXEL_0159] Raw sequence length: 31\n",
            "[PIXEL_0159] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0159] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0159] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0159] CLS token array shape: (1, 512)\n",
            "[PIXEL_0160] Raw sequence length: 50\n",
            "[PIXEL_0160] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0160] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0160] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0160] CLS token array shape: (1, 512)\n",
            "[PIXEL_0161] Raw sequence length: 52\n",
            "[PIXEL_0161] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0161] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0161] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0161] CLS token array shape: (1, 512)\n",
            "[PIXEL_0162] Raw sequence length: 51\n",
            "[PIXEL_0162] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0162] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0162] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0162] CLS token array shape: (1, 512)\n",
            "[PIXEL_0163] Raw sequence length: 53\n",
            "[PIXEL_0163] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0163] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0163] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0163] CLS token array shape: (1, 512)\n",
            "[PIXEL_0164] Raw sequence length: 50\n",
            "[PIXEL_0164] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0164] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0164] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0164] CLS token array shape: (1, 512)\n",
            "[PIXEL_0165] Raw sequence length: 57\n",
            "[PIXEL_0165] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0165] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0165] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0165] CLS token array shape: (1, 512)\n",
            "[PIXEL_0166] Raw sequence length: 50\n",
            "[PIXEL_0166] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0166] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0166] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0166] CLS token array shape: (1, 512)\n",
            "[PIXEL_0167] Raw sequence length: 60\n",
            "[PIXEL_0167] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0167] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0167] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0167] CLS token array shape: (1, 512)\n",
            "[PIXEL_0168] Raw sequence length: 49\n",
            "[PIXEL_0168] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0168] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0168] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0168] CLS token array shape: (1, 512)\n",
            "[PIXEL_0169] Raw sequence length: 45\n",
            "[PIXEL_0169] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0169] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0169] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0169] CLS token array shape: (1, 512)\n",
            "[PIXEL_0170] Raw sequence length: 51\n",
            "[PIXEL_0170] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0170] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0170] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0170] CLS token array shape: (1, 512)\n",
            "[PIXEL_0171] Raw sequence length: 110\n",
            "[PIXEL_0171] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0171] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0171] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0171] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0171] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0171] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0171] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0171] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0171] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0171] CLS token array shape: (3, 512)\n",
            "[PIXEL_0172] Raw sequence length: 46\n",
            "[PIXEL_0172] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0172] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0172] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0172] CLS token array shape: (1, 512)\n",
            "[PIXEL_0173] Raw sequence length: 56\n",
            "[PIXEL_0173] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0173] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0173] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0173] CLS token array shape: (1, 512)\n",
            "[PIXEL_0174] Raw sequence length: 52\n",
            "[PIXEL_0174] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0174] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0174] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0174] CLS token array shape: (1, 512)\n",
            "[PIXEL_0175] Raw sequence length: 59\n",
            "[PIXEL_0175] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0175] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0175] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0175] CLS token array shape: (1, 512)\n",
            "[PIXEL_0176] Raw sequence length: 52\n",
            "[PIXEL_0176] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0176] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0176] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0176] CLS token array shape: (1, 512)\n",
            "[PIXEL_0177] Raw sequence length: 48\n",
            "[PIXEL_0177] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0177] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0177] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0177] CLS token array shape: (1, 512)\n",
            "[PIXEL_0178] Raw sequence length: 45\n",
            "[PIXEL_0178] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0178] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0178] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0178] CLS token array shape: (1, 512)\n",
            "[PIXEL_0179] Raw sequence length: 58\n",
            "[PIXEL_0179] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0179] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0179] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0179] CLS token array shape: (1, 512)\n",
            "[PIXEL_0180] Raw sequence length: 47\n",
            "[PIXEL_0180] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0180] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0180] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0180] CLS token array shape: (1, 512)\n",
            "[PIXEL_0181] Raw sequence length: 61\n",
            "[PIXEL_0181] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0181] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0181] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0181] CLS token array shape: (1, 512)\n",
            "[PIXEL_0182] Raw sequence length: 51\n",
            "[PIXEL_0182] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0182] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0182] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0182] CLS token array shape: (1, 512)\n",
            "[PIXEL_0183] Raw sequence length: 61\n",
            "[PIXEL_0183] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0183] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0183] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0183] CLS token array shape: (1, 512)\n",
            "[PIXEL_0184] Raw sequence length: 50\n",
            "[PIXEL_0184] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0184] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0184] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0184] CLS token array shape: (1, 512)\n",
            "[PIXEL_0185] Raw sequence length: 47\n",
            "[PIXEL_0185] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0185] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0185] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0185] CLS token array shape: (1, 512)\n",
            "[PIXEL_0186] Raw sequence length: 109\n",
            "[PIXEL_0186] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0186] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0186] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0186] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0186] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0186] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0186] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0186] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0186] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0186] CLS token array shape: (3, 512)\n",
            "[PIXEL_0187] Raw sequence length: 57\n",
            "[PIXEL_0187] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0187] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0187] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0187] CLS token array shape: (1, 512)\n",
            "[PIXEL_0188] Raw sequence length: 101\n",
            "[PIXEL_0188] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0188] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0188] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0188] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0188] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0188] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0188] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0188] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0188] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0188] CLS token array shape: (3, 512)\n",
            "[PIXEL_0189] Raw sequence length: 41\n",
            "[PIXEL_0189] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0189] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0189] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0189] CLS token array shape: (1, 512)\n",
            "[PIXEL_0190] Raw sequence length: 53\n",
            "[PIXEL_0190] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0190] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0190] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0190] CLS token array shape: (1, 512)\n",
            "[PIXEL_0191] Raw sequence length: 48\n",
            "[PIXEL_0191] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0191] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0191] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0191] CLS token array shape: (1, 512)\n",
            "[PIXEL_0192] Raw sequence length: 61\n",
            "[PIXEL_0192] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0192] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0192] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0192] CLS token array shape: (1, 512)\n",
            "[PIXEL_0193] Raw sequence length: 52\n",
            "[PIXEL_0193] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0193] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0193] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0193] CLS token array shape: (1, 512)\n",
            "[PIXEL_0194] Raw sequence length: 57\n",
            "[PIXEL_0194] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0194] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0194] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0194] CLS token array shape: (1, 512)\n",
            "[PIXEL_0195] Raw sequence length: 49\n",
            "[PIXEL_0195] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0195] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0195] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0195] CLS token array shape: (1, 512)\n",
            "[PIXEL_0196] Raw sequence length: 54\n",
            "[PIXEL_0196] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0196] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0196] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0196] CLS token array shape: (1, 512)\n",
            "[PIXEL_0197] Raw sequence length: 111\n",
            "[PIXEL_0197] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0197] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0197] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0197] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0197] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0197] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0197] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0197] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0197] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0197] CLS token array shape: (3, 512)\n",
            "[PIXEL_0198] Raw sequence length: 119\n",
            "[PIXEL_0198] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0198] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0198] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0198] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0198] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0198] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0198] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0198] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0198] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0198] CLS token array shape: (3, 512)\n",
            "[PIXEL_0199] Raw sequence length: 57\n",
            "[PIXEL_0199] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0199] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0199] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0199] CLS token array shape: (1, 512)\n",
            "[PIXEL_0200] Raw sequence length: 113\n",
            "[PIXEL_0200] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0200] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0200] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0200] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0200] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0200] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0200] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0200] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0200] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0200] CLS token array shape: (3, 512)\n",
            "[PIXEL_0201] Raw sequence length: 50\n",
            "[PIXEL_0201] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0201] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0201] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0201] CLS token array shape: (1, 512)\n",
            "[PIXEL_0202] Raw sequence length: 46\n",
            "[PIXEL_0202] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0202] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0202] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0202] CLS token array shape: (1, 512)\n",
            "[PIXEL_0203] Raw sequence length: 51\n",
            "[PIXEL_0203] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0203] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0203] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0203] CLS token array shape: (1, 512)\n",
            "[PIXEL_0204] Raw sequence length: 49\n",
            "[PIXEL_0204] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0204] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0204] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0204] CLS token array shape: (1, 512)\n",
            "[PIXEL_0205] Raw sequence length: 49\n",
            "[PIXEL_0205] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0205] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0205] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0205] CLS token array shape: (1, 512)\n",
            "[PIXEL_0206] Raw sequence length: 57\n",
            "[PIXEL_0206] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0206] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0206] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0206] CLS token array shape: (1, 512)\n",
            "[PIXEL_0207] Raw sequence length: 58\n",
            "[PIXEL_0207] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0207] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0207] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0207] CLS token array shape: (1, 512)\n",
            "[PIXEL_0208] Raw sequence length: 53\n",
            "[PIXEL_0208] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0208] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0208] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0208] CLS token array shape: (1, 512)\n",
            "[PIXEL_0209] Raw sequence length: 54\n",
            "[PIXEL_0209] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0209] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0209] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0209] CLS token array shape: (1, 512)\n",
            "[PIXEL_0210] Raw sequence length: 53\n",
            "[PIXEL_0210] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0210] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0210] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0210] CLS token array shape: (1, 512)\n",
            "[PIXEL_0211] Raw sequence length: 50\n",
            "[PIXEL_0211] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0211] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0211] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0211] CLS token array shape: (1, 512)\n",
            "[PIXEL_0212] Raw sequence length: 52\n",
            "[PIXEL_0212] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0212] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0212] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0212] CLS token array shape: (1, 512)\n",
            "[PIXEL_0213] Raw sequence length: 51\n",
            "[PIXEL_0213] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0213] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0213] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0213] CLS token array shape: (1, 512)\n",
            "[PIXEL_0214] Raw sequence length: 53\n",
            "[PIXEL_0214] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0214] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0214] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0214] CLS token array shape: (1, 512)\n",
            "[PIXEL_0215] Raw sequence length: 54\n",
            "[PIXEL_0215] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0215] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0215] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0215] CLS token array shape: (1, 512)\n",
            "[PIXEL_0216] Raw sequence length: 53\n",
            "[PIXEL_0216] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0216] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0216] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0216] CLS token array shape: (1, 512)\n",
            "[PIXEL_0217] Raw sequence length: 54\n",
            "[PIXEL_0217] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0217] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0217] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0217] CLS token array shape: (1, 512)\n",
            "[PIXEL_0218] Raw sequence length: 36\n",
            "[PIXEL_0218] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0218] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0218] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0218] CLS token array shape: (1, 512)\n",
            "[PIXEL_0219] Raw sequence length: 50\n",
            "[PIXEL_0219] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0219] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0219] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0219] CLS token array shape: (1, 512)\n",
            "[PIXEL_0220] Raw sequence length: 108\n",
            "[PIXEL_0220] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0220] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0220] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0220] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0220] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0220] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0220] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0220] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0220] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0220] CLS token array shape: (3, 512)\n",
            "[PIXEL_0221] Raw sequence length: 56\n",
            "[PIXEL_0221] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0221] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0221] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0221] CLS token array shape: (1, 512)\n",
            "[PIXEL_0222] Raw sequence length: 113\n",
            "[PIXEL_0222] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0222] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0222] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0222] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0222] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0222] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0222] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0222] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0222] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0222] CLS token array shape: (3, 512)\n",
            "[PIXEL_0223] Raw sequence length: 52\n",
            "[PIXEL_0223] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0223] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0223] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0223] CLS token array shape: (1, 512)\n",
            "[PIXEL_0224] Raw sequence length: 52\n",
            "[PIXEL_0224] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0224] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0224] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0224] CLS token array shape: (1, 512)\n",
            "[PIXEL_0225] Raw sequence length: 59\n",
            "[PIXEL_0225] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0225] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0225] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0225] CLS token array shape: (1, 512)\n",
            "[PIXEL_0226] Raw sequence length: 56\n",
            "[PIXEL_0226] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0226] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0226] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0226] CLS token array shape: (1, 512)\n",
            "[PIXEL_0227] Raw sequence length: 108\n",
            "[PIXEL_0227] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0227] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0227] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0227] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0227] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0227] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0227] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0227] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0227] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0227] CLS token array shape: (3, 512)\n",
            "[PIXEL_0228] Raw sequence length: 53\n",
            "[PIXEL_0228] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0228] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0228] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0228] CLS token array shape: (1, 512)\n",
            "[PIXEL_0229] Raw sequence length: 52\n",
            "[PIXEL_0229] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0229] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0229] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0229] CLS token array shape: (1, 512)\n",
            "[PIXEL_0230] Raw sequence length: 54\n",
            "[PIXEL_0230] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0230] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0230] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0230] CLS token array shape: (1, 512)\n",
            "[PIXEL_0231] Raw sequence length: 48\n",
            "[PIXEL_0231] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0231] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0231] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0231] CLS token array shape: (1, 512)\n",
            "[PIXEL_0232] Raw sequence length: 47\n",
            "[PIXEL_0232] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0232] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0232] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0232] CLS token array shape: (1, 512)\n",
            "[PIXEL_0233] Raw sequence length: 54\n",
            "[PIXEL_0233] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0233] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0233] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0233] CLS token array shape: (1, 512)\n",
            "[PIXEL_0234] Raw sequence length: 55\n",
            "[PIXEL_0234] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0234] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0234] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0234] CLS token array shape: (1, 512)\n",
            "[PIXEL_0235] Raw sequence length: 47\n",
            "[PIXEL_0235] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0235] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0235] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0235] CLS token array shape: (1, 512)\n",
            "[PIXEL_0236] Raw sequence length: 48\n",
            "[PIXEL_0236] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0236] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0236] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0236] CLS token array shape: (1, 512)\n",
            "[PIXEL_0237] Raw sequence length: 50\n",
            "[PIXEL_0237] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0237] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0237] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0237] CLS token array shape: (1, 512)\n",
            "[PIXEL_0238] Raw sequence length: 54\n",
            "[PIXEL_0238] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0238] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0238] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0238] CLS token array shape: (1, 512)\n",
            "[PIXEL_0239] Raw sequence length: 47\n",
            "[PIXEL_0239] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0239] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0239] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0239] CLS token array shape: (1, 512)\n",
            "[PIXEL_0240] Raw sequence length: 45\n",
            "[PIXEL_0240] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0240] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0240] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0240] CLS token array shape: (1, 512)\n",
            "[PIXEL_0241] Raw sequence length: 60\n",
            "[PIXEL_0241] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0241] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0241] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0241] CLS token array shape: (1, 512)\n",
            "[PIXEL_0242] Raw sequence length: 113\n",
            "[PIXEL_0242] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0242] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0242] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0242] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0242] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0242] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0242] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0242] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0242] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0242] CLS token array shape: (3, 512)\n",
            "[PIXEL_0243] Raw sequence length: 47\n",
            "[PIXEL_0243] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0243] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0243] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0243] CLS token array shape: (1, 512)\n",
            "[PIXEL_0244] Raw sequence length: 42\n",
            "[PIXEL_0244] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0244] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0244] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0244] CLS token array shape: (1, 512)\n",
            "[PIXEL_0245] Raw sequence length: 52\n",
            "[PIXEL_0245] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0245] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0245] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0245] CLS token array shape: (1, 512)\n",
            "[PIXEL_0246] Raw sequence length: 43\n",
            "[PIXEL_0246] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0246] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0246] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0246] CLS token array shape: (1, 512)\n",
            "[PIXEL_0247] Raw sequence length: 57\n",
            "[PIXEL_0247] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0247] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0247] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0247] CLS token array shape: (1, 512)\n",
            "[PIXEL_0248] Raw sequence length: 51\n",
            "[PIXEL_0248] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0248] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0248] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0248] CLS token array shape: (1, 512)\n",
            "[PIXEL_0249] Raw sequence length: 108\n",
            "[PIXEL_0249] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0249] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0249] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0249] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0249] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0249] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0249] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0249] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0249] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0249] CLS token array shape: (3, 512)\n",
            "[PIXEL_0250] Raw sequence length: 46\n",
            "[PIXEL_0250] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0250] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0250] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0250] CLS token array shape: (1, 512)\n",
            "[PIXEL_0251] Raw sequence length: 120\n",
            "[PIXEL_0251] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0251] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0251] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0251] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0251] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0251] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0251] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0251] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0251] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0251] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0251] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0251] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0251] CLS token array shape: (4, 512)\n",
            "[PIXEL_0252] Raw sequence length: 55\n",
            "[PIXEL_0252] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0252] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0252] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0252] CLS token array shape: (1, 512)\n",
            "[PIXEL_0253] Raw sequence length: 48\n",
            "[PIXEL_0253] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0253] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0253] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0253] CLS token array shape: (1, 512)\n",
            "[PIXEL_0254] Raw sequence length: 41\n",
            "[PIXEL_0254] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0254] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0254] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0254] CLS token array shape: (1, 512)\n",
            "[PIXEL_0255] Raw sequence length: 51\n",
            "[PIXEL_0255] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0255] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0255] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0255] CLS token array shape: (1, 512)\n",
            "[PIXEL_0256] Raw sequence length: 52\n",
            "[PIXEL_0256] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0256] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0256] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0256] CLS token array shape: (1, 512)\n",
            "[PIXEL_0257] Raw sequence length: 48\n",
            "[PIXEL_0257] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0257] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0257] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0257] CLS token array shape: (1, 512)\n",
            "[PIXEL_0258] Raw sequence length: 53\n",
            "[PIXEL_0258] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0258] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0258] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0258] CLS token array shape: (1, 512)\n",
            "[PIXEL_0259] Raw sequence length: 50\n",
            "[PIXEL_0259] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0259] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0259] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0259] CLS token array shape: (1, 512)\n",
            "[PIXEL_0260] Raw sequence length: 45\n",
            "[PIXEL_0260] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0260] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0260] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0260] CLS token array shape: (1, 512)\n",
            "[PIXEL_0261] Raw sequence length: 58\n",
            "[PIXEL_0261] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0261] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0261] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0261] CLS token array shape: (1, 512)\n",
            "[PIXEL_0262] Raw sequence length: 53\n",
            "[PIXEL_0262] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0262] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0262] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0262] CLS token array shape: (1, 512)\n",
            "[PIXEL_0263] Raw sequence length: 45\n",
            "[PIXEL_0263] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0263] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0263] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0263] CLS token array shape: (1, 512)\n",
            "[PIXEL_0264] Raw sequence length: 50\n",
            "[PIXEL_0264] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0264] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0264] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0264] CLS token array shape: (1, 512)\n",
            "[PIXEL_0265] Raw sequence length: 41\n",
            "[PIXEL_0265] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0265] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0265] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0265] CLS token array shape: (1, 512)\n",
            "[PIXEL_0266] Raw sequence length: 60\n",
            "[PIXEL_0266] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0266] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0266] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0266] CLS token array shape: (1, 512)\n",
            "[PIXEL_0267] Raw sequence length: 50\n",
            "[PIXEL_0267] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0267] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0267] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0267] CLS token array shape: (1, 512)\n",
            "[PIXEL_0268] Raw sequence length: 49\n",
            "[PIXEL_0268] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0268] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0268] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0268] CLS token array shape: (1, 512)\n",
            "[PIXEL_0269] Raw sequence length: 54\n",
            "[PIXEL_0269] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0269] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0269] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0269] CLS token array shape: (1, 512)\n",
            "[PIXEL_0270] Raw sequence length: 57\n",
            "[PIXEL_0270] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0270] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0270] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0270] CLS token array shape: (1, 512)\n",
            "[PIXEL_0271] Raw sequence length: 48\n",
            "[PIXEL_0271] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0271] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0271] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0271] CLS token array shape: (1, 512)\n",
            "[PIXEL_0272] Raw sequence length: 48\n",
            "[PIXEL_0272] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0272] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0272] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0272] CLS token array shape: (1, 512)\n",
            "[PIXEL_0273] Raw sequence length: 52\n",
            "[PIXEL_0273] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0273] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0273] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0273] CLS token array shape: (1, 512)\n",
            "[PIXEL_0274] Raw sequence length: 51\n",
            "[PIXEL_0274] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0274] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0274] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0274] CLS token array shape: (1, 512)\n",
            "[PIXEL_0275] Raw sequence length: 49\n",
            "[PIXEL_0275] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0275] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0275] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0275] CLS token array shape: (1, 512)\n",
            "[PIXEL_0276] Raw sequence length: 91\n",
            "[PIXEL_0276] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0276] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0276] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0276] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0276] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0276] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0276] CLS token array shape: (2, 512)\n",
            "[PIXEL_0277] Raw sequence length: 54\n",
            "[PIXEL_0277] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0277] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0277] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0277] CLS token array shape: (1, 512)\n",
            "[PIXEL_0278] Raw sequence length: 50\n",
            "[PIXEL_0278] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0278] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0278] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0278] CLS token array shape: (1, 512)\n",
            "[PIXEL_0279] Raw sequence length: 53\n",
            "[PIXEL_0279] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0279] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0279] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0279] CLS token array shape: (1, 512)\n",
            "[PIXEL_0280] Raw sequence length: 59\n",
            "[PIXEL_0280] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0280] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0280] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0280] CLS token array shape: (1, 512)\n",
            "[PIXEL_0281] Raw sequence length: 56\n",
            "[PIXEL_0281] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0281] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0281] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0281] CLS token array shape: (1, 512)\n",
            "[PIXEL_0282] Raw sequence length: 111\n",
            "[PIXEL_0282] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0282] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0282] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0282] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0282] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0282] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0282] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0282] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0282] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0282] CLS token array shape: (3, 512)\n",
            "[PIXEL_0283] Raw sequence length: 61\n",
            "[PIXEL_0283] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0283] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0283] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0283] CLS token array shape: (1, 512)\n",
            "[PIXEL_0284] Raw sequence length: 48\n",
            "[PIXEL_0284] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0284] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0284] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0284] CLS token array shape: (1, 512)\n",
            "[PIXEL_0285] Raw sequence length: 51\n",
            "[PIXEL_0285] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0285] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0285] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0285] CLS token array shape: (1, 512)\n",
            "[PIXEL_0286] Raw sequence length: 105\n",
            "[PIXEL_0286] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0286] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0286] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0286] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0286] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0286] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0286] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0286] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0286] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0286] CLS token array shape: (3, 512)\n",
            "[PIXEL_0287] Raw sequence length: 112\n",
            "[PIXEL_0287] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0287] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0287] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0287] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0287] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0287] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0287] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0287] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0287] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0287] CLS token array shape: (3, 512)\n",
            "[PIXEL_0288] Raw sequence length: 54\n",
            "[PIXEL_0288] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0288] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0288] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0288] CLS token array shape: (1, 512)\n",
            "[PIXEL_0289] Raw sequence length: 102\n",
            "[PIXEL_0289] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0289] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0289] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0289] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0289] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0289] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0289] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0289] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0289] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0289] CLS token array shape: (3, 512)\n",
            "[PIXEL_0290] Raw sequence length: 42\n",
            "[PIXEL_0290] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0290] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0290] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0290] CLS token array shape: (1, 512)\n",
            "[PIXEL_0291] Raw sequence length: 52\n",
            "[PIXEL_0291] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0291] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0291] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0291] CLS token array shape: (1, 512)\n",
            "[PIXEL_0292] Raw sequence length: 49\n",
            "[PIXEL_0292] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0292] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0292] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0292] CLS token array shape: (1, 512)\n",
            "[PIXEL_0293] Raw sequence length: 101\n",
            "[PIXEL_0293] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0293] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0293] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0293] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0293] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0293] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0293] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0293] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0293] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0293] CLS token array shape: (3, 512)\n",
            "[PIXEL_0294] Raw sequence length: 61\n",
            "[PIXEL_0294] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0294] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0294] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0294] CLS token array shape: (1, 512)\n",
            "[PIXEL_0295] Raw sequence length: 47\n",
            "[PIXEL_0295] Padded input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0295] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0295] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0295] CLS token array shape: (1, 512)\n",
            "[PIXEL_0296] Raw sequence length: 50\n",
            "[PIXEL_0296] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0296] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0296] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0296] CLS token array shape: (1, 512)\n",
            "[PIXEL_0297] Raw sequence length: 58\n",
            "[PIXEL_0297] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0297] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0297] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0297] CLS token array shape: (1, 512)\n",
            "[PIXEL_0298] Raw sequence length: 48\n",
            "[PIXEL_0298] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0298] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0298] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0298] CLS token array shape: (1, 512)\n",
            "[PIXEL_0299] Raw sequence length: 55\n",
            "[PIXEL_0299] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0299] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0299] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0299] CLS token array shape: (1, 512)\n",
            "[PIXEL_0300] Raw sequence length: 52\n",
            "[PIXEL_0300] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[PIXEL_0300] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[PIXEL_0300] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[PIXEL_0300] CLS token array shape: (1, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls_embeddings_test = generate_embeddings_sliding_window(test_df, model, max_length=48, stride=24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfcsOGqZ7lJf",
        "outputId": "6ebf5800-3b8a-47ae-b478-75cb61794cf0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOBYMS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOBYMS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOBYMS] CLS token array shape: (5, 512)\n",
            "[ID_YOH896] Raw sequence length: 80\n",
            "[ID_YOH896] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOH896] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOH896] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOH896] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOH896] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOH896] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOH896] CLS token array shape: (2, 512)\n",
            "[ID_YOJ4XB] Raw sequence length: 154\n",
            "[ID_YOJ4XB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOJ4XB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOJ4XB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOJ4XB] CLS token array shape: (5, 512)\n",
            "[ID_YOVR14] Raw sequence length: 79\n",
            "[ID_YOVR14] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOVR14] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOVR14] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOVR14] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YOVR14] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YOVR14] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YOVR14] CLS token array shape: (2, 512)\n",
            "[ID_YP7FJ8] Raw sequence length: 79\n",
            "[ID_YP7FJ8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP7FJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP7FJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP7FJ8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP7FJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP7FJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP7FJ8] CLS token array shape: (2, 512)\n",
            "[ID_YP8EB8] Raw sequence length: 154\n",
            "[ID_YP8EB8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP8EB8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP8EB8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP8EB8] CLS token array shape: (5, 512)\n",
            "[ID_YP9H9B] Raw sequence length: 144\n",
            "[ID_YP9H9B] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YP9H9B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YP9H9B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YP9H9B] CLS token array shape: (5, 512)\n",
            "[ID_YPCPC0] Raw sequence length: 80\n",
            "[ID_YPCPC0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPCPC0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPCPC0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPCPC0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPCPC0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPCPC0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPCPC0] CLS token array shape: (2, 512)\n",
            "[ID_YPG5B2] Raw sequence length: 79\n",
            "[ID_YPG5B2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPG5B2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPG5B2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPG5B2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPG5B2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPG5B2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPG5B2] CLS token array shape: (2, 512)\n",
            "[ID_YPJM6K] Raw sequence length: 80\n",
            "[ID_YPJM6K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPJM6K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPJM6K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPJM6K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPJM6K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPJM6K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPJM6K] CLS token array shape: (2, 512)\n",
            "[ID_YPQR34] Raw sequence length: 145\n",
            "[ID_YPQR34] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPQR34] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPQR34] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPQR34] CLS token array shape: (5, 512)\n",
            "[ID_YPR6IK] Raw sequence length: 74\n",
            "[ID_YPR6IK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPR6IK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPR6IK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPR6IK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YPR6IK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YPR6IK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YPR6IK] CLS token array shape: (2, 512)\n",
            "[ID_YQ3LBT] Raw sequence length: 79\n",
            "[ID_YQ3LBT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ3LBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ3LBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ3LBT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ3LBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ3LBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ3LBT] CLS token array shape: (2, 512)\n",
            "[ID_YQ56PS] Raw sequence length: 292\n",
            "[ID_YQ56PS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ56PS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ56PS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ56PS] CLS token array shape: (11, 512)\n",
            "[ID_YQ5ETE] Raw sequence length: 146\n",
            "[ID_YQ5ETE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ5ETE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ5ETE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ5ETE] CLS token array shape: (5, 512)\n",
            "[ID_YQ6M4Y] Raw sequence length: 129\n",
            "[ID_YQ6M4Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ6M4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ6M4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ6M4Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ6M4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ6M4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ6M4Y] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ6M4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ6M4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ6M4Y] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ6M4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ6M4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ6M4Y] CLS token array shape: (4, 512)\n",
            "[ID_YQ7GUH] Raw sequence length: 80\n",
            "[ID_YQ7GUH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ7GUH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ7GUH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ7GUH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQ7GUH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQ7GUH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQ7GUH] CLS token array shape: (2, 512)\n",
            "[ID_YQCRGR] Raw sequence length: 145\n",
            "[ID_YQCRGR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQCRGR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQCRGR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQCRGR] CLS token array shape: (5, 512)\n",
            "[ID_YQLZCV] Raw sequence length: 153\n",
            "[ID_YQLZCV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQLZCV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQLZCV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQLZCV] CLS token array shape: (5, 512)\n",
            "[ID_YQMMOX] Raw sequence length: 146\n",
            "[ID_YQMMOX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMMOX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMMOX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMMOX] CLS token array shape: (5, 512)\n",
            "[ID_YQMYHH] Raw sequence length: 80\n",
            "[ID_YQMYHH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMYHH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMYHH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMYHH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQMYHH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQMYHH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQMYHH] CLS token array shape: (2, 512)\n",
            "[ID_YQNLF2] Raw sequence length: 80\n",
            "[ID_YQNLF2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQNLF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQNLF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQNLF2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQNLF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQNLF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQNLF2] CLS token array shape: (2, 512)\n",
            "[ID_YQONXC] Raw sequence length: 80\n",
            "[ID_YQONXC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQONXC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQONXC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQONXC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQONXC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQONXC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQONXC] CLS token array shape: (2, 512)\n",
            "[ID_YQP70R] Raw sequence length: 292\n",
            "[ID_YQP70R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQP70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQP70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQP70R] CLS token array shape: (11, 512)\n",
            "[ID_YQTI49] Raw sequence length: 154\n",
            "[ID_YQTI49] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQTI49] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQTI49] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQTI49] CLS token array shape: (5, 512)\n",
            "[ID_YQWUBF] Raw sequence length: 80\n",
            "[ID_YQWUBF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQWUBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQWUBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQWUBF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQWUBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQWUBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQWUBF] CLS token array shape: (2, 512)\n",
            "[ID_YQY1KH] Raw sequence length: 80\n",
            "[ID_YQY1KH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY1KH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY1KH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY1KH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY1KH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY1KH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY1KH] CLS token array shape: (2, 512)\n",
            "[ID_YQY93B] Raw sequence length: 145\n",
            "[ID_YQY93B] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YQY93B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YQY93B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YQY93B] CLS token array shape: (5, 512)\n",
            "[ID_YR0Y59] Raw sequence length: 80\n",
            "[ID_YR0Y59] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR0Y59] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR0Y59] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR0Y59] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR0Y59] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR0Y59] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR0Y59] CLS token array shape: (2, 512)\n",
            "[ID_YR2YNZ] Raw sequence length: 154\n",
            "[ID_YR2YNZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR2YNZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR2YNZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR2YNZ] CLS token array shape: (5, 512)\n",
            "[ID_YR9JMP] Raw sequence length: 80\n",
            "[ID_YR9JMP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR9JMP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR9JMP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR9JMP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YR9JMP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YR9JMP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YR9JMP] CLS token array shape: (2, 512)\n",
            "[ID_YRC0ZS] Raw sequence length: 79\n",
            "[ID_YRC0ZS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRC0ZS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRC0ZS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRC0ZS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRC0ZS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRC0ZS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRC0ZS] CLS token array shape: (2, 512)\n",
            "[ID_YRPT7Y] Raw sequence length: 79\n",
            "[ID_YRPT7Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRPT7Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRPT7Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRPT7Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRPT7Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRPT7Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRPT7Y] CLS token array shape: (2, 512)\n",
            "[ID_YRR3I4] Raw sequence length: 74\n",
            "[ID_YRR3I4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRR3I4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRR3I4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRR3I4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRR3I4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRR3I4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRR3I4] CLS token array shape: (2, 512)\n",
            "[ID_YRVNFY] Raw sequence length: 129\n",
            "[ID_YRVNFY] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRVNFY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRVNFY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRVNFY] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRVNFY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRVNFY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRVNFY] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRVNFY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRVNFY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRVNFY] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YRVNFY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YRVNFY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YRVNFY] CLS token array shape: (4, 512)\n",
            "[ID_YSFE2A] Raw sequence length: 80\n",
            "[ID_YSFE2A] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSFE2A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSFE2A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSFE2A] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSFE2A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSFE2A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSFE2A] CLS token array shape: (2, 512)\n",
            "[ID_YSH3D0] Raw sequence length: 79\n",
            "[ID_YSH3D0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSH3D0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSH3D0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSH3D0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSH3D0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSH3D0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSH3D0] CLS token array shape: (2, 512)\n",
            "[ID_YSU8UN] Raw sequence length: 79\n",
            "[ID_YSU8UN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSU8UN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSU8UN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSU8UN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSU8UN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSU8UN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSU8UN] CLS token array shape: (2, 512)\n",
            "[ID_YSWZ8C] Raw sequence length: 79\n",
            "[ID_YSWZ8C] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSWZ8C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSWZ8C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSWZ8C] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSWZ8C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSWZ8C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSWZ8C] CLS token array shape: (2, 512)\n",
            "[ID_YSYB21] Raw sequence length: 145\n",
            "[ID_YSYB21] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYB21] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYB21] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYB21] CLS token array shape: (5, 512)\n",
            "[ID_YSYH7U] Raw sequence length: 148\n",
            "[ID_YSYH7U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YSYH7U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YSYH7U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YSYH7U] CLS token array shape: (5, 512)\n",
            "[ID_YT8OI2] Raw sequence length: 80\n",
            "[ID_YT8OI2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YT8OI2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YT8OI2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YT8OI2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YT8OI2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YT8OI2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YT8OI2] CLS token array shape: (2, 512)\n",
            "[ID_YTD703] Raw sequence length: 79\n",
            "[ID_YTD703] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTD703] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTD703] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTD703] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTD703] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTD703] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTD703] CLS token array shape: (2, 512)\n",
            "[ID_YTE997] Raw sequence length: 79\n",
            "[ID_YTE997] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTE997] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTE997] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTE997] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTE997] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTE997] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTE997] CLS token array shape: (2, 512)\n",
            "[ID_YTFG6G] Raw sequence length: 154\n",
            "[ID_YTFG6G] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFG6G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFG6G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFG6G] CLS token array shape: (5, 512)\n",
            "[ID_YTFOYC] Raw sequence length: 145\n",
            "[ID_YTFOYC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTFOYC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTFOYC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTFOYC] CLS token array shape: (5, 512)\n",
            "[ID_YTGT9U] Raw sequence length: 74\n",
            "[ID_YTGT9U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTGT9U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTGT9U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTGT9U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTGT9U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTGT9U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTGT9U] CLS token array shape: (2, 512)\n",
            "[ID_YTIACC] Raw sequence length: 77\n",
            "[ID_YTIACC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTIACC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTIACC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTIACC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTIACC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTIACC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTIACC] CLS token array shape: (2, 512)\n",
            "[ID_YTJ7BX] Raw sequence length: 80\n",
            "[ID_YTJ7BX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTJ7BX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTJ7BX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTJ7BX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTJ7BX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTJ7BX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTJ7BX] CLS token array shape: (2, 512)\n",
            "[ID_YTOIQ7] Raw sequence length: 80\n",
            "[ID_YTOIQ7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTOIQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTOIQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTOIQ7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YTOIQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YTOIQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YTOIQ7] CLS token array shape: (2, 512)\n",
            "[ID_YU0FMO] Raw sequence length: 80\n",
            "[ID_YU0FMO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU0FMO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU0FMO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU0FMO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU0FMO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU0FMO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU0FMO] CLS token array shape: (2, 512)\n",
            "[ID_YU2SBF] Raw sequence length: 129\n",
            "[ID_YU2SBF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU2SBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU2SBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU2SBF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU2SBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU2SBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU2SBF] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU2SBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU2SBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU2SBF] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YU2SBF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YU2SBF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YU2SBF] CLS token array shape: (4, 512)\n",
            "[ID_YUB0MN] Raw sequence length: 80\n",
            "[ID_YUB0MN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUB0MN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUB0MN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUB0MN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUB0MN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUB0MN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUB0MN] CLS token array shape: (2, 512)\n",
            "[ID_YUBIZV] Raw sequence length: 220\n",
            "[ID_YUBIZV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBIZV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBIZV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBIZV] CLS token array shape: (8, 512)\n",
            "[ID_YUBTOY] Raw sequence length: 74\n",
            "[ID_YUBTOY] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBTOY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBTOY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBTOY] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUBTOY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUBTOY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUBTOY] CLS token array shape: (2, 512)\n",
            "[ID_YUCAFX] Raw sequence length: 80\n",
            "[ID_YUCAFX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUCAFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUCAFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUCAFX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUCAFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUCAFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUCAFX] CLS token array shape: (2, 512)\n",
            "[ID_YULBY9] Raw sequence length: 80\n",
            "[ID_YULBY9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YULBY9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YULBY9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YULBY9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YULBY9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YULBY9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YULBY9] CLS token array shape: (2, 512)\n",
            "[ID_YUMOK6] Raw sequence length: 80\n",
            "[ID_YUMOK6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUMOK6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUMOK6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUMOK6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YUMOK6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YUMOK6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YUMOK6] CLS token array shape: (2, 512)\n",
            "[ID_YVF78B] Raw sequence length: 80\n",
            "[ID_YVF78B] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVF78B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVF78B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVF78B] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVF78B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVF78B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVF78B] CLS token array shape: (2, 512)\n",
            "[ID_YVHAWQ] Raw sequence length: 146\n",
            "[ID_YVHAWQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVHAWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVHAWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVHAWQ] CLS token array shape: (5, 512)\n",
            "[ID_YVJD8B] Raw sequence length: 79\n",
            "[ID_YVJD8B] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVJD8B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVJD8B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVJD8B] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVJD8B] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVJD8B] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVJD8B] CLS token array shape: (2, 512)\n",
            "[ID_YVLS89] Raw sequence length: 80\n",
            "[ID_YVLS89] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVLS89] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVLS89] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVLS89] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVLS89] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVLS89] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVLS89] CLS token array shape: (2, 512)\n",
            "[ID_YVLVT6] Raw sequence length: 80\n",
            "[ID_YVLVT6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVLVT6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVLVT6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVLVT6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVLVT6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVLVT6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVLVT6] CLS token array shape: (2, 512)\n",
            "[ID_YVREWQ] Raw sequence length: 154\n",
            "[ID_YVREWQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVREWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVREWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVREWQ] CLS token array shape: (5, 512)\n",
            "[ID_YVSNMF] Raw sequence length: 292\n",
            "[ID_YVSNMF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVSNMF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVSNMF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVSNMF] CLS token array shape: (11, 512)\n",
            "[ID_YVVBZL] Raw sequence length: 80\n",
            "[ID_YVVBZL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVVBZL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVVBZL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVVBZL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YVVBZL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YVVBZL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YVVBZL] CLS token array shape: (2, 512)\n",
            "[ID_YW64I4] Raw sequence length: 80\n",
            "[ID_YW64I4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YW64I4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YW64I4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YW64I4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YW64I4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YW64I4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YW64I4] CLS token array shape: (2, 512)\n",
            "[ID_YWFOAM] Raw sequence length: 146\n",
            "[ID_YWFOAM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWFOAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWFOAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWFOAM] CLS token array shape: (5, 512)\n",
            "[ID_YWPQTW] Raw sequence length: 80\n",
            "[ID_YWPQTW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPQTW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPQTW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPQTW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPQTW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPQTW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPQTW] CLS token array shape: (2, 512)\n",
            "[ID_YWPZUL] Raw sequence length: 146\n",
            "[ID_YWPZUL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWPZUL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWPZUL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWPZUL] CLS token array shape: (5, 512)\n",
            "[ID_YWQ3UT] Raw sequence length: 80\n",
            "[ID_YWQ3UT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWQ3UT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWQ3UT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWQ3UT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWQ3UT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWQ3UT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWQ3UT] CLS token array shape: (2, 512)\n",
            "[ID_YWSBVQ] Raw sequence length: 146\n",
            "[ID_YWSBVQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWSBVQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWSBVQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWSBVQ] CLS token array shape: (5, 512)\n",
            "[ID_YWU5GO] Raw sequence length: 145\n",
            "[ID_YWU5GO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YWU5GO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YWU5GO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YWU5GO] CLS token array shape: (5, 512)\n",
            "[ID_YX3BGD] Raw sequence length: 80\n",
            "[ID_YX3BGD] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YX3BGD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YX3BGD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YX3BGD] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YX3BGD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YX3BGD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YX3BGD] CLS token array shape: (2, 512)\n",
            "[ID_YXAWZM] Raw sequence length: 79\n",
            "[ID_YXAWZM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXAWZM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXAWZM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXAWZM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXAWZM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXAWZM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXAWZM] CLS token array shape: (2, 512)\n",
            "[ID_YXBJP8] Raw sequence length: 80\n",
            "[ID_YXBJP8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXBJP8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXBJP8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXBJP8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXBJP8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXBJP8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXBJP8] CLS token array shape: (2, 512)\n",
            "[ID_YXL2U8] Raw sequence length: 80\n",
            "[ID_YXL2U8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL2U8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL2U8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL2U8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL2U8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL2U8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL2U8] CLS token array shape: (2, 512)\n",
            "[ID_YXL3UW] Raw sequence length: 146\n",
            "[ID_YXL3UW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXL3UW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXL3UW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXL3UW] CLS token array shape: (5, 512)\n",
            "[ID_YXQ731] Raw sequence length: 154\n",
            "[ID_YXQ731] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXQ731] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXQ731] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXQ731] CLS token array shape: (5, 512)\n",
            "[ID_YXUD84] Raw sequence length: 80\n",
            "[ID_YXUD84] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXUD84] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXUD84] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXUD84] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YXUD84] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YXUD84] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YXUD84] CLS token array shape: (2, 512)\n",
            "[ID_YY3711] Raw sequence length: 74\n",
            "[ID_YY3711] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY3711] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY3711] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY3711] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY3711] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY3711] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY3711] CLS token array shape: (2, 512)\n",
            "[ID_YY5XNQ] Raw sequence length: 146\n",
            "[ID_YY5XNQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY5XNQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY5XNQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY5XNQ] CLS token array shape: (5, 512)\n",
            "[ID_YY7P4S] Raw sequence length: 80\n",
            "[ID_YY7P4S] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY7P4S] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY7P4S] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY7P4S] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YY7P4S] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YY7P4S] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YY7P4S] CLS token array shape: (2, 512)\n",
            "[ID_YYA72I] Raw sequence length: 146\n",
            "[ID_YYA72I] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYA72I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYA72I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYA72I] CLS token array shape: (5, 512)\n",
            "[ID_YYB0YC] Raw sequence length: 146\n",
            "[ID_YYB0YC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYB0YC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYB0YC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYB0YC] CLS token array shape: (5, 512)\n",
            "[ID_YYMNV9] Raw sequence length: 80\n",
            "[ID_YYMNV9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYMNV9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYMNV9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYMNV9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYMNV9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYMNV9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYMNV9] CLS token array shape: (2, 512)\n",
            "[ID_YYQ6FM] Raw sequence length: 78\n",
            "[ID_YYQ6FM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYQ6FM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYQ6FM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYQ6FM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYQ6FM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYQ6FM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYQ6FM] CLS token array shape: (2, 512)\n",
            "[ID_YYRORS] Raw sequence length: 80\n",
            "[ID_YYRORS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYRORS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYRORS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYRORS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYRORS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYRORS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYRORS] CLS token array shape: (2, 512)\n",
            "[ID_YYTMEQ] Raw sequence length: 80\n",
            "[ID_YYTMEQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYTMEQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYTMEQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYTMEQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYTMEQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYTMEQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYTMEQ] CLS token array shape: (2, 512)\n",
            "[ID_YYUZD8] Raw sequence length: 79\n",
            "[ID_YYUZD8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYUZD8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYUZD8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYUZD8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYUZD8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYUZD8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYUZD8] CLS token array shape: (2, 512)\n",
            "[ID_YYV2T4] Raw sequence length: 80\n",
            "[ID_YYV2T4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYV2T4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYV2T4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYV2T4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYV2T4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYV2T4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYV2T4] CLS token array shape: (2, 512)\n",
            "[ID_YYW3C1] Raw sequence length: 79\n",
            "[ID_YYW3C1] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYW3C1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYW3C1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYW3C1] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YYW3C1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YYW3C1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YYW3C1] CLS token array shape: (2, 512)\n",
            "[ID_YZEZXQ] Raw sequence length: 146\n",
            "[ID_YZEZXQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZEZXQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZEZXQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZEZXQ] CLS token array shape: (5, 512)\n",
            "[ID_YZP0VO] Raw sequence length: 79\n",
            "[ID_YZP0VO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZP0VO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZP0VO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZP0VO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZP0VO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZP0VO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZP0VO] CLS token array shape: (2, 512)\n",
            "[ID_YZRQZQ] Raw sequence length: 154\n",
            "[ID_YZRQZQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZRQZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZRQZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZRQZQ] CLS token array shape: (5, 512)\n",
            "[ID_YZSI0I] Raw sequence length: 79\n",
            "[ID_YZSI0I] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZSI0I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZSI0I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZSI0I] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_YZSI0I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_YZSI0I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_YZSI0I] CLS token array shape: (2, 512)\n",
            "[ID_Z01LKJ] Raw sequence length: 145\n",
            "[ID_Z01LKJ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z01LKJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z01LKJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z01LKJ] CLS token array shape: (5, 512)\n",
            "[ID_Z0HRWF] Raw sequence length: 80\n",
            "[ID_Z0HRWF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0HRWF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0HRWF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0HRWF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0HRWF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0HRWF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0HRWF] CLS token array shape: (2, 512)\n",
            "[ID_Z0IT3R] Raw sequence length: 80\n",
            "[ID_Z0IT3R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0IT3R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0IT3R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0IT3R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0IT3R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0IT3R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0IT3R] CLS token array shape: (2, 512)\n",
            "[ID_Z0M7V2] Raw sequence length: 291\n",
            "[ID_Z0M7V2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0M7V2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0M7V2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0M7V2] CLS token array shape: (11, 512)\n",
            "[ID_Z0MAFE] Raw sequence length: 74\n",
            "[ID_Z0MAFE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0MAFE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0MAFE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0MAFE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0MAFE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0MAFE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0MAFE] CLS token array shape: (2, 512)\n",
            "[ID_Z0O190] Raw sequence length: 80\n",
            "[ID_Z0O190] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0O190] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0O190] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0O190] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0O190] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0O190] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0O190] CLS token array shape: (2, 512)\n",
            "[ID_Z0P94M] Raw sequence length: 126\n",
            "[ID_Z0P94M] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0P94M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0P94M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0P94M] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0P94M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0P94M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0P94M] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0P94M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0P94M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0P94M] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0P94M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0P94M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0P94M] CLS token array shape: (4, 512)\n",
            "[ID_Z0R053] Raw sequence length: 154\n",
            "[ID_Z0R053] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0R053] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0R053] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0R053] CLS token array shape: (5, 512)\n",
            "[ID_Z0TP71] Raw sequence length: 79\n",
            "[ID_Z0TP71] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0TP71] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0TP71] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0TP71] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0TP71] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0TP71] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0TP71] CLS token array shape: (2, 512)\n",
            "[ID_Z0XND2] Raw sequence length: 80\n",
            "[ID_Z0XND2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0XND2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0XND2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0XND2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0XND2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0XND2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0XND2] CLS token array shape: (2, 512)\n",
            "[ID_Z0Y4DL] Raw sequence length: 79\n",
            "[ID_Z0Y4DL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0Y4DL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0Y4DL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0Y4DL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0Y4DL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0Y4DL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0Y4DL] CLS token array shape: (2, 512)\n",
            "[ID_Z0ZJOB] Raw sequence length: 146\n",
            "[ID_Z0ZJOB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z0ZJOB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z0ZJOB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z0ZJOB] CLS token array shape: (5, 512)\n",
            "[ID_Z1A2YU] Raw sequence length: 146\n",
            "[ID_Z1A2YU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1A2YU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1A2YU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1A2YU] CLS token array shape: (5, 512)\n",
            "[ID_Z1FXRX] Raw sequence length: 159\n",
            "[ID_Z1FXRX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1FXRX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1FXRX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1FXRX] CLS token array shape: (5, 512)\n",
            "[ID_Z1I75U] Raw sequence length: 80\n",
            "[ID_Z1I75U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1I75U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1I75U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1I75U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1I75U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1I75U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1I75U] CLS token array shape: (2, 512)\n",
            "[ID_Z1MI0A] Raw sequence length: 80\n",
            "[ID_Z1MI0A] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1MI0A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1MI0A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1MI0A] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1MI0A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1MI0A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1MI0A] CLS token array shape: (2, 512)\n",
            "[ID_Z1PF7L] Raw sequence length: 80\n",
            "[ID_Z1PF7L] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1PF7L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1PF7L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1PF7L] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z1PF7L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z1PF7L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z1PF7L] CLS token array shape: (2, 512)\n",
            "[ID_Z23MT4] Raw sequence length: 80\n",
            "[ID_Z23MT4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z23MT4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z23MT4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z23MT4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z23MT4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z23MT4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z23MT4] CLS token array shape: (2, 512)\n",
            "[ID_Z24RIY] Raw sequence length: 80\n",
            "[ID_Z24RIY] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z24RIY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z24RIY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z24RIY] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z24RIY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z24RIY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z24RIY] CLS token array shape: (2, 512)\n",
            "[ID_Z29S2I] Raw sequence length: 145\n",
            "[ID_Z29S2I] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z29S2I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z29S2I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z29S2I] CLS token array shape: (5, 512)\n",
            "[ID_Z2AN8X] Raw sequence length: 80\n",
            "[ID_Z2AN8X] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2AN8X] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2AN8X] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2AN8X] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2AN8X] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2AN8X] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2AN8X] CLS token array shape: (2, 512)\n",
            "[ID_Z2HS7V] Raw sequence length: 146\n",
            "[ID_Z2HS7V] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HS7V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HS7V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HS7V] CLS token array shape: (5, 512)\n",
            "[ID_Z2HYHG] Raw sequence length: 80\n",
            "[ID_Z2HYHG] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HYHG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HYHG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HYHG] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2HYHG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2HYHG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2HYHG] CLS token array shape: (2, 512)\n",
            "[ID_Z2J82F] Raw sequence length: 146\n",
            "[ID_Z2J82F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2J82F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2J82F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2J82F] CLS token array shape: (5, 512)\n",
            "[ID_Z2X8BK] Raw sequence length: 291\n",
            "[ID_Z2X8BK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z2X8BK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z2X8BK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z2X8BK] CLS token array shape: (11, 512)\n",
            "[ID_Z338MU] Raw sequence length: 80\n",
            "[ID_Z338MU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z338MU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z338MU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z338MU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z338MU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z338MU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z338MU] CLS token array shape: (2, 512)\n",
            "[ID_Z39YGK] Raw sequence length: 129\n",
            "[ID_Z39YGK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z39YGK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z39YGK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z39YGK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z39YGK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z39YGK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z39YGK] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z39YGK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z39YGK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z39YGK] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z39YGK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z39YGK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z39YGK] CLS token array shape: (4, 512)\n",
            "[ID_Z3O3Z7] Raw sequence length: 145\n",
            "[ID_Z3O3Z7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3O3Z7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3O3Z7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3O3Z7] CLS token array shape: (5, 512)\n",
            "[ID_Z3XOA5] Raw sequence length: 77\n",
            "[ID_Z3XOA5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3XOA5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3XOA5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3XOA5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3XOA5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3XOA5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3XOA5] CLS token array shape: (2, 512)\n",
            "[ID_Z3YI97] Raw sequence length: 80\n",
            "[ID_Z3YI97] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3YI97] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3YI97] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3YI97] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z3YI97] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z3YI97] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z3YI97] CLS token array shape: (2, 512)\n",
            "[ID_Z44FNL] Raw sequence length: 291\n",
            "[ID_Z44FNL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z44FNL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z44FNL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z44FNL] CLS token array shape: (11, 512)\n",
            "[ID_Z49DFD] Raw sequence length: 79\n",
            "[ID_Z49DFD] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z49DFD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z49DFD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z49DFD] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z49DFD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z49DFD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z49DFD] CLS token array shape: (2, 512)\n",
            "[ID_Z4GP7F] Raw sequence length: 154\n",
            "[ID_Z4GP7F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4GP7F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4GP7F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4GP7F] CLS token array shape: (5, 512)\n",
            "[ID_Z4HNQ7] Raw sequence length: 154\n",
            "[ID_Z4HNQ7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4HNQ7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4HNQ7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4HNQ7] CLS token array shape: (5, 512)\n",
            "[ID_Z4J06N] Raw sequence length: 80\n",
            "[ID_Z4J06N] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4J06N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4J06N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4J06N] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4J06N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4J06N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4J06N] CLS token array shape: (2, 512)\n",
            "[ID_Z4P56Y] Raw sequence length: 146\n",
            "[ID_Z4P56Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4P56Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4P56Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4P56Y] CLS token array shape: (5, 512)\n",
            "[ID_Z4POMD] Raw sequence length: 80\n",
            "[ID_Z4POMD] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4POMD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4POMD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4POMD] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z4POMD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z4POMD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z4POMD] CLS token array shape: (2, 512)\n",
            "[ID_Z50CA4] Raw sequence length: 147\n",
            "[ID_Z50CA4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z50CA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z50CA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z50CA4] CLS token array shape: (5, 512)\n",
            "[ID_Z537AC] Raw sequence length: 146\n",
            "[ID_Z537AC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z537AC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z537AC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z537AC] CLS token array shape: (5, 512)\n",
            "[ID_Z55RRH] Raw sequence length: 146\n",
            "[ID_Z55RRH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z55RRH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z55RRH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z55RRH] CLS token array shape: (5, 512)\n",
            "[ID_Z5AM0O] Raw sequence length: 79\n",
            "[ID_Z5AM0O] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5AM0O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5AM0O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5AM0O] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5AM0O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5AM0O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5AM0O] CLS token array shape: (2, 512)\n",
            "[ID_Z5EFFX] Raw sequence length: 173\n",
            "[ID_Z5EFFX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5EFFX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5EFFX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5EFFX] CLS token array shape: (6, 512)\n",
            "[ID_Z5GJ9F] Raw sequence length: 80\n",
            "[ID_Z5GJ9F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5GJ9F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5GJ9F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5GJ9F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5GJ9F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5GJ9F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5GJ9F] CLS token array shape: (2, 512)\n",
            "[ID_Z5MPPB] Raw sequence length: 126\n",
            "[ID_Z5MPPB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5MPPB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5MPPB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5MPPB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5MPPB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5MPPB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5MPPB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5MPPB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5MPPB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5MPPB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5MPPB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5MPPB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5MPPB] CLS token array shape: (4, 512)\n",
            "[ID_Z5NHZW] Raw sequence length: 79\n",
            "[ID_Z5NHZW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5NHZW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5NHZW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5NHZW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5NHZW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5NHZW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5NHZW] CLS token array shape: (2, 512)\n",
            "[ID_Z5PW8D] Raw sequence length: 78\n",
            "[ID_Z5PW8D] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5PW8D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5PW8D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5PW8D] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5PW8D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5PW8D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5PW8D] CLS token array shape: (2, 512)\n",
            "[ID_Z5WXF0] Raw sequence length: 80\n",
            "[ID_Z5WXF0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5WXF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5WXF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5WXF0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5WXF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5WXF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5WXF0] CLS token array shape: (2, 512)\n",
            "[ID_Z5ZL7G] Raw sequence length: 80\n",
            "[ID_Z5ZL7G] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZL7G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZL7G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZL7G] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZL7G] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZL7G] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZL7G] CLS token array shape: (2, 512)\n",
            "[ID_Z5ZUXO] Raw sequence length: 129\n",
            "[ID_Z5ZUXO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZUXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZUXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZUXO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZUXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZUXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZUXO] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZUXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZUXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZUXO] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z5ZUXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z5ZUXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z5ZUXO] CLS token array shape: (4, 512)\n",
            "[ID_Z622TK] Raw sequence length: 144\n",
            "[ID_Z622TK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z622TK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z622TK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z622TK] CLS token array shape: (5, 512)\n",
            "[ID_Z63WD7] Raw sequence length: 80\n",
            "[ID_Z63WD7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z63WD7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z63WD7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z63WD7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z63WD7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z63WD7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z63WD7] CLS token array shape: (2, 512)\n",
            "[ID_Z644AP] Raw sequence length: 80\n",
            "[ID_Z644AP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z644AP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z644AP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z644AP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z644AP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z644AP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z644AP] CLS token array shape: (2, 512)\n",
            "[ID_Z667ZQ] Raw sequence length: 79\n",
            "[ID_Z667ZQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z667ZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z667ZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z667ZQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z667ZQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z667ZQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z667ZQ] CLS token array shape: (2, 512)\n",
            "[ID_Z697Z8] Raw sequence length: 74\n",
            "[ID_Z697Z8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z697Z8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z697Z8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z697Z8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z697Z8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z697Z8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z697Z8] CLS token array shape: (2, 512)\n",
            "[ID_Z6B4FC] Raw sequence length: 162\n",
            "[ID_Z6B4FC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6B4FC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6B4FC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6B4FC] CLS token array shape: (5, 512)\n",
            "[ID_Z6MXIL] Raw sequence length: 80\n",
            "[ID_Z6MXIL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6MXIL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6MXIL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6MXIL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6MXIL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6MXIL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6MXIL] CLS token array shape: (2, 512)\n",
            "[ID_Z6NUGT] Raw sequence length: 80\n",
            "[ID_Z6NUGT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6NUGT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6NUGT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6NUGT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6NUGT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6NUGT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6NUGT] CLS token array shape: (2, 512)\n",
            "[ID_Z6QI77] Raw sequence length: 80\n",
            "[ID_Z6QI77] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6QI77] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6QI77] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6QI77] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6QI77] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6QI77] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6QI77] CLS token array shape: (2, 512)\n",
            "[ID_Z6SR0U] Raw sequence length: 292\n",
            "[ID_Z6SR0U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6SR0U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6SR0U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6SR0U] CLS token array shape: (11, 512)\n",
            "[ID_Z6VCXO] Raw sequence length: 79\n",
            "[ID_Z6VCXO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6VCXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6VCXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6VCXO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z6VCXO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z6VCXO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z6VCXO] CLS token array shape: (2, 512)\n",
            "[ID_Z7DRSO] Raw sequence length: 80\n",
            "[ID_Z7DRSO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7DRSO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7DRSO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7DRSO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7DRSO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7DRSO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7DRSO] CLS token array shape: (2, 512)\n",
            "[ID_Z7DXME] Raw sequence length: 79\n",
            "[ID_Z7DXME] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7DXME] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7DXME] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7DXME] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7DXME] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7DXME] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7DXME] CLS token array shape: (2, 512)\n",
            "[ID_Z7EE4M] Raw sequence length: 80\n",
            "[ID_Z7EE4M] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7EE4M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7EE4M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7EE4M] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7EE4M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7EE4M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7EE4M] CLS token array shape: (2, 512)\n",
            "[ID_Z7IK9D] Raw sequence length: 146\n",
            "[ID_Z7IK9D] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7IK9D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7IK9D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7IK9D] CLS token array shape: (5, 512)\n",
            "[ID_Z7KVFS] Raw sequence length: 80\n",
            "[ID_Z7KVFS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KVFS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KVFS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KVFS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KVFS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KVFS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KVFS] CLS token array shape: (2, 512)\n",
            "[ID_Z7KYC3] Raw sequence length: 131\n",
            "[ID_Z7KYC3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KYC3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KYC3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KYC3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KYC3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KYC3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KYC3] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KYC3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KYC3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KYC3] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7KYC3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7KYC3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7KYC3] CLS token array shape: (4, 512)\n",
            "[ID_Z7LYX9] Raw sequence length: 146\n",
            "[ID_Z7LYX9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7LYX9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7LYX9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7LYX9] CLS token array shape: (5, 512)\n",
            "[ID_Z7R7YX] Raw sequence length: 79\n",
            "[ID_Z7R7YX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7R7YX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7R7YX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7R7YX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7R7YX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7R7YX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7R7YX] CLS token array shape: (2, 512)\n",
            "[ID_Z7RSEW] Raw sequence length: 79\n",
            "[ID_Z7RSEW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7RSEW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7RSEW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7RSEW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7RSEW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7RSEW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7RSEW] CLS token array shape: (2, 512)\n",
            "[ID_Z7T2GU] Raw sequence length: 79\n",
            "[ID_Z7T2GU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7T2GU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7T2GU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7T2GU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7T2GU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7T2GU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7T2GU] CLS token array shape: (2, 512)\n",
            "[ID_Z7UHRK] Raw sequence length: 129\n",
            "[ID_Z7UHRK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7UHRK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7UHRK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7UHRK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7UHRK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7UHRK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7UHRK] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7UHRK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7UHRK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7UHRK] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7UHRK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7UHRK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7UHRK] CLS token array shape: (4, 512)\n",
            "[ID_Z7WBUF] Raw sequence length: 80\n",
            "[ID_Z7WBUF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7WBUF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7WBUF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7WBUF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7WBUF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7WBUF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7WBUF] CLS token array shape: (2, 512)\n",
            "[ID_Z7ZHD2] Raw sequence length: 291\n",
            "[ID_Z7ZHD2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z7ZHD2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z7ZHD2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z7ZHD2] CLS token array shape: (11, 512)\n",
            "[ID_Z886NP] Raw sequence length: 146\n",
            "[ID_Z886NP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z886NP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z886NP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z886NP] CLS token array shape: (5, 512)\n",
            "[ID_Z8BB1K] Raw sequence length: 271\n",
            "[ID_Z8BB1K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8BB1K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8BB1K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8BB1K] CLS token array shape: (10, 512)\n",
            "[ID_Z8EX2O] Raw sequence length: 79\n",
            "[ID_Z8EX2O] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8EX2O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8EX2O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8EX2O] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8EX2O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8EX2O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8EX2O] CLS token array shape: (2, 512)\n",
            "[ID_Z8SDAM] Raw sequence length: 80\n",
            "[ID_Z8SDAM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SDAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SDAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SDAM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SDAM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SDAM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SDAM] CLS token array shape: (2, 512)\n",
            "[ID_Z8SSZN] Raw sequence length: 292\n",
            "[ID_Z8SSZN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z8SSZN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z8SSZN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z8SSZN] CLS token array shape: (11, 512)\n",
            "[ID_Z92F0M] Raw sequence length: 77\n",
            "[ID_Z92F0M] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z92F0M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z92F0M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z92F0M] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z92F0M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z92F0M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z92F0M] CLS token array shape: (2, 512)\n",
            "[ID_Z9O519] Raw sequence length: 79\n",
            "[ID_Z9O519] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9O519] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9O519] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9O519] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9O519] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9O519] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9O519] CLS token array shape: (2, 512)\n",
            "[ID_Z9QXNB] Raw sequence length: 154\n",
            "[ID_Z9QXNB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9QXNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9QXNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9QXNB] CLS token array shape: (5, 512)\n",
            "[ID_Z9VP2K] Raw sequence length: 80\n",
            "[ID_Z9VP2K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9VP2K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9VP2K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9VP2K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9VP2K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9VP2K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9VP2K] CLS token array shape: (2, 512)\n",
            "[ID_Z9XFWV] Raw sequence length: 98\n",
            "[ID_Z9XFWV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9XFWV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9XFWV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9XFWV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9XFWV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9XFWV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9XFWV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_Z9XFWV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_Z9XFWV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_Z9XFWV] CLS token array shape: (3, 512)\n",
            "[ID_ZA0VE3] Raw sequence length: 77\n",
            "[ID_ZA0VE3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA0VE3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA0VE3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA0VE3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA0VE3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA0VE3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA0VE3] CLS token array shape: (2, 512)\n",
            "[ID_ZA1QDN] Raw sequence length: 80\n",
            "[ID_ZA1QDN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA1QDN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA1QDN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA1QDN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA1QDN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA1QDN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA1QDN] CLS token array shape: (2, 512)\n",
            "[ID_ZA5EHV] Raw sequence length: 80\n",
            "[ID_ZA5EHV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA5EHV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA5EHV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA5EHV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA5EHV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA5EHV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA5EHV] CLS token array shape: (2, 512)\n",
            "[ID_ZA8SVZ] Raw sequence length: 292\n",
            "[ID_ZA8SVZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA8SVZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA8SVZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA8SVZ] CLS token array shape: (11, 512)\n",
            "[ID_ZA9DQW] Raw sequence length: 146\n",
            "[ID_ZA9DQW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZA9DQW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZA9DQW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZA9DQW] CLS token array shape: (5, 512)\n",
            "[ID_ZAEH10] Raw sequence length: 154\n",
            "[ID_ZAEH10] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAEH10] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAEH10] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAEH10] CLS token array shape: (5, 512)\n",
            "[ID_ZAK70R] Raw sequence length: 80\n",
            "[ID_ZAK70R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAK70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAK70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAK70R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAK70R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAK70R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAK70R] CLS token array shape: (2, 512)\n",
            "[ID_ZAXEMX] Raw sequence length: 292\n",
            "[ID_ZAXEMX] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXEMX] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXEMX] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXEMX] CLS token array shape: (11, 512)\n",
            "[ID_ZAXSAZ] Raw sequence length: 79\n",
            "[ID_ZAXSAZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXSAZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXSAZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXSAZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZAXSAZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZAXSAZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZAXSAZ] CLS token array shape: (2, 512)\n",
            "[ID_ZBAY9R] Raw sequence length: 79\n",
            "[ID_ZBAY9R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBAY9R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBAY9R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBAY9R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBAY9R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBAY9R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBAY9R] CLS token array shape: (2, 512)\n",
            "[ID_ZBB9X7] Raw sequence length: 80\n",
            "[ID_ZBB9X7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBB9X7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBB9X7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBB9X7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBB9X7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBB9X7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBB9X7] CLS token array shape: (2, 512)\n",
            "[ID_ZBJPAL] Raw sequence length: 79\n",
            "[ID_ZBJPAL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBJPAL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBJPAL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBJPAL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBJPAL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBJPAL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBJPAL] CLS token array shape: (2, 512)\n",
            "[ID_ZBLEG3] Raw sequence length: 80\n",
            "[ID_ZBLEG3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBLEG3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBLEG3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBLEG3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBLEG3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBLEG3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBLEG3] CLS token array shape: (2, 512)\n",
            "[ID_ZBNDFT] Raw sequence length: 74\n",
            "[ID_ZBNDFT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBNDFT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBNDFT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBNDFT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBNDFT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBNDFT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBNDFT] CLS token array shape: (2, 512)\n",
            "[ID_ZBNE1C] Raw sequence length: 80\n",
            "[ID_ZBNE1C] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBNE1C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBNE1C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBNE1C] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBNE1C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBNE1C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBNE1C] CLS token array shape: (2, 512)\n",
            "[ID_ZBPBLO] Raw sequence length: 79\n",
            "[ID_ZBPBLO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBPBLO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBPBLO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBPBLO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBPBLO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBPBLO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBPBLO] CLS token array shape: (2, 512)\n",
            "[ID_ZBQCNN] Raw sequence length: 80\n",
            "[ID_ZBQCNN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBQCNN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBQCNN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBQCNN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBQCNN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBQCNN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBQCNN] CLS token array shape: (2, 512)\n",
            "[ID_ZBUDYL] Raw sequence length: 292\n",
            "[ID_ZBUDYL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZBUDYL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZBUDYL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZBUDYL] CLS token array shape: (11, 512)\n",
            "[ID_ZC0R1A] Raw sequence length: 154\n",
            "[ID_ZC0R1A] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC0R1A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC0R1A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC0R1A] CLS token array shape: (5, 512)\n",
            "[ID_ZC80ZC] Raw sequence length: 80\n",
            "[ID_ZC80ZC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC80ZC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC80ZC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC80ZC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZC80ZC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZC80ZC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZC80ZC] CLS token array shape: (2, 512)\n",
            "[ID_ZCTFA4] Raw sequence length: 146\n",
            "[ID_ZCTFA4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTFA4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTFA4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTFA4] CLS token array shape: (5, 512)\n",
            "[ID_ZCTSNV] Raw sequence length: 80\n",
            "[ID_ZCTSNV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTSNV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTSNV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTSNV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCTSNV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCTSNV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCTSNV] CLS token array shape: (2, 512)\n",
            "[ID_ZCV4D4] Raw sequence length: 74\n",
            "[ID_ZCV4D4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCV4D4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCV4D4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCV4D4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCV4D4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCV4D4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCV4D4] CLS token array shape: (2, 512)\n",
            "[ID_ZCY9XS] Raw sequence length: 79\n",
            "[ID_ZCY9XS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCY9XS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCY9XS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCY9XS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZCY9XS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZCY9XS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZCY9XS] CLS token array shape: (2, 512)\n",
            "[ID_ZD6SS2] Raw sequence length: 292\n",
            "[ID_ZD6SS2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD6SS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD6SS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD6SS2] CLS token array shape: (11, 512)\n",
            "[ID_ZD7489] Raw sequence length: 80\n",
            "[ID_ZD7489] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD7489] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD7489] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD7489] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZD7489] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZD7489] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZD7489] CLS token array shape: (2, 512)\n",
            "[ID_ZDBJ7L] Raw sequence length: 80\n",
            "[ID_ZDBJ7L] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDBJ7L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDBJ7L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDBJ7L] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDBJ7L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDBJ7L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDBJ7L] CLS token array shape: (2, 512)\n",
            "[ID_ZDE6LC] Raw sequence length: 154\n",
            "[ID_ZDE6LC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDE6LC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDE6LC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDE6LC] CLS token array shape: (5, 512)\n",
            "[ID_ZDFPML] Raw sequence length: 79\n",
            "[ID_ZDFPML] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDFPML] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDFPML] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDFPML] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDFPML] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDFPML] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDFPML] CLS token array shape: (2, 512)\n",
            "[ID_ZDGIQV] Raw sequence length: 146\n",
            "[ID_ZDGIQV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDGIQV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDGIQV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDGIQV] CLS token array shape: (5, 512)\n",
            "[ID_ZDIFBT] Raw sequence length: 146\n",
            "[ID_ZDIFBT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDIFBT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDIFBT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDIFBT] CLS token array shape: (5, 512)\n",
            "[ID_ZDILV4] Raw sequence length: 146\n",
            "[ID_ZDILV4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDILV4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDILV4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDILV4] CLS token array shape: (5, 512)\n",
            "[ID_ZDQTLM] Raw sequence length: 291\n",
            "[ID_ZDQTLM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDQTLM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDQTLM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDQTLM] CLS token array shape: (11, 512)\n",
            "[ID_ZDSORC] Raw sequence length: 146\n",
            "[ID_ZDSORC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDSORC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDSORC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDSORC] CLS token array shape: (5, 512)\n",
            "[ID_ZDVVHP] Raw sequence length: 148\n",
            "[ID_ZDVVHP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDVVHP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDVVHP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDVVHP] CLS token array shape: (5, 512)\n",
            "[ID_ZDZ4CT] Raw sequence length: 79\n",
            "[ID_ZDZ4CT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDZ4CT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDZ4CT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDZ4CT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZDZ4CT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZDZ4CT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZDZ4CT] CLS token array shape: (2, 512)\n",
            "[ID_ZE0H7E] Raw sequence length: 79\n",
            "[ID_ZE0H7E] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE0H7E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE0H7E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE0H7E] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE0H7E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE0H7E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE0H7E] CLS token array shape: (2, 512)\n",
            "[ID_ZE3LN6] Raw sequence length: 291\n",
            "[ID_ZE3LN6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE3LN6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE3LN6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE3LN6] CLS token array shape: (11, 512)\n",
            "[ID_ZE8JB3] Raw sequence length: 79\n",
            "[ID_ZE8JB3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE8JB3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE8JB3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE8JB3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZE8JB3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZE8JB3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZE8JB3] CLS token array shape: (2, 512)\n",
            "[ID_ZEEK19] Raw sequence length: 80\n",
            "[ID_ZEEK19] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEEK19] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEEK19] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEEK19] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEEK19] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEEK19] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEEK19] CLS token array shape: (2, 512)\n",
            "[ID_ZEFI0E] Raw sequence length: 145\n",
            "[ID_ZEFI0E] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEFI0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEFI0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEFI0E] CLS token array shape: (5, 512)\n",
            "[ID_ZEHKBI] Raw sequence length: 292\n",
            "[ID_ZEHKBI] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEHKBI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEHKBI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEHKBI] CLS token array shape: (11, 512)\n",
            "[ID_ZEKY5S] Raw sequence length: 79\n",
            "[ID_ZEKY5S] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEKY5S] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEKY5S] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEKY5S] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZEKY5S] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZEKY5S] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZEKY5S] CLS token array shape: (2, 512)\n",
            "[ID_ZELAJP] Raw sequence length: 256\n",
            "[ID_ZELAJP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZELAJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZELAJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZELAJP] CLS token array shape: (9, 512)\n",
            "[ID_ZFJVT5] Raw sequence length: 80\n",
            "[ID_ZFJVT5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFJVT5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFJVT5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFJVT5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFJVT5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFJVT5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFJVT5] CLS token array shape: (2, 512)\n",
            "[ID_ZFMEM5] Raw sequence length: 146\n",
            "[ID_ZFMEM5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFMEM5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFMEM5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFMEM5] CLS token array shape: (5, 512)\n",
            "[ID_ZFT7UF] Raw sequence length: 80\n",
            "[ID_ZFT7UF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFT7UF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFT7UF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFT7UF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZFT7UF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZFT7UF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZFT7UF] CLS token array shape: (2, 512)\n",
            "[ID_ZG033J] Raw sequence length: 79\n",
            "[ID_ZG033J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG033J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG033J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG033J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG033J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG033J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG033J] CLS token array shape: (2, 512)\n",
            "[ID_ZG0XJH] Raw sequence length: 80\n",
            "[ID_ZG0XJH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG0XJH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG0XJH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG0XJH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG0XJH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG0XJH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG0XJH] CLS token array shape: (2, 512)\n",
            "[ID_ZG31D9] Raw sequence length: 146\n",
            "[ID_ZG31D9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG31D9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG31D9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG31D9] CLS token array shape: (5, 512)\n",
            "[ID_ZG8JYK] Raw sequence length: 80\n",
            "[ID_ZG8JYK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG8JYK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG8JYK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG8JYK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZG8JYK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZG8JYK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZG8JYK] CLS token array shape: (2, 512)\n",
            "[ID_ZGAD8R] Raw sequence length: 80\n",
            "[ID_ZGAD8R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGAD8R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGAD8R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGAD8R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGAD8R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGAD8R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGAD8R] CLS token array shape: (2, 512)\n",
            "[ID_ZGKQ83] Raw sequence length: 80\n",
            "[ID_ZGKQ83] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGKQ83] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGKQ83] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGKQ83] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGKQ83] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGKQ83] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGKQ83] CLS token array shape: (2, 512)\n",
            "[ID_ZGKSFK] Raw sequence length: 80\n",
            "[ID_ZGKSFK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGKSFK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGKSFK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGKSFK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGKSFK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGKSFK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGKSFK] CLS token array shape: (2, 512)\n",
            "[ID_ZGM7VU] Raw sequence length: 79\n",
            "[ID_ZGM7VU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGM7VU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGM7VU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGM7VU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGM7VU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGM7VU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGM7VU] CLS token array shape: (2, 512)\n",
            "[ID_ZGPMDW] Raw sequence length: 79\n",
            "[ID_ZGPMDW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGPMDW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGPMDW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGPMDW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGPMDW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGPMDW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGPMDW] CLS token array shape: (2, 512)\n",
            "[ID_ZGR643] Raw sequence length: 79\n",
            "[ID_ZGR643] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGR643] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGR643] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGR643] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZGR643] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZGR643] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZGR643] CLS token array shape: (2, 512)\n",
            "[ID_ZH9J6J] Raw sequence length: 146\n",
            "[ID_ZH9J6J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZH9J6J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZH9J6J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZH9J6J] CLS token array shape: (5, 512)\n",
            "[ID_ZHJ8MA] Raw sequence length: 146\n",
            "[ID_ZHJ8MA] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHJ8MA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHJ8MA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHJ8MA] CLS token array shape: (5, 512)\n",
            "[ID_ZHMQYN] Raw sequence length: 80\n",
            "[ID_ZHMQYN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHMQYN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHMQYN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHMQYN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHMQYN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHMQYN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHMQYN] CLS token array shape: (2, 512)\n",
            "[ID_ZHOZJE] Raw sequence length: 74\n",
            "[ID_ZHOZJE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHOZJE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHOZJE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHOZJE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHOZJE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHOZJE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHOZJE] CLS token array shape: (2, 512)\n",
            "[ID_ZHR76K] Raw sequence length: 79\n",
            "[ID_ZHR76K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHR76K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHR76K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHR76K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHR76K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHR76K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHR76K] CLS token array shape: (2, 512)\n",
            "[ID_ZHVUNB] Raw sequence length: 204\n",
            "[ID_ZHVUNB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHVUNB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHVUNB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHVUNB] CLS token array shape: (7, 512)\n",
            "[ID_ZHXTJI] Raw sequence length: 144\n",
            "[ID_ZHXTJI] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHXTJI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHXTJI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHXTJI] CLS token array shape: (5, 512)\n",
            "[ID_ZHYRV7] Raw sequence length: 145\n",
            "[ID_ZHYRV7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZHYRV7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZHYRV7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZHYRV7] CLS token array shape: (5, 512)\n",
            "[ID_ZI10A7] Raw sequence length: 80\n",
            "[ID_ZI10A7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI10A7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI10A7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI10A7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI10A7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI10A7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI10A7] CLS token array shape: (2, 512)\n",
            "[ID_ZI4M2D] Raw sequence length: 80\n",
            "[ID_ZI4M2D] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI4M2D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI4M2D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI4M2D] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI4M2D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI4M2D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI4M2D] CLS token array shape: (2, 512)\n",
            "[ID_ZI89A7] Raw sequence length: 80\n",
            "[ID_ZI89A7] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI89A7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI89A7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI89A7] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI89A7] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI89A7] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI89A7] CLS token array shape: (2, 512)\n",
            "[ID_ZI8RNO] Raw sequence length: 80\n",
            "[ID_ZI8RNO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI8RNO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI8RNO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI8RNO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZI8RNO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZI8RNO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZI8RNO] CLS token array shape: (2, 512)\n",
            "[ID_ZIKO2K] Raw sequence length: 79\n",
            "[ID_ZIKO2K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIKO2K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIKO2K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIKO2K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIKO2K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIKO2K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIKO2K] CLS token array shape: (2, 512)\n",
            "[ID_ZIQ5M1] Raw sequence length: 80\n",
            "[ID_ZIQ5M1] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIQ5M1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIQ5M1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIQ5M1] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIQ5M1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIQ5M1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIQ5M1] CLS token array shape: (2, 512)\n",
            "[ID_ZITA1Z] Raw sequence length: 154\n",
            "[ID_ZITA1Z] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITA1Z] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITA1Z] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITA1Z] CLS token array shape: (5, 512)\n",
            "[ID_ZITXBE] Raw sequence length: 292\n",
            "[ID_ZITXBE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZITXBE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZITXBE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZITXBE] CLS token array shape: (11, 512)\n",
            "[ID_ZIVO0K] Raw sequence length: 79\n",
            "[ID_ZIVO0K] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIVO0K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIVO0K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIVO0K] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIVO0K] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIVO0K] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIVO0K] CLS token array shape: (2, 512)\n",
            "[ID_ZIXDCB] Raw sequence length: 145\n",
            "[ID_ZIXDCB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZIXDCB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZIXDCB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZIXDCB] CLS token array shape: (5, 512)\n",
            "[ID_ZJ00U3] Raw sequence length: 146\n",
            "[ID_ZJ00U3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ00U3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ00U3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ00U3] CLS token array shape: (5, 512)\n",
            "[ID_ZJ7UN9] Raw sequence length: 145\n",
            "[ID_ZJ7UN9] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ7UN9] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ7UN9] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ7UN9] CLS token array shape: (5, 512)\n",
            "[ID_ZJ9U9V] Raw sequence length: 146\n",
            "[ID_ZJ9U9V] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJ9U9V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJ9U9V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJ9U9V] CLS token array shape: (5, 512)\n",
            "[ID_ZJDFWZ] Raw sequence length: 80\n",
            "[ID_ZJDFWZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJDFWZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJDFWZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJDFWZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJDFWZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJDFWZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJDFWZ] CLS token array shape: (2, 512)\n",
            "[ID_ZJPD8O] Raw sequence length: 292\n",
            "[ID_ZJPD8O] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJPD8O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJPD8O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJPD8O] CLS token array shape: (11, 512)\n",
            "[ID_ZJTGHR] Raw sequence length: 78\n",
            "[ID_ZJTGHR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJTGHR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJTGHR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJTGHR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZJTGHR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZJTGHR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZJTGHR] CLS token array shape: (2, 512)\n",
            "[ID_ZK0MV8] Raw sequence length: 79\n",
            "[ID_ZK0MV8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK0MV8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK0MV8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK0MV8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK0MV8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK0MV8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK0MV8] CLS token array shape: (2, 512)\n",
            "[ID_ZK0SMK] Raw sequence length: 80\n",
            "[ID_ZK0SMK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK0SMK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK0SMK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK0SMK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK0SMK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK0SMK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK0SMK] CLS token array shape: (2, 512)\n",
            "[ID_ZK3NRI] Raw sequence length: 79\n",
            "[ID_ZK3NRI] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK3NRI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK3NRI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK3NRI] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK3NRI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK3NRI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK3NRI] CLS token array shape: (2, 512)\n",
            "[ID_ZK9XJJ] Raw sequence length: 146\n",
            "[ID_ZK9XJJ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZK9XJJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZK9XJJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZK9XJJ] CLS token array shape: (5, 512)\n",
            "[ID_ZKHBJR] Raw sequence length: 80\n",
            "[ID_ZKHBJR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKHBJR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKHBJR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKHBJR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKHBJR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKHBJR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKHBJR] CLS token array shape: (2, 512)\n",
            "[ID_ZKNTJ8] Raw sequence length: 292\n",
            "[ID_ZKNTJ8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKNTJ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKNTJ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKNTJ8] CLS token array shape: (11, 512)\n",
            "[ID_ZKS1Y8] Raw sequence length: 80\n",
            "[ID_ZKS1Y8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKS1Y8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKS1Y8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKS1Y8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKS1Y8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKS1Y8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKS1Y8] CLS token array shape: (2, 512)\n",
            "[ID_ZKUVPM] Raw sequence length: 145\n",
            "[ID_ZKUVPM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKUVPM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKUVPM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKUVPM] CLS token array shape: (5, 512)\n",
            "[ID_ZKVAUE] Raw sequence length: 146\n",
            "[ID_ZKVAUE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKVAUE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKVAUE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKVAUE] CLS token array shape: (5, 512)\n",
            "[ID_ZKXXJ5] Raw sequence length: 79\n",
            "[ID_ZKXXJ5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKXXJ5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKXXJ5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKXXJ5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZKXXJ5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZKXXJ5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZKXXJ5] CLS token array shape: (2, 512)\n",
            "[ID_ZL3BCT] Raw sequence length: 79\n",
            "[ID_ZL3BCT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZL3BCT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZL3BCT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZL3BCT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZL3BCT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZL3BCT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZL3BCT] CLS token array shape: (2, 512)\n",
            "[ID_ZL9XX2] Raw sequence length: 80\n",
            "[ID_ZL9XX2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZL9XX2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZL9XX2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZL9XX2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZL9XX2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZL9XX2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZL9XX2] CLS token array shape: (2, 512)\n",
            "[ID_ZLB0W3] Raw sequence length: 126\n",
            "[ID_ZLB0W3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLB0W3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLB0W3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLB0W3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLB0W3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLB0W3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLB0W3] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLB0W3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLB0W3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLB0W3] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLB0W3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLB0W3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLB0W3] CLS token array shape: (4, 512)\n",
            "[ID_ZLBEWE] Raw sequence length: 80\n",
            "[ID_ZLBEWE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBEWE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBEWE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBEWE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBEWE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBEWE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBEWE] CLS token array shape: (2, 512)\n",
            "[ID_ZLBJPC] Raw sequence length: 291\n",
            "[ID_ZLBJPC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLBJPC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLBJPC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLBJPC] CLS token array shape: (11, 512)\n",
            "[ID_ZLJ7PL] Raw sequence length: 80\n",
            "[ID_ZLJ7PL] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLJ7PL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLJ7PL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLJ7PL] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLJ7PL] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLJ7PL] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLJ7PL] CLS token array shape: (2, 512)\n",
            "[ID_ZLKX3Q] Raw sequence length: 154\n",
            "[ID_ZLKX3Q] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLKX3Q] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLKX3Q] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLKX3Q] CLS token array shape: (5, 512)\n",
            "[ID_ZLM59I] Raw sequence length: 79\n",
            "[ID_ZLM59I] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLM59I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLM59I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLM59I] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLM59I] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLM59I] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLM59I] CLS token array shape: (2, 512)\n",
            "[ID_ZLOP6A] Raw sequence length: 146\n",
            "[ID_ZLOP6A] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLOP6A] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLOP6A] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLOP6A] CLS token array shape: (5, 512)\n",
            "[ID_ZLX9CR] Raw sequence length: 80\n",
            "[ID_ZLX9CR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLX9CR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLX9CR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLX9CR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZLX9CR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZLX9CR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZLX9CR] CLS token array shape: (2, 512)\n",
            "[ID_ZM3XJQ] Raw sequence length: 146\n",
            "[ID_ZM3XJQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM3XJQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM3XJQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM3XJQ] CLS token array shape: (5, 512)\n",
            "[ID_ZM6H38] Raw sequence length: 80\n",
            "[ID_ZM6H38] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM6H38] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM6H38] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM6H38] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM6H38] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM6H38] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM6H38] CLS token array shape: (2, 512)\n",
            "[ID_ZM8JLB] Raw sequence length: 80\n",
            "[ID_ZM8JLB] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM8JLB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM8JLB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM8JLB] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZM8JLB] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZM8JLB] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZM8JLB] CLS token array shape: (2, 512)\n",
            "[ID_ZMA4KV] Raw sequence length: 145\n",
            "[ID_ZMA4KV] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMA4KV] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMA4KV] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMA4KV] CLS token array shape: (5, 512)\n",
            "[ID_ZMG0QS] Raw sequence length: 77\n",
            "[ID_ZMG0QS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMG0QS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMG0QS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMG0QS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMG0QS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMG0QS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMG0QS] CLS token array shape: (2, 512)\n",
            "[ID_ZMJOYK] Raw sequence length: 80\n",
            "[ID_ZMJOYK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMJOYK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMJOYK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMJOYK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMJOYK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMJOYK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMJOYK] CLS token array shape: (2, 512)\n",
            "[ID_ZMKCQA] Raw sequence length: 80\n",
            "[ID_ZMKCQA] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMKCQA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMKCQA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMKCQA] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMKCQA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMKCQA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMKCQA] CLS token array shape: (2, 512)\n",
            "[ID_ZMT8IU] Raw sequence length: 129\n",
            "[ID_ZMT8IU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT8IU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT8IU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT8IU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT8IU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT8IU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT8IU] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT8IU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT8IU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT8IU] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT8IU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT8IU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT8IU] CLS token array shape: (4, 512)\n",
            "[ID_ZMT965] Raw sequence length: 292\n",
            "[ID_ZMT965] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMT965] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMT965] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMT965] CLS token array shape: (11, 512)\n",
            "[ID_ZMW79D] Raw sequence length: 79\n",
            "[ID_ZMW79D] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMW79D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMW79D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMW79D] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMW79D] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMW79D] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMW79D] CLS token array shape: (2, 512)\n",
            "[ID_ZMYI7J] Raw sequence length: 79\n",
            "[ID_ZMYI7J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMYI7J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMYI7J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMYI7J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMYI7J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMYI7J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMYI7J] CLS token array shape: (2, 512)\n",
            "[ID_ZMZKA8] Raw sequence length: 146\n",
            "[ID_ZMZKA8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZMZKA8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZMZKA8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZMZKA8] CLS token array shape: (5, 512)\n",
            "[ID_ZNGE8W] Raw sequence length: 145\n",
            "[ID_ZNGE8W] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNGE8W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNGE8W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNGE8W] CLS token array shape: (5, 512)\n",
            "[ID_ZNIU3V] Raw sequence length: 80\n",
            "[ID_ZNIU3V] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNIU3V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNIU3V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNIU3V] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNIU3V] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNIU3V] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNIU3V] CLS token array shape: (2, 512)\n",
            "[ID_ZNV5QM] Raw sequence length: 154\n",
            "[ID_ZNV5QM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNV5QM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNV5QM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNV5QM] CLS token array shape: (5, 512)\n",
            "[ID_ZNW7TJ] Raw sequence length: 79\n",
            "[ID_ZNW7TJ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNW7TJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNW7TJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNW7TJ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNW7TJ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNW7TJ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNW7TJ] CLS token array shape: (2, 512)\n",
            "[ID_ZNWGRR] Raw sequence length: 146\n",
            "[ID_ZNWGRR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNWGRR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNWGRR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNWGRR] CLS token array shape: (5, 512)\n",
            "[ID_ZNX7ZE] Raw sequence length: 79\n",
            "[ID_ZNX7ZE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNX7ZE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNX7ZE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNX7ZE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNX7ZE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNX7ZE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNX7ZE] CLS token array shape: (2, 512)\n",
            "[ID_ZNYAJN] Raw sequence length: 126\n",
            "[ID_ZNYAJN] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNYAJN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNYAJN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNYAJN] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNYAJN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNYAJN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNYAJN] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNYAJN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNYAJN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNYAJN] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZNYAJN] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZNYAJN] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZNYAJN] CLS token array shape: (4, 512)\n",
            "[ID_ZO04I6] Raw sequence length: 79\n",
            "[ID_ZO04I6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO04I6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO04I6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO04I6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO04I6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO04I6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO04I6] CLS token array shape: (2, 512)\n",
            "[ID_ZO3TEW] Raw sequence length: 80\n",
            "[ID_ZO3TEW] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO3TEW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO3TEW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO3TEW] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO3TEW] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO3TEW] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO3TEW] CLS token array shape: (2, 512)\n",
            "[ID_ZO7767] Raw sequence length: 74\n",
            "[ID_ZO7767] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO7767] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO7767] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO7767] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZO7767] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZO7767] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZO7767] CLS token array shape: (2, 512)\n",
            "[ID_ZOBXT0] Raw sequence length: 154\n",
            "[ID_ZOBXT0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOBXT0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOBXT0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOBXT0] CLS token array shape: (5, 512)\n",
            "[ID_ZODZK2] Raw sequence length: 80\n",
            "[ID_ZODZK2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZODZK2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZODZK2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZODZK2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZODZK2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZODZK2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZODZK2] CLS token array shape: (2, 512)\n",
            "[ID_ZOE9G3] Raw sequence length: 79\n",
            "[ID_ZOE9G3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9G3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9G3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9G3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9G3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9G3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9G3] CLS token array shape: (2, 512)\n",
            "[ID_ZOE9X6] Raw sequence length: 290\n",
            "[ID_ZOE9X6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOE9X6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOE9X6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOE9X6] CLS token array shape: (11, 512)\n",
            "[ID_ZOGEJU] Raw sequence length: 146\n",
            "[ID_ZOGEJU] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOGEJU] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOGEJU] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOGEJU] CLS token array shape: (5, 512)\n",
            "[ID_ZOKU5O] Raw sequence length: 145\n",
            "[ID_ZOKU5O] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOKU5O] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOKU5O] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOKU5O] CLS token array shape: (5, 512)\n",
            "[ID_ZOLFUK] Raw sequence length: 79\n",
            "[ID_ZOLFUK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOLFUK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOLFUK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOLFUK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOLFUK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOLFUK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOLFUK] CLS token array shape: (2, 512)\n",
            "[ID_ZOLH5W] Raw sequence length: 79\n",
            "[ID_ZOLH5W] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOLH5W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOLH5W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOLH5W] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOLH5W] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOLH5W] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOLH5W] CLS token array shape: (2, 512)\n",
            "[ID_ZOP96N] Raw sequence length: 146\n",
            "[ID_ZOP96N] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOP96N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOP96N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOP96N] CLS token array shape: (5, 512)\n",
            "[ID_ZOQ80F] Raw sequence length: 78\n",
            "[ID_ZOQ80F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOQ80F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOQ80F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOQ80F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZOQ80F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZOQ80F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZOQ80F] CLS token array shape: (2, 512)\n",
            "[ID_ZPAYBZ] Raw sequence length: 154\n",
            "[ID_ZPAYBZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPAYBZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPAYBZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPAYBZ] CLS token array shape: (5, 512)\n",
            "[ID_ZPGN0E] Raw sequence length: 79\n",
            "[ID_ZPGN0E] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPGN0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPGN0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPGN0E] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPGN0E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPGN0E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPGN0E] CLS token array shape: (2, 512)\n",
            "[ID_ZPNB5H] Raw sequence length: 155\n",
            "[ID_ZPNB5H] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPNB5H] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPNB5H] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPNB5H] CLS token array shape: (5, 512)\n",
            "[ID_ZPQ51R] Raw sequence length: 80\n",
            "[ID_ZPQ51R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPQ51R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPQ51R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPQ51R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPQ51R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPQ51R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPQ51R] CLS token array shape: (2, 512)\n",
            "[ID_ZPQ5MZ] Raw sequence length: 77\n",
            "[ID_ZPQ5MZ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPQ5MZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPQ5MZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPQ5MZ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPQ5MZ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPQ5MZ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPQ5MZ] CLS token array shape: (2, 512)\n",
            "[ID_ZPRPO3] Raw sequence length: 80\n",
            "[ID_ZPRPO3] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPRPO3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPRPO3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPRPO3] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPRPO3] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPRPO3] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPRPO3] CLS token array shape: (2, 512)\n",
            "[ID_ZPY671] Raw sequence length: 80\n",
            "[ID_ZPY671] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPY671] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPY671] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPY671] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZPY671] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZPY671] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZPY671] CLS token array shape: (2, 512)\n",
            "[ID_ZQ5H4U] Raw sequence length: 80\n",
            "[ID_ZQ5H4U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ5H4U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ5H4U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ5H4U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ5H4U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ5H4U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ5H4U] CLS token array shape: (2, 512)\n",
            "[ID_ZQ6CO6] Raw sequence length: 79\n",
            "[ID_ZQ6CO6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ6CO6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ6CO6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ6CO6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ6CO6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ6CO6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ6CO6] CLS token array shape: (2, 512)\n",
            "[ID_ZQ97GG] Raw sequence length: 145\n",
            "[ID_ZQ97GG] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQ97GG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQ97GG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQ97GG] CLS token array shape: (5, 512)\n",
            "[ID_ZQCPFH] Raw sequence length: 145\n",
            "[ID_ZQCPFH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQCPFH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQCPFH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQCPFH] CLS token array shape: (5, 512)\n",
            "[ID_ZQEHWQ] Raw sequence length: 146\n",
            "[ID_ZQEHWQ] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQEHWQ] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQEHWQ] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQEHWQ] CLS token array shape: (5, 512)\n",
            "[ID_ZQI5RF] Raw sequence length: 78\n",
            "[ID_ZQI5RF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQI5RF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQI5RF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQI5RF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQI5RF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQI5RF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQI5RF] CLS token array shape: (2, 512)\n",
            "[ID_ZQLNHD] Raw sequence length: 80\n",
            "[ID_ZQLNHD] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQLNHD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQLNHD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQLNHD] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQLNHD] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQLNHD] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQLNHD] CLS token array shape: (2, 512)\n",
            "[ID_ZQPZR4] Raw sequence length: 80\n",
            "[ID_ZQPZR4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQPZR4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQPZR4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQPZR4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQPZR4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQPZR4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQPZR4] CLS token array shape: (2, 512)\n",
            "[ID_ZQXI2E] Raw sequence length: 79\n",
            "[ID_ZQXI2E] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQXI2E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQXI2E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQXI2E] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZQXI2E] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZQXI2E] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZQXI2E] CLS token array shape: (2, 512)\n",
            "[ID_ZR4NS4] Raw sequence length: 159\n",
            "[ID_ZR4NS4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZR4NS4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZR4NS4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZR4NS4] CLS token array shape: (5, 512)\n",
            "[ID_ZRC5N0] Raw sequence length: 145\n",
            "[ID_ZRC5N0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRC5N0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRC5N0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRC5N0] CLS token array shape: (5, 512)\n",
            "[ID_ZRCNS2] Raw sequence length: 101\n",
            "[ID_ZRCNS2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRCNS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRCNS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRCNS2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRCNS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRCNS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRCNS2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRCNS2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRCNS2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRCNS2] CLS token array shape: (3, 512)\n",
            "[ID_ZRDJLE] Raw sequence length: 146\n",
            "[ID_ZRDJLE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRDJLE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRDJLE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRDJLE] CLS token array shape: (5, 512)\n",
            "[ID_ZREWKM] Raw sequence length: 145\n",
            "[ID_ZREWKM] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZREWKM] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZREWKM] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZREWKM] CLS token array shape: (5, 512)\n",
            "[ID_ZRFS2P] Raw sequence length: 154\n",
            "[ID_ZRFS2P] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRFS2P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRFS2P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRFS2P] CLS token array shape: (5, 512)\n",
            "[ID_ZRGG3F] Raw sequence length: 74\n",
            "[ID_ZRGG3F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRGG3F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRGG3F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRGG3F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRGG3F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRGG3F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRGG3F] CLS token array shape: (2, 512)\n",
            "[ID_ZRH3Z5] Raw sequence length: 79\n",
            "[ID_ZRH3Z5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRH3Z5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRH3Z5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRH3Z5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRH3Z5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRH3Z5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRH3Z5] CLS token array shape: (2, 512)\n",
            "[ID_ZRKJ5U] Raw sequence length: 79\n",
            "[ID_ZRKJ5U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRKJ5U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRKJ5U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRKJ5U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRKJ5U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRKJ5U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRKJ5U] CLS token array shape: (2, 512)\n",
            "[ID_ZRSC7M] Raw sequence length: 145\n",
            "[ID_ZRSC7M] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRSC7M] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRSC7M] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRSC7M] CLS token array shape: (5, 512)\n",
            "[ID_ZRUPK5] Raw sequence length: 79\n",
            "[ID_ZRUPK5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRUPK5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRUPK5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRUPK5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRUPK5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRUPK5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRUPK5] CLS token array shape: (2, 512)\n",
            "[ID_ZRZ410] Raw sequence length: 80\n",
            "[ID_ZRZ410] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRZ410] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRZ410] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRZ410] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRZ410] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRZ410] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRZ410] CLS token array shape: (2, 512)\n",
            "[ID_ZRZPXA] Raw sequence length: 79\n",
            "[ID_ZRZPXA] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRZPXA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRZPXA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRZPXA] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZRZPXA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZRZPXA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZRZPXA] CLS token array shape: (2, 512)\n",
            "[ID_ZS17RR] Raw sequence length: 80\n",
            "[ID_ZS17RR] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS17RR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS17RR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS17RR] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS17RR] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS17RR] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS17RR] CLS token array shape: (2, 512)\n",
            "[ID_ZS4ATE] Raw sequence length: 80\n",
            "[ID_ZS4ATE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS4ATE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS4ATE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS4ATE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS4ATE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS4ATE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS4ATE] CLS token array shape: (2, 512)\n",
            "[ID_ZS963Y] Raw sequence length: 80\n",
            "[ID_ZS963Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS963Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS963Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS963Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZS963Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZS963Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZS963Y] CLS token array shape: (2, 512)\n",
            "[ID_ZSCAPE] Raw sequence length: 291\n",
            "[ID_ZSCAPE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSCAPE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSCAPE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSCAPE] CLS token array shape: (11, 512)\n",
            "[ID_ZSK2V0] Raw sequence length: 79\n",
            "[ID_ZSK2V0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSK2V0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSK2V0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSK2V0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSK2V0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSK2V0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSK2V0] CLS token array shape: (2, 512)\n",
            "[ID_ZSKVWC] Raw sequence length: 80\n",
            "[ID_ZSKVWC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSKVWC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSKVWC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSKVWC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSKVWC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSKVWC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSKVWC] CLS token array shape: (2, 512)\n",
            "[ID_ZSMUJP] Raw sequence length: 80\n",
            "[ID_ZSMUJP] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSMUJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSMUJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSMUJP] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSMUJP] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSMUJP] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSMUJP] CLS token array shape: (2, 512)\n",
            "[ID_ZSW9R5] Raw sequence length: 79\n",
            "[ID_ZSW9R5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSW9R5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSW9R5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSW9R5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSW9R5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSW9R5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSW9R5] CLS token array shape: (2, 512)\n",
            "[ID_ZSWVZ8] Raw sequence length: 154\n",
            "[ID_ZSWVZ8] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZSWVZ8] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZSWVZ8] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZSWVZ8] CLS token array shape: (5, 512)\n",
            "[ID_ZTD5W2] Raw sequence length: 79\n",
            "[ID_ZTD5W2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTD5W2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTD5W2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTD5W2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTD5W2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTD5W2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTD5W2] CLS token array shape: (2, 512)\n",
            "[ID_ZTHFDF] Raw sequence length: 80\n",
            "[ID_ZTHFDF] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTHFDF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTHFDF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTHFDF] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTHFDF] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTHFDF] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTHFDF] CLS token array shape: (2, 512)\n",
            "[ID_ZTNT6L] Raw sequence length: 154\n",
            "[ID_ZTNT6L] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTNT6L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTNT6L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTNT6L] CLS token array shape: (5, 512)\n",
            "[ID_ZTS34F] Raw sequence length: 79\n",
            "[ID_ZTS34F] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTS34F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTS34F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTS34F] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZTS34F] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZTS34F] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZTS34F] CLS token array shape: (2, 512)\n",
            "[ID_ZU8KEC] Raw sequence length: 80\n",
            "[ID_ZU8KEC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZU8KEC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZU8KEC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZU8KEC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZU8KEC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZU8KEC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZU8KEC] CLS token array shape: (2, 512)\n",
            "[ID_ZUCM2J] Raw sequence length: 78\n",
            "[ID_ZUCM2J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUCM2J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUCM2J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUCM2J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUCM2J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUCM2J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUCM2J] CLS token array shape: (2, 512)\n",
            "[ID_ZUFF8P] Raw sequence length: 80\n",
            "[ID_ZUFF8P] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUFF8P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUFF8P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUFF8P] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUFF8P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUFF8P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUFF8P] CLS token array shape: (2, 512)\n",
            "[ID_ZUIN5P] Raw sequence length: 79\n",
            "[ID_ZUIN5P] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUIN5P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUIN5P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUIN5P] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZUIN5P] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZUIN5P] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZUIN5P] CLS token array shape: (2, 512)\n",
            "[ID_ZV61RS] Raw sequence length: 129\n",
            "[ID_ZV61RS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZV61RS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZV61RS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZV61RS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZV61RS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZV61RS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZV61RS] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZV61RS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZV61RS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZV61RS] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZV61RS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZV61RS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZV61RS] CLS token array shape: (4, 512)\n",
            "[ID_ZVGXX0] Raw sequence length: 80\n",
            "[ID_ZVGXX0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVGXX0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVGXX0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVGXX0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVGXX0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVGXX0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVGXX0] CLS token array shape: (2, 512)\n",
            "[ID_ZVKBF5] Raw sequence length: 79\n",
            "[ID_ZVKBF5] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVKBF5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVKBF5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVKBF5] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVKBF5] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVKBF5] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVKBF5] CLS token array shape: (2, 512)\n",
            "[ID_ZVU1ZI] Raw sequence length: 79\n",
            "[ID_ZVU1ZI] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVU1ZI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVU1ZI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVU1ZI] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVU1ZI] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVU1ZI] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVU1ZI] CLS token array shape: (2, 512)\n",
            "[ID_ZVUPSK] Raw sequence length: 80\n",
            "[ID_ZVUPSK] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVUPSK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVUPSK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVUPSK] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZVUPSK] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZVUPSK] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZVUPSK] CLS token array shape: (2, 512)\n",
            "[ID_ZW2YU4] Raw sequence length: 79\n",
            "[ID_ZW2YU4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZW2YU4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZW2YU4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZW2YU4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZW2YU4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZW2YU4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZW2YU4] CLS token array shape: (2, 512)\n",
            "[ID_ZW6U4C] Raw sequence length: 79\n",
            "[ID_ZW6U4C] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZW6U4C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZW6U4C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZW6U4C] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZW6U4C] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZW6U4C] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZW6U4C] CLS token array shape: (2, 512)\n",
            "[ID_ZWBNJE] Raw sequence length: 80\n",
            "[ID_ZWBNJE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWBNJE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWBNJE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWBNJE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWBNJE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWBNJE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWBNJE] CLS token array shape: (2, 512)\n",
            "[ID_ZWECCO] Raw sequence length: 292\n",
            "[ID_ZWECCO] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWECCO] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWECCO] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWECCO] CLS token array shape: (11, 512)\n",
            "[ID_ZWHNOT] Raw sequence length: 146\n",
            "[ID_ZWHNOT] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHNOT] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHNOT] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHNOT] CLS token array shape: (5, 512)\n",
            "[ID_ZWHOG6] Raw sequence length: 74\n",
            "[ID_ZWHOG6] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHOG6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHOG6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHOG6] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHOG6] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHOG6] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHOG6] CLS token array shape: (2, 512)\n",
            "[ID_ZWHV0R] Raw sequence length: 80\n",
            "[ID_ZWHV0R] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHV0R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHV0R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHV0R] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWHV0R] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWHV0R] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWHV0R] CLS token array shape: (2, 512)\n",
            "[ID_ZWM728] Raw sequence length: 256\n",
            "[ID_ZWM728] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWM728] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWM728] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWM728] CLS token array shape: (9, 512)\n",
            "[ID_ZWQENE] Raw sequence length: 146\n",
            "[ID_ZWQENE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWQENE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWQENE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWQENE] CLS token array shape: (5, 512)\n",
            "[ID_ZWR2AH] Raw sequence length: 129\n",
            "[ID_ZWR2AH] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWR2AH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWR2AH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWR2AH] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWR2AH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWR2AH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWR2AH] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWR2AH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWR2AH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWR2AH] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWR2AH] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWR2AH] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWR2AH] CLS token array shape: (4, 512)\n",
            "[ID_ZWSJF0] Raw sequence length: 168\n",
            "[ID_ZWSJF0] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZWSJF0] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZWSJF0] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZWSJF0] CLS token array shape: (6, 512)\n",
            "[ID_ZX6I2U] Raw sequence length: 84\n",
            "[ID_ZX6I2U] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZX6I2U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZX6I2U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZX6I2U] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZX6I2U] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZX6I2U] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZX6I2U] CLS token array shape: (2, 512)\n",
            "[ID_ZXDC0J] Raw sequence length: 152\n",
            "[ID_ZXDC0J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXDC0J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXDC0J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXDC0J] CLS token array shape: (5, 512)\n",
            "[ID_ZXM3J1] Raw sequence length: 129\n",
            "[ID_ZXM3J1] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXM3J1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXM3J1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXM3J1] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXM3J1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXM3J1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXM3J1] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXM3J1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXM3J1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXM3J1] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXM3J1] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXM3J1] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXM3J1] CLS token array shape: (4, 512)\n",
            "[ID_ZXRISS] Raw sequence length: 79\n",
            "[ID_ZXRISS] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXRISS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXRISS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXRISS] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXRISS] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXRISS] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXRISS] CLS token array shape: (2, 512)\n",
            "[ID_ZXTIGY] Raw sequence length: 79\n",
            "[ID_ZXTIGY] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXTIGY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXTIGY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXTIGY] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZXTIGY] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZXTIGY] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZXTIGY] CLS token array shape: (2, 512)\n",
            "[ID_ZY2Z4Y] Raw sequence length: 146\n",
            "[ID_ZY2Z4Y] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY2Z4Y] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY2Z4Y] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY2Z4Y] CLS token array shape: (5, 512)\n",
            "[ID_ZY8T54] Raw sequence length: 292\n",
            "[ID_ZY8T54] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY8T54] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY8T54] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY8T54] CLS token array shape: (11, 512)\n",
            "[ID_ZY907J] Raw sequence length: 79\n",
            "[ID_ZY907J] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY907J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY907J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY907J] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZY907J] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZY907J] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZY907J] CLS token array shape: (2, 512)\n",
            "[ID_ZYH3ZG] Raw sequence length: 80\n",
            "[ID_ZYH3ZG] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYH3ZG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYH3ZG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYH3ZG] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYH3ZG] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYH3ZG] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYH3ZG] CLS token array shape: (2, 512)\n",
            "[ID_ZYN260] Raw sequence length: 77\n",
            "[ID_ZYN260] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYN260] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYN260] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYN260] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYN260] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYN260] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYN260] CLS token array shape: (2, 512)\n",
            "[ID_ZYZPJ4] Raw sequence length: 80\n",
            "[ID_ZYZPJ4] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYZPJ4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYZPJ4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYZPJ4] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZYZPJ4] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZYZPJ4] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZYZPJ4] CLS token array shape: (2, 512)\n",
            "[ID_ZZ5C2L] Raw sequence length: 80\n",
            "[ID_ZZ5C2L] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZ5C2L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZ5C2L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZ5C2L] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZ5C2L] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZ5C2L] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZ5C2L] CLS token array shape: (2, 512)\n",
            "[ID_ZZDVEC] Raw sequence length: 80\n",
            "[ID_ZZDVEC] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZDVEC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZDVEC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZDVEC] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZDVEC] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZDVEC] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZDVEC] CLS token array shape: (2, 512)\n",
            "[ID_ZZK9QA] Raw sequence length: 80\n",
            "[ID_ZZK9QA] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZK9QA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZK9QA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZK9QA] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZK9QA] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZK9QA] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZK9QA] CLS token array shape: (2, 512)\n",
            "[ID_ZZNU8N] Raw sequence length: 79\n",
            "[ID_ZZNU8N] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZNU8N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZNU8N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZNU8N] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZNU8N] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZNU8N] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZNU8N] CLS token array shape: (2, 512)\n",
            "[ID_ZZPXSE] Raw sequence length: 79\n",
            "[ID_ZZPXSE] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZPXSE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZPXSE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZPXSE] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZPXSE] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZPXSE] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZPXSE] CLS token array shape: (2, 512)\n",
            "[ID_ZZUHF2] Raw sequence length: 154\n",
            "[ID_ZZUHF2] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZUHF2] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZUHF2] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZUHF2] CLS token array shape: (5, 512)\n",
            "[ID_ZZVJ91] Raw sequence length: 292\n",
            "[ID_ZZVJ91] Window 0 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 24 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 48 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 72 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 96 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 120 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 144 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 168 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 192 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 216 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] Window 240 input shape: torch.Size([1, 48, 10])\n",
            "[ID_ZZVJ91] Output type: <class 'transformers.models.patchtst.modeling_patchtst.PatchTSTModelOutput'>\n",
            "[ID_ZZVJ91] Output shape: torch.Size([1, 10, 5, 512])\n",
            "[ID_ZZVJ91] CLS token array shape: (11, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for uid, cls_list in cls_embeddings.items():\n",
        "    arr = np.array(cls_list)\n",
        "    print(f\"{uid}  shape: {arr.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekNlJgQR0QaR",
        "outputId": "ccfa7e8e-354b-433b-e9a6-36a47ee202ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIXEL_0001  shape: (1, 512)\n",
            "PIXEL_0002  shape: (3, 512)\n",
            "PIXEL_0003  shape: (3, 512)\n",
            "PIXEL_0004  shape: (1, 512)\n",
            "PIXEL_0005  shape: (1, 512)\n",
            "PIXEL_0006  shape: (3, 512)\n",
            "PIXEL_0007  shape: (1, 512)\n",
            "PIXEL_0008  shape: (3, 512)\n",
            "PIXEL_0009  shape: (1, 512)\n",
            "PIXEL_0010  shape: (1, 512)\n",
            "PIXEL_0011  shape: (1, 512)\n",
            "PIXEL_0012  shape: (1, 512)\n",
            "PIXEL_0013  shape: (1, 512)\n",
            "PIXEL_0014  shape: (1, 512)\n",
            "PIXEL_0015  shape: (1, 512)\n",
            "PIXEL_0016  shape: (1, 512)\n",
            "PIXEL_0017  shape: (1, 512)\n",
            "PIXEL_0018  shape: (1, 512)\n",
            "PIXEL_0019  shape: (1, 512)\n",
            "PIXEL_0020  shape: (1, 512)\n",
            "PIXEL_0021  shape: (1, 512)\n",
            "PIXEL_0022  shape: (1, 512)\n",
            "PIXEL_0023  shape: (1, 512)\n",
            "PIXEL_0024  shape: (1, 512)\n",
            "PIXEL_0025  shape: (3, 512)\n",
            "PIXEL_0026  shape: (3, 512)\n",
            "PIXEL_0027  shape: (3, 512)\n",
            "PIXEL_0028  shape: (1, 512)\n",
            "PIXEL_0029  shape: (1, 512)\n",
            "PIXEL_0030  shape: (1, 512)\n",
            "PIXEL_0031  shape: (1, 512)\n",
            "PIXEL_0032  shape: (1, 512)\n",
            "PIXEL_0033  shape: (1, 512)\n",
            "PIXEL_0034  shape: (1, 512)\n",
            "PIXEL_0035  shape: (1, 512)\n",
            "PIXEL_0036  shape: (1, 512)\n",
            "PIXEL_0037  shape: (1, 512)\n",
            "PIXEL_0038  shape: (1, 512)\n",
            "PIXEL_0039  shape: (1, 512)\n",
            "PIXEL_0040  shape: (1, 512)\n",
            "PIXEL_0041  shape: (1, 512)\n",
            "PIXEL_0042  shape: (1, 512)\n",
            "PIXEL_0043  shape: (3, 512)\n",
            "PIXEL_0044  shape: (1, 512)\n",
            "PIXEL_0045  shape: (1, 512)\n",
            "PIXEL_0046  shape: (1, 512)\n",
            "PIXEL_0047  shape: (1, 512)\n",
            "PIXEL_0048  shape: (1, 512)\n",
            "PIXEL_0049  shape: (3, 512)\n",
            "PIXEL_0050  shape: (1, 512)\n",
            "PIXEL_0051  shape: (1, 512)\n",
            "PIXEL_0052  shape: (3, 512)\n",
            "PIXEL_0053  shape: (1, 512)\n",
            "PIXEL_0054  shape: (1, 512)\n",
            "PIXEL_0055  shape: (1, 512)\n",
            "PIXEL_0056  shape: (3, 512)\n",
            "PIXEL_0057  shape: (3, 512)\n",
            "PIXEL_0058  shape: (1, 512)\n",
            "PIXEL_0059  shape: (1, 512)\n",
            "PIXEL_0060  shape: (3, 512)\n",
            "PIXEL_0061  shape: (1, 512)\n",
            "PIXEL_0062  shape: (1, 512)\n",
            "PIXEL_0063  shape: (1, 512)\n",
            "PIXEL_0064  shape: (1, 512)\n",
            "PIXEL_0065  shape: (1, 512)\n",
            "PIXEL_0066  shape: (1, 512)\n",
            "PIXEL_0067  shape: (4, 512)\n",
            "PIXEL_0068  shape: (1, 512)\n",
            "PIXEL_0069  shape: (1, 512)\n",
            "PIXEL_0070  shape: (1, 512)\n",
            "PIXEL_0071  shape: (1, 512)\n",
            "PIXEL_0072  shape: (1, 512)\n",
            "PIXEL_0073  shape: (1, 512)\n",
            "PIXEL_0074  shape: (1, 512)\n",
            "PIXEL_0075  shape: (1, 512)\n",
            "PIXEL_0076  shape: (3, 512)\n",
            "PIXEL_0077  shape: (1, 512)\n",
            "PIXEL_0078  shape: (1, 512)\n",
            "PIXEL_0079  shape: (1, 512)\n",
            "PIXEL_0080  shape: (3, 512)\n",
            "PIXEL_0081  shape: (1, 512)\n",
            "PIXEL_0082  shape: (3, 512)\n",
            "PIXEL_0083  shape: (1, 512)\n",
            "PIXEL_0084  shape: (1, 512)\n",
            "PIXEL_0085  shape: (1, 512)\n",
            "PIXEL_0086  shape: (1, 512)\n",
            "PIXEL_0087  shape: (1, 512)\n",
            "PIXEL_0088  shape: (3, 512)\n",
            "PIXEL_0089  shape: (3, 512)\n",
            "PIXEL_0090  shape: (1, 512)\n",
            "PIXEL_0091  shape: (1, 512)\n",
            "PIXEL_0092  shape: (1, 512)\n",
            "PIXEL_0093  shape: (1, 512)\n",
            "PIXEL_0094  shape: (1, 512)\n",
            "PIXEL_0095  shape: (3, 512)\n",
            "PIXEL_0096  shape: (1, 512)\n",
            "PIXEL_0097  shape: (1, 512)\n",
            "PIXEL_0098  shape: (3, 512)\n",
            "PIXEL_0099  shape: (1, 512)\n",
            "PIXEL_0100  shape: (1, 512)\n",
            "PIXEL_0101  shape: (1, 512)\n",
            "PIXEL_0102  shape: (1, 512)\n",
            "PIXEL_0103  shape: (1, 512)\n",
            "PIXEL_0104  shape: (1, 512)\n",
            "PIXEL_0105  shape: (1, 512)\n",
            "PIXEL_0106  shape: (1, 512)\n",
            "PIXEL_0107  shape: (1, 512)\n",
            "PIXEL_0108  shape: (1, 512)\n",
            "PIXEL_0109  shape: (3, 512)\n",
            "PIXEL_0110  shape: (1, 512)\n",
            "PIXEL_0111  shape: (2, 512)\n",
            "PIXEL_0112  shape: (1, 512)\n",
            "PIXEL_0113  shape: (3, 512)\n",
            "PIXEL_0114  shape: (3, 512)\n",
            "PIXEL_0115  shape: (1, 512)\n",
            "PIXEL_0116  shape: (1, 512)\n",
            "PIXEL_0117  shape: (1, 512)\n",
            "PIXEL_0118  shape: (1, 512)\n",
            "PIXEL_0119  shape: (1, 512)\n",
            "PIXEL_0120  shape: (1, 512)\n",
            "PIXEL_0121  shape: (1, 512)\n",
            "PIXEL_0122  shape: (1, 512)\n",
            "PIXEL_0123  shape: (3, 512)\n",
            "PIXEL_0124  shape: (1, 512)\n",
            "PIXEL_0125  shape: (3, 512)\n",
            "PIXEL_0126  shape: (1, 512)\n",
            "PIXEL_0127  shape: (1, 512)\n",
            "PIXEL_0128  shape: (1, 512)\n",
            "PIXEL_0129  shape: (1, 512)\n",
            "PIXEL_0130  shape: (1, 512)\n",
            "PIXEL_0131  shape: (1, 512)\n",
            "PIXEL_0132  shape: (1, 512)\n",
            "PIXEL_0133  shape: (3, 512)\n",
            "PIXEL_0134  shape: (1, 512)\n",
            "PIXEL_0135  shape: (3, 512)\n",
            "PIXEL_0136  shape: (3, 512)\n",
            "PIXEL_0137  shape: (3, 512)\n",
            "PIXEL_0138  shape: (1, 512)\n",
            "PIXEL_0139  shape: (1, 512)\n",
            "PIXEL_0140  shape: (1, 512)\n",
            "PIXEL_0141  shape: (1, 512)\n",
            "PIXEL_0142  shape: (1, 512)\n",
            "PIXEL_0143  shape: (1, 512)\n",
            "PIXEL_0144  shape: (1, 512)\n",
            "PIXEL_0145  shape: (1, 512)\n",
            "PIXEL_0146  shape: (1, 512)\n",
            "PIXEL_0147  shape: (1, 512)\n",
            "PIXEL_0148  shape: (1, 512)\n",
            "PIXEL_0149  shape: (3, 512)\n",
            "PIXEL_0150  shape: (3, 512)\n",
            "PIXEL_0151  shape: (3, 512)\n",
            "PIXEL_0152  shape: (1, 512)\n",
            "PIXEL_0153  shape: (1, 512)\n",
            "PIXEL_0154  shape: (1, 512)\n",
            "PIXEL_0155  shape: (1, 512)\n",
            "PIXEL_0156  shape: (3, 512)\n",
            "PIXEL_0157  shape: (1, 512)\n",
            "PIXEL_0158  shape: (1, 512)\n",
            "PIXEL_0159  shape: (1, 512)\n",
            "PIXEL_0160  shape: (1, 512)\n",
            "PIXEL_0161  shape: (1, 512)\n",
            "PIXEL_0162  shape: (1, 512)\n",
            "PIXEL_0163  shape: (1, 512)\n",
            "PIXEL_0164  shape: (1, 512)\n",
            "PIXEL_0165  shape: (1, 512)\n",
            "PIXEL_0166  shape: (1, 512)\n",
            "PIXEL_0167  shape: (1, 512)\n",
            "PIXEL_0168  shape: (1, 512)\n",
            "PIXEL_0169  shape: (1, 512)\n",
            "PIXEL_0170  shape: (1, 512)\n",
            "PIXEL_0171  shape: (3, 512)\n",
            "PIXEL_0172  shape: (1, 512)\n",
            "PIXEL_0173  shape: (1, 512)\n",
            "PIXEL_0174  shape: (1, 512)\n",
            "PIXEL_0175  shape: (1, 512)\n",
            "PIXEL_0176  shape: (1, 512)\n",
            "PIXEL_0177  shape: (1, 512)\n",
            "PIXEL_0178  shape: (1, 512)\n",
            "PIXEL_0179  shape: (1, 512)\n",
            "PIXEL_0180  shape: (1, 512)\n",
            "PIXEL_0181  shape: (1, 512)\n",
            "PIXEL_0182  shape: (1, 512)\n",
            "PIXEL_0183  shape: (1, 512)\n",
            "PIXEL_0184  shape: (1, 512)\n",
            "PIXEL_0185  shape: (1, 512)\n",
            "PIXEL_0186  shape: (3, 512)\n",
            "PIXEL_0187  shape: (1, 512)\n",
            "PIXEL_0188  shape: (3, 512)\n",
            "PIXEL_0189  shape: (1, 512)\n",
            "PIXEL_0190  shape: (1, 512)\n",
            "PIXEL_0191  shape: (1, 512)\n",
            "PIXEL_0192  shape: (1, 512)\n",
            "PIXEL_0193  shape: (1, 512)\n",
            "PIXEL_0194  shape: (1, 512)\n",
            "PIXEL_0195  shape: (1, 512)\n",
            "PIXEL_0196  shape: (1, 512)\n",
            "PIXEL_0197  shape: (3, 512)\n",
            "PIXEL_0198  shape: (3, 512)\n",
            "PIXEL_0199  shape: (1, 512)\n",
            "PIXEL_0200  shape: (3, 512)\n",
            "PIXEL_0201  shape: (1, 512)\n",
            "PIXEL_0202  shape: (1, 512)\n",
            "PIXEL_0203  shape: (1, 512)\n",
            "PIXEL_0204  shape: (1, 512)\n",
            "PIXEL_0205  shape: (1, 512)\n",
            "PIXEL_0206  shape: (1, 512)\n",
            "PIXEL_0207  shape: (1, 512)\n",
            "PIXEL_0208  shape: (1, 512)\n",
            "PIXEL_0209  shape: (1, 512)\n",
            "PIXEL_0210  shape: (1, 512)\n",
            "PIXEL_0211  shape: (1, 512)\n",
            "PIXEL_0212  shape: (1, 512)\n",
            "PIXEL_0213  shape: (1, 512)\n",
            "PIXEL_0214  shape: (1, 512)\n",
            "PIXEL_0215  shape: (1, 512)\n",
            "PIXEL_0216  shape: (1, 512)\n",
            "PIXEL_0217  shape: (1, 512)\n",
            "PIXEL_0218  shape: (1, 512)\n",
            "PIXEL_0219  shape: (1, 512)\n",
            "PIXEL_0220  shape: (3, 512)\n",
            "PIXEL_0221  shape: (1, 512)\n",
            "PIXEL_0222  shape: (3, 512)\n",
            "PIXEL_0223  shape: (1, 512)\n",
            "PIXEL_0224  shape: (1, 512)\n",
            "PIXEL_0225  shape: (1, 512)\n",
            "PIXEL_0226  shape: (1, 512)\n",
            "PIXEL_0227  shape: (3, 512)\n",
            "PIXEL_0228  shape: (1, 512)\n",
            "PIXEL_0229  shape: (1, 512)\n",
            "PIXEL_0230  shape: (1, 512)\n",
            "PIXEL_0231  shape: (1, 512)\n",
            "PIXEL_0232  shape: (1, 512)\n",
            "PIXEL_0233  shape: (1, 512)\n",
            "PIXEL_0234  shape: (1, 512)\n",
            "PIXEL_0235  shape: (1, 512)\n",
            "PIXEL_0236  shape: (1, 512)\n",
            "PIXEL_0237  shape: (1, 512)\n",
            "PIXEL_0238  shape: (1, 512)\n",
            "PIXEL_0239  shape: (1, 512)\n",
            "PIXEL_0240  shape: (1, 512)\n",
            "PIXEL_0241  shape: (1, 512)\n",
            "PIXEL_0242  shape: (3, 512)\n",
            "PIXEL_0243  shape: (1, 512)\n",
            "PIXEL_0244  shape: (1, 512)\n",
            "PIXEL_0245  shape: (1, 512)\n",
            "PIXEL_0246  shape: (1, 512)\n",
            "PIXEL_0247  shape: (1, 512)\n",
            "PIXEL_0248  shape: (1, 512)\n",
            "PIXEL_0249  shape: (3, 512)\n",
            "PIXEL_0250  shape: (1, 512)\n",
            "PIXEL_0251  shape: (4, 512)\n",
            "PIXEL_0252  shape: (1, 512)\n",
            "PIXEL_0253  shape: (1, 512)\n",
            "PIXEL_0254  shape: (1, 512)\n",
            "PIXEL_0255  shape: (1, 512)\n",
            "PIXEL_0256  shape: (1, 512)\n",
            "PIXEL_0257  shape: (1, 512)\n",
            "PIXEL_0258  shape: (1, 512)\n",
            "PIXEL_0259  shape: (1, 512)\n",
            "PIXEL_0260  shape: (1, 512)\n",
            "PIXEL_0261  shape: (1, 512)\n",
            "PIXEL_0262  shape: (1, 512)\n",
            "PIXEL_0263  shape: (1, 512)\n",
            "PIXEL_0264  shape: (1, 512)\n",
            "PIXEL_0265  shape: (1, 512)\n",
            "PIXEL_0266  shape: (1, 512)\n",
            "PIXEL_0267  shape: (1, 512)\n",
            "PIXEL_0268  shape: (1, 512)\n",
            "PIXEL_0269  shape: (1, 512)\n",
            "PIXEL_0270  shape: (1, 512)\n",
            "PIXEL_0271  shape: (1, 512)\n",
            "PIXEL_0272  shape: (1, 512)\n",
            "PIXEL_0273  shape: (1, 512)\n",
            "PIXEL_0274  shape: (1, 512)\n",
            "PIXEL_0275  shape: (1, 512)\n",
            "PIXEL_0276  shape: (2, 512)\n",
            "PIXEL_0277  shape: (1, 512)\n",
            "PIXEL_0278  shape: (1, 512)\n",
            "PIXEL_0279  shape: (1, 512)\n",
            "PIXEL_0280  shape: (1, 512)\n",
            "PIXEL_0281  shape: (1, 512)\n",
            "PIXEL_0282  shape: (3, 512)\n",
            "PIXEL_0283  shape: (1, 512)\n",
            "PIXEL_0284  shape: (1, 512)\n",
            "PIXEL_0285  shape: (1, 512)\n",
            "PIXEL_0286  shape: (3, 512)\n",
            "PIXEL_0287  shape: (3, 512)\n",
            "PIXEL_0288  shape: (1, 512)\n",
            "PIXEL_0289  shape: (3, 512)\n",
            "PIXEL_0290  shape: (1, 512)\n",
            "PIXEL_0291  shape: (1, 512)\n",
            "PIXEL_0292  shape: (1, 512)\n",
            "PIXEL_0293  shape: (3, 512)\n",
            "PIXEL_0294  shape: (1, 512)\n",
            "PIXEL_0295  shape: (1, 512)\n",
            "PIXEL_0296  shape: (1, 512)\n",
            "PIXEL_0297  shape: (1, 512)\n",
            "PIXEL_0298  shape: (1, 512)\n",
            "PIXEL_0299  shape: (1, 512)\n",
            "PIXEL_0300  shape: (1, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_train_embeddings = []\n",
        "labels = []\n",
        "\n",
        "for uid, cls_list in cls_embeddings.items():\n",
        "    agg_embedding = mean_aggregator(cls_list)  #  Full mean pooling, no splitting\n",
        "    final_train_embeddings.append(agg_embedding)\n",
        "\n",
        "    crop_type = train_df.loc[train_df['unique_id'] == uid, 'crop_type'].iloc[0]\n",
        "    labels.append(crop_type)\n"
      ],
      "metadata": {
        "id": "JFCBi13v3zF0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_test_embeddings = []\n",
        "test_uids = []\n",
        "\n",
        "for uid, cls_list in cls_embeddings_test.items():\n",
        "    agg_embedding = mean_aggregator(cls_list)  #  Full mean over all CLS tokens\n",
        "    final_test_embeddings.append(agg_embedding)\n",
        "    test_uids.append(uid)  # Optional: useful for mapping back later\n"
      ],
      "metadata": {
        "id": "FSuPwTM08L4O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Updated label map with correct crop type names\n",
        "label_map = {'cocoa': 0, 'rubber': 1, 'oil': 2}  # 'oil' instead of 'oil_palm'\n",
        "\n",
        "# Extract the first crop_type per unique_id\n",
        "pixel_labels = train_df.groupby('unique_id').first()['crop_type']\n",
        "\n",
        "# Map crop types to integer labels\n",
        "labels = pixel_labels.map(label_map)\n",
        "\n",
        "# Drop any unmapped values (NaN) and convert to integer array\n",
        "labels = labels.dropna().astype(int).values\n",
        "\n",
        "# Output shape and distribution\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "print(\"Label distribution:\", np.bincount(labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXCjhzJFks5e",
        "outputId": "37712ed5-f9e5-44ed-84e4-d5cda4c95dc4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels shape: (300,)\n",
            "Label distribution: [100 100 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.array(final_train_embeddings)  # shape: [num_pixels, 512]\n",
        "y_train = np.array(labels)  # shape: [num_pixels]\n"
      ],
      "metadata": {
        "id": "_xpjOaSA_fWy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sQxtxSy_i2M",
        "outputId": "f391b65d-f245-40d8-cb5c-f27487f06851"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 512) (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "\n",
        "# Optional: get label  crop name mapping\n",
        "class_names = le.classes_\n"
      ],
      "metadata": {
        "id": "6j3RxypcAklc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(final_train_embeddings)\n",
        "\n",
        "# Flatten from shape [N, 1, 512]  [N, 512] if needed\n",
        "if X_train.ndim == 3 and X_train.shape[1] == 1:\n",
        "    X_train = X_train.squeeze(1)\n"
      ],
      "metadata": {
        "id": "GGly67JFBIgL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)  # should be (N, 512)\n",
        "print(\"y_train shape:\", y_train.shape)  # should be (N,)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFJPMz4joo_X",
        "outputId": "5dec9ca2-7ab9-435a-f29a-47938ce71275"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (300, 512)\n",
            "y_train shape: (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train = np.array(final_train_embeddings)\n",
        "y_train = np.array(y_train_encoded)\n",
        "\n",
        "#  FIX THE SHAPE\n",
        "if X_train.ndim == 3 and X_train.shape[1] == 1:\n",
        "    X_train = X_train.squeeze(1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial',class_weight='balanced')\n",
        "clf.fit(X_tr, y_tr)\n"
      ],
      "metadata": {
        "id": "2kKV26OOPyUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e15d3a38-a8b5-46ac-d542-21264d083a07"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(class_weight='balanced', max_iter=1000,\n",
              "                   multi_class='multinomial')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   multi_class=&#x27;multinomial&#x27;)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "y_pred_val = clf.predict(X_val)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred_val):.4f}\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred_val)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Validation Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "KEgc7_DNkJ2b",
        "outputId": "c4909bbb-601d-49b2-882f-4da26aecce5a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.2833\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.20      0.20        20\n",
            "           1       0.39      0.45      0.42        20\n",
            "           2       0.25      0.20      0.22        20\n",
            "\n",
            "    accuracy                           0.28        60\n",
            "   macro avg       0.28      0.28      0.28        60\n",
            "weighted avg       0.28      0.28      0.28        60\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "clf.fit(X_tr, y_tr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "oMmjfjV5nArp",
        "outputId": "da4a1293-7227-479b-b40a-a955db8b058b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Predict class probabilities on validation set\n",
        "y_proba_val = clf.predict_proba(X_val)\n",
        "\n",
        "# Compute log loss\n",
        "val_log_loss = log_loss(y_val, y_proba_val)\n",
        "\n",
        "print(f\"Validation Log Loss: {val_log_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZLgPnzJnSZF",
        "outputId": "5397e7a7-df1b-4015-9c5d-8b32cd9426fe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Log Loss: 1.0999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict using trained model\n",
        "y_pred = clf.predict(X_train)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_train, y_pred)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "# Plot it\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "CHX4Sp2gcWK_",
        "outputId": "205de6e5-eb62-48e5-cc63-3228f1f05a70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9433\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94       100\n",
            "           1       0.92      0.94      0.93       100\n",
            "           2       0.96      0.95      0.95       100\n",
            "\n",
            "    accuracy                           0.94       300\n",
            "   macro avg       0.94      0.94      0.94       300\n",
            "weighted avg       0.94      0.94      0.94       300\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Ensure X_test is ready\n",
        "X_test = np.array(final_test_embeddings)\n",
        "if X_test.ndim == 3 and X_test.shape[1] == 1:\n",
        "    X_test = X_test.squeeze(1)\n",
        "\n",
        "# 2 Get class probabilities using predict_proba\n",
        "probs = clf.predict_proba(X_test)  # shape: [N, 3]\n",
        "\n",
        "# 3 Map columns to class names from LabelEncoder\n",
        "class_names = le.inverse_transform(np.arange(probs.shape[1]))  # ['cocoa', 'rubber', 'oil']\n",
        "\n",
        "# 4 Create DataFrame with unique_id and class probabilities\n",
        "probs_df = pd.DataFrame(probs, columns=class_names)\n",
        "probs_df.insert(0, \"unique_id\", test_uids)  # Add UIDs to front\n",
        "\n",
        "# 5 Optional: round for presentation\n",
        "probs_df = probs_df.round(3)\n",
        "\n",
        "# Preview\n",
        "print(probs_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CsO6skrhF_B",
        "outputId": "cca32aee-b552-4e67-abb5-790b49391202"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   unique_id      0      1      2\n",
            "0  ID_002AIV  0.174  0.699  0.127\n",
            "1  ID_0042EI  0.491  0.361  0.148\n",
            "2  ID_008SD4  0.408  0.363  0.229\n",
            "3  ID_00AQE9  0.254  0.632  0.114\n",
            "4  ID_00F4A9  0.656  0.303  0.041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs_df.to_csv(\"test_probabilities.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "KsefkRyShF82"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IrWVsmG_hF6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKb5hzV6hF1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "19c5799fdc7f40258f28f1568a967de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79099b1ded42423fb22479cd36217db6",
              "IPY_MODEL_f41396ad91fd41e5848fbdbbc263b358",
              "IPY_MODEL_18a0d4c6ef4a42bba8f996c090accc19"
            ],
            "layout": "IPY_MODEL_942f9db83e2d48e3a3812f5c2c873a05"
          }
        },
        "79099b1ded42423fb22479cd36217db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d14bd34c3484a188062a12c82a91ba8",
            "placeholder": "",
            "style": "IPY_MODEL_5518ec3258d14c75b5e663ee7c0bb0c5",
            "value": "config.json:"
          }
        },
        "f41396ad91fd41e5848fbdbbc263b358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a88839dce48f4ff38353a64edc9be18c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f14d99d894cc4a4c9abd2e77b0bd3fbe",
            "value": 1
          }
        },
        "18a0d4c6ef4a42bba8f996c090accc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c63246cbff45d28042aae86152eeba",
            "placeholder": "",
            "style": "IPY_MODEL_24e8273d1b8a4348a95fbf4d48f6c6e2",
            "value": "1.19k/?[00:00&lt;00:00,90.2kB/s]"
          }
        },
        "942f9db83e2d48e3a3812f5c2c873a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d14bd34c3484a188062a12c82a91ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5518ec3258d14c75b5e663ee7c0bb0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a88839dce48f4ff38353a64edc9be18c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f14d99d894cc4a4c9abd2e77b0bd3fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29c63246cbff45d28042aae86152eeba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e8273d1b8a4348a95fbf4d48f6c6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb9c4ef904548eaaaa8fe37c94588ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2337e161ffbc4334af4b948da716ea59",
              "IPY_MODEL_5dcd8406094547f7b9cf788beba99dba",
              "IPY_MODEL_d24dacc1c21e4418ade4fecf1aa21040"
            ],
            "layout": "IPY_MODEL_ff8072efb457436696c3df1f40111063"
          }
        },
        "2337e161ffbc4334af4b948da716ea59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4df50ccb6249c7bd4b829139440b4d",
            "placeholder": "",
            "style": "IPY_MODEL_dfae76d3452049c5b70c762abb8d7f1c",
            "value": "model.safetensors:100%"
          }
        },
        "5dcd8406094547f7b9cf788beba99dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c81114c28e6e471485edf3857e1ec627",
            "max": 75757968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_decbf00bc3a84733a166c28443073881",
            "value": 75757968
          }
        },
        "d24dacc1c21e4418ade4fecf1aa21040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7885ae2379044158dcec2d28a331fb1",
            "placeholder": "",
            "style": "IPY_MODEL_f23293cddadc4e80a8636a80d79fa68d",
            "value": "75.8M/75.8M[00:00&lt;00:00,97.1MB/s]"
          }
        },
        "ff8072efb457436696c3df1f40111063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4df50ccb6249c7bd4b829139440b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfae76d3452049c5b70c762abb8d7f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c81114c28e6e471485edf3857e1ec627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "decbf00bc3a84733a166c28443073881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7885ae2379044158dcec2d28a331fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23293cddadc4e80a8636a80d79fa68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}